#!/usr/bin/env python3
"""
æµ‹è¯•é›ªçƒæ•°æ®é›†æˆæ•ˆæœ
éªŒè¯ç¤¾äº¤æƒ…ç»ªåˆ†ææ˜¯å¦æ­£ç¡®é›†æˆåˆ°æ™ºèƒ½é€‰è‚¡ç³»ç»Ÿä¸­
"""

import logging
import time
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_xueqiu_data_fetch():
    """æµ‹è¯•é›ªçƒæ•°æ®è·å–"""
    logger.info("=" * 60)
    logger.info("ğŸ“± æµ‹è¯•1: é›ªçƒæ•°æ®è·å–")
    logger.info("=" * 60)
    
    try:
        from tradingagents.dataflows.xueqiu_utils import get_xueqiu_provider
        
        provider = get_xueqiu_provider()
        
        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
        test_symbols = ['000001', '600519', '000858']  # å¹³å®‰é“¶è¡Œã€è´µå·èŒ…å°ã€äº”ç²®æ¶²
        
        for symbol in test_symbols:
            logger.info(f"\nğŸ“Š æµ‹è¯•è‚¡ç¥¨: {symbol}")
            
            # è·å–æƒ…ç»ªæ•°æ®
            sentiment = provider.get_stock_sentiment(symbol, days=7)
            if sentiment:
                logger.info(f"âœ… æƒ…ç»ªåˆ†ææˆåŠŸ:")
                logger.info(f"   - è®¨è®ºæ•°: {sentiment.get('total_discussions', 0)}")
                logger.info(f"   - æƒ…ç»ªåˆ†æ•°: {sentiment.get('sentiment_score', 0):.2f}")
                logger.info(f"   - ç§¯ææ¯”ä¾‹: {sentiment.get('positive_ratio', 0):.2%}")
                logger.info(f"   - å¹³å‡äº’åŠ¨: {sentiment.get('avg_interactions', 0):.0f}")
            else:
                logger.warning(f"âš ï¸ æœªè·å–åˆ° {symbol} çš„æƒ…ç»ªæ•°æ®")
            
            # è·å–è®¨è®ºæ•°æ®
            discussions = provider.get_stock_discussions(symbol, limit=5)
            if discussions:
                logger.info(f"âœ… è·å–åˆ° {len(discussions)} æ¡è®¨è®º")
                if discussions:
                    top_discussion = discussions[0]
                    logger.info(f"   æœ€çƒ­è®¨è®º: {top_discussion.get('text', '')[:100]}...")
            
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        logger.info("\nâœ… é›ªçƒæ•°æ®è·å–æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ é›ªçƒæ•°æ®è·å–æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_batch_processor_with_social():
    """æµ‹è¯•æ‰¹å¤„ç†å™¨çš„ç¤¾äº¤æ•°æ®é›†æˆ"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¤– æµ‹è¯•2: æ‰¹å¤„ç†å™¨ç¤¾äº¤æ•°æ®é›†æˆ")
    logger.info("=" * 60)
    
    try:
        from tradingagents.selectors.batch_ai_processor import BatchAIProcessor, BatchConfig
        
        # é…ç½®æ‰¹å¤„ç†å™¨
        config = BatchConfig(
            batch_size=10,
            max_workers=4,
            enable_social=True,  # å¯ç”¨ç¤¾äº¤åˆ†æ
            social_weight=0.2,
            min_discussions=5
        )
        
        processor = BatchAIProcessor(config)
        
        # æµ‹è¯•è‚¡ç¥¨
        test_symbols = ['000001', '600519']
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ {len(test_symbols)} åªè‚¡ç¥¨...")
        
        # æ‰§è¡Œæ‰¹å¤„ç†
        report = processor.process_stocks(test_symbols)
        
        logger.info(f"\nğŸ“Š æ‰¹å¤„ç†æŠ¥å‘Š:")
        logger.info(f"   - æ€»è‚¡ç¥¨æ•°: {report.total_stocks}")
        logger.info(f"   - æˆåŠŸå¤„ç†: {report.successful_stocks}")
        logger.info(f"   - å¤„ç†æ—¶é—´: {report.total_time:.2f}ç§’")
        logger.info(f"   - ååé‡: {report.throughput:.2f}è‚¡ç¥¨/ç§’")
        
        # æ£€æŸ¥ç¼“å­˜ä¸­çš„ç»“æœ
        if hasattr(processor, '_results_cache'):
            for symbol in test_symbols:
                if symbol in processor._results_cache:
                    result = processor._results_cache[symbol]
                    if result.success and result.analysis_result:
                        analysis = result.analysis_result
                        
                        logger.info(f"\nğŸ“ˆ {symbol} åˆ†æç»“æœ:")
                        logger.info(f"   - ç»¼åˆè¯„åˆ†: {analysis.get('combined_score', 0):.1f}")
                        logger.info(f"   - æ¨è: {analysis.get('recommendation', 'HOLD')}")
                        
                        # æ£€æŸ¥ç¤¾äº¤æ•°æ®
                        if 'social_signals' in analysis:
                            logger.info(f"   - ç¤¾äº¤ä¿¡å·: {', '.join(analysis['social_signals'])}")
                        
                        if 'analyst_results' in analysis and 'social' in analysis['analyst_results']:
                            social_data = analysis['analyst_results']['social']
                            logger.info(f"   - ç¤¾äº¤è¯„åˆ†: {social_data.get('social_score', 0):.1f}")
        
        logger.info("\nâœ… æ‰¹å¤„ç†å™¨ç¤¾äº¤æ•°æ®é›†æˆæµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_async_pipeline_social():
    """æµ‹è¯•å¼‚æ­¥ç®¡é“çš„ç¤¾äº¤æ•°æ®é›†æˆ"""
    logger.info("\n" + "=" * 60)
    logger.info("âš¡ æµ‹è¯•3: å¼‚æ­¥ç®¡é“ç¤¾äº¤æ•°æ®é›†æˆ")
    logger.info("=" * 60)
    
    try:
        import asyncio
        from tradingagents.dataflows.async_data_pipeline import AsyncDataPipeline, PipelineConfig
        
        async def run_test():
            # é…ç½®ç®¡é“
            config = PipelineConfig(
                max_concurrent_tasks=10,
                batch_size=50,
                enable_caching=True,
                cache_ttl=3600
            )
            
            pipeline = AsyncDataPipeline(config)
            
            # æµ‹è¯•è‚¡ç¥¨
            test_symbols = ['000001', '000002']
            
            logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥å¤„ç† {len(test_symbols)} åªè‚¡ç¥¨...")
            
            # å¤„ç†è‚¡ç¥¨
            result = await pipeline.process_symbols(test_symbols)
            
            if result and 'results' in result:
                for symbol, data in result['results'].items():
                    if not isinstance(data, dict) or 'error' in data:
                        continue
                    
                    logger.info(f"\nğŸ“Š {symbol} æ•°æ®:")
                    
                    # æ£€æŸ¥ç¤¾äº¤æ•°æ®å­—æ®µ
                    social_fields = [
                        'social_sentiment_score',
                        'total_discussions', 
                        'social_heat',
                        'sentiment_trend'
                    ]
                    
                    for field in social_fields:
                        if field in data:
                            logger.info(f"   - {field}: {data[field]}")
                    
                    # æ£€æŸ¥å¢å¼ºè¯„åˆ†
                    if 'enrich_score' in data:
                        logger.info(f"   - å¢å¼ºè¯„åˆ†: {data['enrich_score']:.1f}")
                    
                    if 'final_score' in data:
                        logger.info(f"   - æœ€ç»ˆè¯„åˆ†: {data['final_score']:.1f}")
            
            # æ˜¾ç¤ºåº¦é‡
            if 'metrics' in result:
                metrics = result['metrics']
                logger.info(f"\nğŸ“ˆ ç®¡é“åº¦é‡:")
                logger.info(f"   - å¤„ç†æ—¶é—´: {metrics.get('total_time', 0):.2f}ç§’")
                logger.info(f"   - ååé‡: {metrics.get('throughput', 0):.2f}è‚¡ç¥¨/ç§’")
            
            return True
        
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        success = asyncio.run(run_test())
        
        if success:
            logger.info("\nâœ… å¼‚æ­¥ç®¡é“ç¤¾äº¤æ•°æ®é›†æˆæµ‹è¯•é€šè¿‡!")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ å¼‚æ­¥ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_stock_selector_integration():
    """æµ‹è¯•è‚¡ç¥¨é€‰æ‹©å™¨çš„å®Œæ•´é›†æˆ"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¯ æµ‹è¯•4: è‚¡ç¥¨é€‰æ‹©å™¨å®Œæ•´é›†æˆ")
    logger.info("=" * 60)
    
    try:
        from tradingagents.selectors.stock_selector import StockSelector
        from tradingagents.selectors.config import AIMode
        
        selector = StockSelector()
        
        logger.info("ğŸš€ æ‰§è¡ŒAIå¢å¼ºé€‰è‚¡ï¼ˆåŒ…å«ç¤¾äº¤æ•°æ®ï¼‰...")
        
        # ä½¿ç”¨AIå¢å¼ºæ¨¡å¼é€‰è‚¡
        result = selector.ai_enhanced_select(
            min_score=60,
            limit=5,
            ai_mode=AIMode.AI_ENHANCED
        )
        
        if result and result.data is not None and not result.data.empty:
            logger.info(f"\nğŸ“Š é€‰è‚¡ç»“æœ:")
            logger.info(f"   - é€‰ä¸­è‚¡ç¥¨æ•°: {len(result.data)}")
            logger.info(f"   - æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¤¾äº¤æ•°æ®åˆ—
            social_columns = ['social_score', 'social_heat', 'social_sentiment', 'social_signals']
            available_social_cols = [col for col in social_columns if col in result.data.columns]
            
            if available_social_cols:
                logger.info(f"   - åŒ…å«ç¤¾äº¤æ•°æ®åˆ—: {', '.join(available_social_cols)}")
                
                # æ˜¾ç¤ºå‰å‡ åªè‚¡ç¥¨çš„ç¤¾äº¤æ•°æ®
                for idx, row in result.data.head(3).iterrows():
                    symbol = row.get('ts_code', '')
                    logger.info(f"\n   ğŸ“ˆ {symbol}:")
                    
                    if 'intelligent_score' in row:
                        logger.info(f"      - æ™ºèƒ½ç»¼åˆè¯„åˆ†: {row['intelligent_score']:.1f}")
                    
                    for col in available_social_cols:
                        if col in row and pd.notna(row[col]):
                            if col == 'social_signals':
                                logger.info(f"      - {col}: {row[col]}")
                            else:
                                logger.info(f"      - {col}: {row[col]:.2f}")
            else:
                logger.warning("   âš ï¸ æœªæ‰¾åˆ°ç¤¾äº¤æ•°æ®åˆ—")
            
            logger.info("\nâœ… è‚¡ç¥¨é€‰æ‹©å™¨é›†æˆæµ‹è¯•é€šè¿‡!")
            return True
        else:
            logger.warning("âš ï¸ é€‰è‚¡ç»“æœä¸ºç©º")
            return False
            
    except Exception as e:
        logger.error(f"âŒ è‚¡ç¥¨é€‰æ‹©å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•é›ªçƒæ•°æ®é›†æˆæ•ˆæœ")
    logger.info(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    test_results = {}
    
    # æµ‹è¯•1: é›ªçƒæ•°æ®è·å–
    test_results['xueqiu_fetch'] = test_xueqiu_data_fetch()
    time.sleep(1)
    
    # æµ‹è¯•2: æ‰¹å¤„ç†å™¨é›†æˆ
    test_results['batch_processor'] = test_batch_processor_with_social()
    time.sleep(1)
    
    # æµ‹è¯•3: å¼‚æ­¥ç®¡é“é›†æˆ
    test_results['async_pipeline'] = test_async_pipeline_social()
    time.sleep(1)
    
    # æµ‹è¯•4: å®Œæ•´é€‰è‚¡é›†æˆ
    test_results['stock_selector'] = test_stock_selector_integration()
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    logger.info("=" * 60)
    
    all_passed = True
    for test_name, passed in test_results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        logger.info(f"   {test_name}: {status}")
        if not passed:
            all_passed = False
    
    if all_passed:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é›ªçƒæ•°æ®å·²æˆåŠŸé›†æˆåˆ°æ™ºèƒ½é€‰è‚¡ç³»ç»Ÿ!")
        logger.info("\nğŸ“ˆ é›†æˆæ•ˆæœ:")
        logger.info("   1. æ‰¹å¤„ç†å™¨å¯ä»¥è·å–å¹¶åˆ†æé›ªçƒæƒ…ç»ªæ•°æ®")
        logger.info("   2. å¼‚æ­¥ç®¡é“åŒ…å«ç¤¾äº¤æ•°æ®è·å–å’Œè¯„åˆ†")
        logger.info("   3. è‚¡ç¥¨é€‰æ‹©å™¨ä½¿ç”¨ç¤¾äº¤ä¿¡å·è¿›è¡Œæ™ºèƒ½è¯„åˆ†")
        logger.info("   4. ç¼“å­˜ç­–ç•¥æœ‰æ•ˆå‡å°‘é‡å¤è¯·æ±‚")
    else:
        logger.error("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—å¹¶ä¿®å¤é—®é¢˜")
    
    return all_passed

if __name__ == "__main__":
    import pandas as pd
    
    # è®¾ç½®pandasæ˜¾ç¤ºé€‰é¡¹
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    
    # è¿è¡Œæµ‹è¯•
    success = main()
    exit(0 if success else 1)