#!/usr/bin/env python3
"""
AKShareæ•°æ®æºå·¥å…·
æä¾›AKShareæ•°æ®è·å–çš„ç»Ÿä¸€æ¥å£
"""

import pandas as pd
from typing import Optional, Dict, Any, List, Tuple
import warnings
from datetime import datetime, timedelta
import time
import concurrent.futures
import threading
from pathlib import Path

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('akshare')
warnings.filterwarnings('ignore')

class AKShareProvider:
    """AKShareæ•°æ®æä¾›å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–AKShareæä¾›å™¨"""
        try:
            import akshare as ak
            self.ak = ak
            self.connected = True

            # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            self._configure_timeout()

            logger.info(f"âœ… AKShareåˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            self.ak = None
            self.connected = False
            logger.error(f"âŒ AKShareæœªå®‰è£…")

    def _configure_timeout(self):
        """é…ç½®AKShareçš„è¶…æ—¶è®¾ç½®"""
        try:
            import requests
            import socket

            # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            socket.setdefaulttimeout(60)  # 60ç§’è¶…æ—¶

            # å¦‚æœAKShareä½¿ç”¨requestsï¼Œè®¾ç½®é»˜è®¤è¶…æ—¶
            if hasattr(requests, 'adapters'):
                from requests.adapters import HTTPAdapter
                from urllib3.util.retry import Retry

                # åˆ›å»ºé‡è¯•ç­–ç•¥
                retry_strategy = Retry(
                    total=3,
                    backoff_factor=1,
                    status_forcelist=[429, 500, 502, 503, 504],
                )

                # è®¾ç½®é€‚é…å™¨
                adapter = HTTPAdapter(max_retries=retry_strategy)
                session = requests.Session()
                session.mount("http://", adapter)
                session.mount("https://", adapter)

                logger.info(f"ğŸ”§ AKShareè¶…æ—¶é…ç½®å®Œæˆ: 60ç§’è¶…æ—¶ï¼Œ3æ¬¡é‡è¯•")

        except Exception as e:
            logger.error(f"âš ï¸ AKShareè¶…æ—¶é…ç½®å¤±è´¥: {e}")
            logger.info(f"ğŸ”§ ä½¿ç”¨é»˜è®¤è¶…æ—¶è®¾ç½®")
    
    def get_stock_data(self, symbol: str, start_date: str = None, end_date: str = None) -> Optional[pd.DataFrame]:
        """è·å–è‚¡ç¥¨å†å²æ•°æ®"""
        if not self.connected:
            return None
        
        try:
            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            if len(symbol) == 6:
                symbol = symbol
            else:
                symbol = symbol.replace('.SZ', '').replace('.SS', '')
            
            # è·å–æ•°æ®
            data = self.ak.stock_zh_a_hist(
                symbol=symbol,
                period="daily",
                start_date=start_date.replace('-', '') if start_date else "20240101",
                end_date=end_date.replace('-', '') if end_date else "20241231",
                adjust=""
            )
            
            return data
            
        except Exception as e:
            logger.error(f"âŒ AKShareè·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return None
    
    def get_stock_info(self, symbol: str) -> Dict[str, Any]:
        """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        if not self.connected:
            return {}
        
        try:
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_list = self.ak.stock_info_a_code_name()
            stock_info = stock_list[stock_list['code'] == symbol]
            
            if not stock_info.empty:
                return {
                    'symbol': symbol,
                    'name': stock_info.iloc[0]['name'],
                    'source': 'akshare'
                }
            else:
                return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'akshare'}
                
        except Exception as e:
            logger.error(f"âŒ AKShareè·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'akshare'}

    def get_hk_stock_data(self, symbol: str, start_date: str = None, end_date: str = None) -> Optional[pd.DataFrame]:
        """
        è·å–æ¸¯è‚¡å†å²æ•°æ®

        Args:
            symbol: æ¸¯è‚¡ä»£ç  (å¦‚: 00700 æˆ– 0700.HK)
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)

        Returns:
            DataFrame: æ¸¯è‚¡å†å²æ•°æ®
        """
        if not self.connected:
            logger.error(f"âŒ AKShareæœªè¿æ¥")
            return None

        try:
            # æ ‡å‡†åŒ–æ¸¯è‚¡ä»£ç  - AKShareä½¿ç”¨5ä½æ•°å­—æ ¼å¼
            hk_symbol = self._normalize_hk_symbol_for_akshare(symbol)

            logger.info(f"ğŸ‡­ğŸ‡° AKShareè·å–æ¸¯è‚¡æ•°æ®: {hk_symbol} ({start_date} åˆ° {end_date})")

            # æ ¼å¼åŒ–æ—¥æœŸä¸ºAKShareéœ€è¦çš„æ ¼å¼
            start_date_formatted = start_date.replace('-', '') if start_date else "20240101"
            end_date_formatted = end_date.replace('-', '') if end_date else "20241231"

            # ä½¿ç”¨AKShareè·å–æ¸¯è‚¡å†å²æ•°æ®ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
            import threading

            result = [None]
            exception = [None]

            def fetch_hist_data():
                try:
                    result[0] = self.ak.stock_hk_hist(
                        symbol=hk_symbol,
                        period="daily",
                        start_date=start_date_formatted,
                        end_date=end_date_formatted,
                        adjust=""
                    )
                except Exception as e:
                    exception[0] = e

            # å¯åŠ¨çº¿ç¨‹
            thread = threading.Thread(target=fetch_hist_data)
            thread.daemon = True
            thread.start()

            # ç­‰å¾…60ç§’
            thread.join(timeout=60)

            if thread.is_alive():
                # è¶…æ—¶äº†
                logger.warning(f"âš ï¸ AKShareæ¸¯è‚¡å†å²æ•°æ®è·å–è¶…æ—¶ï¼ˆ60ç§’ï¼‰: {symbol}")
                raise Exception(f"AKShareæ¸¯è‚¡å†å²æ•°æ®è·å–è¶…æ—¶ï¼ˆ60ç§’ï¼‰: {symbol}")
            elif exception[0]:
                # æœ‰å¼‚å¸¸
                raise exception[0]
            else:
                # æˆåŠŸ
                data = result[0]

            if not data.empty:
                # æ•°æ®é¢„å¤„ç†
                data = data.reset_index()
                data['Symbol'] = symbol  # ä¿æŒåŸå§‹æ ¼å¼

                # é‡å‘½ååˆ—ä»¥ä¿æŒä¸€è‡´æ€§
                column_mapping = {
                    'æ—¥æœŸ': 'Date',
                    'å¼€ç›˜': 'Open',
                    'æ”¶ç›˜': 'Close',
                    'æœ€é«˜': 'High',
                    'æœ€ä½': 'Low',
                    'æˆäº¤é‡': 'Volume',
                    'æˆäº¤é¢': 'Amount'
                }

                for old_col, new_col in column_mapping.items():
                    if old_col in data.columns:
                        data = data.rename(columns={old_col: new_col})

                logger.info(f"âœ… AKShareæ¸¯è‚¡æ•°æ®è·å–æˆåŠŸ: {symbol}, {len(data)}æ¡è®°å½•")
                return data
            else:
                logger.warning(f"âš ï¸ AKShareæ¸¯è‚¡æ•°æ®ä¸ºç©º: {symbol}")
                return None

        except Exception as e:
            logger.error(f"âŒ AKShareè·å–æ¸¯è‚¡æ•°æ®å¤±è´¥: {e}")
            return None

    def get_hk_stock_info(self, symbol: str) -> Dict[str, Any]:
        """
        è·å–æ¸¯è‚¡åŸºæœ¬ä¿¡æ¯

        Args:
            symbol: æ¸¯è‚¡ä»£ç 

        Returns:
            Dict: æ¸¯è‚¡åŸºæœ¬ä¿¡æ¯
        """
        if not self.connected:
            return {
                'symbol': symbol,
                'name': f'æ¸¯è‚¡{symbol}',
                'currency': 'HKD',
                'exchange': 'HKG',
                'source': 'akshare_unavailable'
            }

        try:
            hk_symbol = self._normalize_hk_symbol_for_akshare(symbol)

            logger.info(f"ğŸ‡­ğŸ‡° AKShareè·å–æ¸¯è‚¡ä¿¡æ¯: {hk_symbol}")

            # å°è¯•è·å–æ¸¯è‚¡å®æ—¶è¡Œæƒ…æ•°æ®æ¥è·å–åŸºæœ¬ä¿¡æ¯
            # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶åŒ…è£…ï¼ˆå…¼å®¹Windowsï¼‰
            import threading
            import time


            result = [None]
            exception = [None]

            def fetch_data():
                try:
                    result[0] = self.ak.stock_hk_spot_em()
                except Exception as e:
                    exception[0] = e

            # å¯åŠ¨çº¿ç¨‹
            thread = threading.Thread(target=fetch_data)
            thread.daemon = True
            thread.start()

            # ç­‰å¾…60ç§’
            thread.join(timeout=60)

            if thread.is_alive():
                # è¶…æ—¶äº†
                logger.warning(f"âš ï¸ AKShareæ¸¯è‚¡ä¿¡æ¯è·å–è¶…æ—¶ï¼ˆ60ç§’ï¼‰ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                raise Exception("AKShareæ¸¯è‚¡ä¿¡æ¯è·å–è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
            elif exception[0]:
                # æœ‰å¼‚å¸¸
                raise exception[0]
            else:
                # æˆåŠŸ
                spot_data = result[0]

            # æŸ¥æ‰¾å¯¹åº”çš„è‚¡ç¥¨ä¿¡æ¯
            if not spot_data.empty:
                # æŸ¥æ‰¾åŒ¹é…çš„è‚¡ç¥¨
                matching_stocks = spot_data[spot_data['ä»£ç '].str.contains(hk_symbol[:5], na=False)]

                if not matching_stocks.empty:
                    stock_info = matching_stocks.iloc[0]
                    return {
                        'symbol': symbol,
                        'name': stock_info.get('åç§°', f'æ¸¯è‚¡{symbol}'),
                        'currency': 'HKD',
                        'exchange': 'HKG',
                        'latest_price': stock_info.get('æœ€æ–°ä»·', None),
                        'source': 'akshare'
                    }

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
            return {
                'symbol': symbol,
                'name': f'æ¸¯è‚¡{symbol}',
                'currency': 'HKD',
                'exchange': 'HKG',
                'source': 'akshare'
            }

        except Exception as e:
            logger.error(f"âŒ AKShareè·å–æ¸¯è‚¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'symbol': symbol,
                'name': f'æ¸¯è‚¡{symbol}',
                'currency': 'HKD',
                'exchange': 'HKG',
                'source': 'akshare_error',
                'error': str(e)
            }

    def _normalize_hk_symbol_for_akshare(self, symbol: str) -> str:
        """
        æ ‡å‡†åŒ–æ¸¯è‚¡ä»£ç ä¸ºAKShareæ ¼å¼

        Args:
            symbol: åŸå§‹æ¸¯è‚¡ä»£ç  (å¦‚: 0700.HK æˆ– 700)

        Returns:
            str: AKShareæ ¼å¼çš„æ¸¯è‚¡ä»£ç  (å¦‚: 00700)
        """
        if not symbol:
            return symbol

        # ç§»é™¤.HKåç¼€
        clean_symbol = symbol.replace('.HK', '').replace('.hk', '')

        # ç¡®ä¿æ˜¯5ä½æ•°å­—æ ¼å¼
        if clean_symbol.isdigit():
            return clean_symbol.zfill(5)

        return clean_symbol

    def get_financial_data(self, symbol: str) -> Dict[str, Any]:
        """
        è·å–è‚¡ç¥¨è´¢åŠ¡æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç  (6ä½æ•°å­—)
            
        Returns:
            Dict: åŒ…å«ä¸»è¦è´¢åŠ¡æŒ‡æ ‡çš„è´¢åŠ¡æ•°æ®
        """
        if not self.connected:
            logger.error(f"âŒ AKShareæœªè¿æ¥ï¼Œæ— æ³•è·å–{symbol}è´¢åŠ¡æ•°æ®")
            return {}
        
        try:
            logger.info(f"ğŸ” å¼€å§‹è·å–{symbol}çš„AKShareè´¢åŠ¡æ•°æ®")
            
            financial_data = {}
            
            # 1. ä¼˜å…ˆè·å–ä¸»è¦è´¢åŠ¡æŒ‡æ ‡
            try:
                logger.debug(f"ğŸ“Š å°è¯•è·å–{symbol}ä¸»è¦è´¢åŠ¡æŒ‡æ ‡...")
                main_indicators = self.ak.stock_financial_abstract(symbol=symbol)
                if main_indicators is not None and not main_indicators.empty:
                    financial_data['main_indicators'] = main_indicators
                    logger.info(f"âœ… æˆåŠŸè·å–{symbol}ä¸»è¦è´¢åŠ¡æŒ‡æ ‡: {len(main_indicators)}æ¡è®°å½•")
                    logger.debug(f"ä¸»è¦è´¢åŠ¡æŒ‡æ ‡åˆ—å: {list(main_indicators.columns)}")
                else:
                    logger.warning(f"âš ï¸ {symbol}ä¸»è¦è´¢åŠ¡æŒ‡æ ‡ä¸ºç©º")
            except Exception as e:
                logger.warning(f"âŒ è·å–{symbol}ä¸»è¦è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
            
            # 2. å°è¯•è·å–èµ„äº§è´Ÿå€ºè¡¨ï¼ˆå¯èƒ½å¤±è´¥ï¼Œé™çº§ä¸ºdebugæ—¥å¿—ï¼‰
            try:
                logger.debug(f"ğŸ“Š å°è¯•è·å–{symbol}èµ„äº§è´Ÿå€ºè¡¨...")
                balance_sheet = self.ak.stock_balance_sheet_by_report_em(symbol=symbol)
                if balance_sheet is not None and not balance_sheet.empty:
                    financial_data['balance_sheet'] = balance_sheet
                    logger.debug(f"âœ… æˆåŠŸè·å–{symbol}èµ„äº§è´Ÿå€ºè¡¨: {len(balance_sheet)}æ¡è®°å½•")
                else:
                    logger.debug(f"âš ï¸ {symbol}èµ„äº§è´Ÿå€ºè¡¨ä¸ºç©º")
            except Exception as e:
                logger.debug(f"âŒ è·å–{symbol}èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {e}")
            
            # 3. å°è¯•è·å–åˆ©æ¶¦è¡¨ï¼ˆå¯èƒ½å¤±è´¥ï¼Œé™çº§ä¸ºdebugæ—¥å¿—ï¼‰
            try:
                logger.debug(f"ğŸ“Š å°è¯•è·å–{symbol}åˆ©æ¶¦è¡¨...")
                income_statement = self.ak.stock_profit_sheet_by_report_em(symbol=symbol)
                if income_statement is not None and not income_statement.empty:
                    financial_data['income_statement'] = income_statement
                    logger.debug(f"âœ… æˆåŠŸè·å–{symbol}åˆ©æ¶¦è¡¨: {len(income_statement)}æ¡è®°å½•")
                else:
                    logger.debug(f"âš ï¸ {symbol}åˆ©æ¶¦è¡¨ä¸ºç©º")
            except Exception as e:
                logger.debug(f"âŒ è·å–{symbol}åˆ©æ¶¦è¡¨å¤±è´¥: {e}")
            
            # 4. å°è¯•è·å–ç°é‡‘æµé‡è¡¨ï¼ˆå¯èƒ½å¤±è´¥ï¼Œé™çº§ä¸ºdebugæ—¥å¿—ï¼‰
            try:
                logger.debug(f"ğŸ“Š å°è¯•è·å–{symbol}ç°é‡‘æµé‡è¡¨...")
                cash_flow = self.ak.stock_cash_flow_sheet_by_report_em(symbol=symbol)
                if cash_flow is not None and not cash_flow.empty:
                    financial_data['cash_flow'] = cash_flow
                    logger.debug(f"âœ… æˆåŠŸè·å–{symbol}ç°é‡‘æµé‡è¡¨: {len(cash_flow)}æ¡è®°å½•")
                else:
                    logger.debug(f"âš ï¸ {symbol}ç°é‡‘æµé‡è¡¨ä¸ºç©º")
            except Exception as e:
                logger.debug(f"âŒ è·å–{symbol}ç°é‡‘æµé‡è¡¨å¤±è´¥: {e}")
            
            # è®°å½•æœ€ç»ˆç»“æœ
            if financial_data:
                logger.info(f"âœ… AKShareè´¢åŠ¡æ•°æ®è·å–å®Œæˆ: {symbol}, åŒ…å«{len(financial_data)}ä¸ªæ•°æ®é›†")
                for key, value in financial_data.items():
                    if hasattr(value, '__len__'):
                        logger.info(f"  - {key}: {len(value)}æ¡è®°å½•")
            else:
                logger.warning(f"âš ï¸ æœªèƒ½è·å–{symbol}çš„ä»»ä½•AKShareè´¢åŠ¡æ•°æ®")
            
            return financial_data
            
        except Exception as e:
            logger.error(f"âŒ AKShareè·å–{symbol}è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            return {}

    def get_stock_list(self) -> Optional[pd.DataFrame]:
        """
        è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨
        
        Returns:
            DataFrame: åŒ…å«æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä¿¡æ¯
        """
        if not self.connected:
            return None
        
        try:
            logger.info("ğŸ” å¼€å§‹è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
            
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_list = self.ak.stock_info_a_code_name()
            
            if stock_list is not None and not stock_list.empty:
                # æ·»åŠ æ ‡å‡†åŒ–çš„å­—æ®µ
                stock_list['symbol'] = stock_list['code']
                stock_list['name'] = stock_list['name']
                stock_list['market'] = stock_list['code'].apply(self._get_market_from_code)
                
                logger.info(f"âœ… è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨æˆåŠŸï¼Œå…± {len(stock_list)} åªè‚¡ç¥¨")
                return stock_list
            else:
                logger.warning("âš ï¸ æœªèƒ½è·å–è‚¡ç¥¨åˆ—è¡¨")
                return None
                
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return None

    def _get_market_from_code(self, code: str) -> str:
        """æ ¹æ®è‚¡ç¥¨ä»£ç åˆ¤æ–­å¸‚åœº"""
        if code.startswith(('000', '001', '002', '003', '300')):
            return 'SZ'  # æ·±åœ³
        elif code.startswith(('600', '601', '603', '605', '688', '689')):
            return 'SH'  # ä¸Šæµ·
        else:
            return 'SZ'  # é»˜è®¤æ·±åœ³

    def batch_get_stock_data(self, symbols: List[str], start_date: str = None, 
                           end_date: str = None, max_workers: int = 20,  # æ¿€è¿›ä¼˜åŒ–ï¼šæå‡åˆ°20å¹¶å‘
                           delay: float = 0.1) -> Dict[str, pd.DataFrame]:  # ç¼©çŸ­å»¶è¿Ÿ
        """
        æ‰¹é‡è·å–è‚¡ç¥¨å†å²æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)  
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
            delay: è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            {symbol: DataFrame} å­—å…¸
        """
        if not self.connected:
            logger.error("âŒ AKShareæœªè¿æ¥")
            return {}
        
        if not symbols:
            logger.warning("âš ï¸ è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸ºç©º")
            return {}
        
        results = {}
        total = len(symbols)
        processed = 0
        failed = 0
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡è·å– {total} åªè‚¡ç¥¨çš„AKShareæ•°æ®...")
        logger.info(f"ğŸ“Š é…ç½®: å¹¶å‘æ•°={max_workers}, å»¶è¿Ÿ={delay}ç§’, æ—¥æœŸèŒƒå›´={start_date}åˆ°{end_date}")
        
        def fetch_single_stock(symbol: str) -> Tuple[str, Optional[pd.DataFrame]]:
            """è·å–å•ä¸ªè‚¡ç¥¨æ•°æ®"""
            try:
                # è¯·æ±‚é—´éš”
                time.sleep(delay)
                
                data = self.get_stock_data(symbol, start_date, end_date)
                return symbol, data
                
            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡è·å– {symbol} å¤±è´¥: {e}")
                return symbol, None
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰¹é‡å¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_symbol = {
                executor.submit(fetch_single_stock, symbol): symbol 
                for symbol in symbols
            }
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    symbol_result, data = future.result()
                    if data is not None and not data.empty:
                        results[symbol_result] = data
                        processed += 1
                    else:
                        failed += 1
                    
                    # è¿›åº¦æŠ¥å‘Š
                    current = processed + failed
                    if current % 50 == 0 or current == total:
                        progress = current / total * 100
                        logger.info(f"ğŸ“ˆ è¿›åº¦: {current}/{total} ({progress:.1f}%) - æˆåŠŸ:{processed} å¤±è´¥:{failed}")
                        
                except Exception as e:
                    logger.error(f"âŒ å¤„ç† {symbol} ç»“æœæ—¶å¤±è´¥: {e}")
                    failed += 1
        
        success_rate = processed / total * 100 if total > 0 else 0
        logger.info(f"âœ… AKShareæ‰¹é‡è·å–å®Œæˆ: æ€»æ•°:{total} æˆåŠŸ:{processed} å¤±è´¥:{failed} æˆåŠŸç‡:{success_rate:.1f}%")
        
        return results

    def batch_get_financial_data(self, symbols: List[str], max_workers: int = 10,  # æ¿€è¿›ä¼˜åŒ–ï¼šæå‡åˆ°10å¹¶å‘
                               delay: float = 0.5) -> Dict[str, Dict[str, Any]]:  # ç¼©çŸ­å»¶è¿Ÿ
        """
        æ‰¹é‡è·å–è´¢åŠ¡æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘æ•°ï¼ˆè´¢åŠ¡æ•°æ®è¯·æ±‚è¾ƒé‡ï¼Œå»ºè®®è¾ƒå°å€¼ï¼‰
            delay: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            {symbol: financial_data} å­—å…¸
        """
        if not self.connected:
            logger.error("âŒ AKShareæœªè¿æ¥")
            return {}
        
        results = {}
        total = len(symbols)
        processed = 0
        failed = 0
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡è·å– {total} åªè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®...")
        
        def fetch_single_financial(symbol: str) -> Tuple[str, Dict[str, Any]]:
            """è·å–å•ä¸ªè‚¡ç¥¨è´¢åŠ¡æ•°æ®"""
            try:
                time.sleep(delay)  # è´¢åŠ¡æ•°æ®è¯·æ±‚é—´éš”è¾ƒé•¿
                financial_data = self.get_financial_data(symbol)
                return symbol, financial_data
            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡è·å– {symbol} è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
                return symbol, {}
        
        # ä½¿ç”¨è¾ƒå°çš„çº¿ç¨‹æ± 
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_symbol = {
                executor.submit(fetch_single_financial, symbol): symbol 
                for symbol in symbols
            }
            
            for future in concurrent.futures.as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    symbol_result, financial_data = future.result()
                    if financial_data:
                        results[symbol_result] = financial_data
                        processed += 1
                    else:
                        failed += 1
                    
                    current = processed + failed
                    if current % 20 == 0 or current == total:
                        progress = current / total * 100
                        logger.info(f"ğŸ“ˆ è´¢åŠ¡æ•°æ®è¿›åº¦: {current}/{total} ({progress:.1f}%) - æˆåŠŸ:{processed} å¤±è´¥:{failed}")
                        
                except Exception as e:
                    logger.error(f"âŒ å¤„ç† {symbol} è´¢åŠ¡æ•°æ®ç»“æœæ—¶å¤±è´¥: {e}")
                    failed += 1
        
        success_rate = processed / total * 100 if total > 0 else 0
        logger.info(f"âœ… AKShareè´¢åŠ¡æ•°æ®æ‰¹é‡è·å–å®Œæˆ: æˆåŠŸç‡:{success_rate:.1f}%")
        
        return results

    def batch_download_all_stocks(self, start_date: str = None, end_date: str = None,
                                save_to_file: bool = True, file_path: str = None) -> Dict[str, Any]:
        """
        æ‰¹é‡ä¸‹è½½æ‰€æœ‰Aè‚¡å†å²æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            file_path: ä¿å­˜è·¯å¾„
            
        Returns:
            ä¸‹è½½ç»Ÿè®¡å’Œæ•°æ®
        """
        # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = self.get_stock_list()
        if stock_list is None or stock_list.empty:
            logger.error("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return {}
        
        symbols = stock_list['code'].tolist()
        logger.info(f"ğŸ¯ å‡†å¤‡æ‰¹é‡ä¸‹è½½ {len(symbols)} åªAè‚¡æ•°æ®")
        
        # 2. æ‰¹é‡ä¸‹è½½æ•°æ®ï¼ˆä½¿ç”¨æ¿€è¿›å¹¶å‘ä¼˜åŒ–ï¼‰
        stock_data = self.batch_get_stock_data(
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            max_workers=25,  # æ¿€è¿›ä¼˜åŒ–ï¼šæ™ºèƒ½é€‰è‚¡ä¸“ç”¨é«˜å¹¶å‘
            delay=0.05       # æ›´çŸ­çš„å»¶è¿Ÿ
        )
        
        # 3. æ‰¹é‡è·å–åŸºæœ¬ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        logger.info("ğŸ“‹ æ‰¹é‡è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
        
        # 4. ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_stocks': len(symbols),
            'successful_downloads': len(stock_data),
            'failed_downloads': len(symbols) - len(stock_data),
            'success_rate': len(stock_data) / len(symbols) * 100 if symbols else 0,
            'stock_list': stock_list,
            'download_summary': {}
        }
        
        # 5. ç”Ÿæˆä¸‹è½½æ‘˜è¦
        for symbol, df in stock_data.items():
            if df is not None and not df.empty:
                stats['download_summary'][symbol] = {
                    'records': len(df),
                    'date_range': f"{df.index.min()} - {df.index.max()}" if not df.empty else "æ— æ•°æ®",
                    'data_size': df.memory_usage(deep=True).sum()
                }
        
        logger.info(f"ğŸ‰ AKShareæ‰¹é‡ä¸‹è½½å®Œæˆ: æˆåŠŸç‡ {stats['success_rate']:.1f}%")
        
        # 6. ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        if save_to_file and stock_data:
            try:
                if not file_path:
                    file_path = f"akshare_batch_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
                
                import pickle
                with open(file_path, 'wb') as f:
                    pickle.dump({
                        'stats': stats,
                        'data': stock_data,
                        'download_time': datetime.now().isoformat()
                    }, f)
                
                logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {file_path}")
                stats['saved_file'] = file_path
                
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        
        return {
            'stats': stats,
            'data': stock_data
        }

    def smart_batch_update(self, symbols: List[str], existing_data: Dict[str, pd.DataFrame] = None,
                         start_date: str = None, end_date: str = None) -> Dict[str, pd.DataFrame]:
        """
        æ™ºèƒ½æ‰¹é‡æ›´æ–° - åªè·å–ç¼ºå¤±çš„æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            existing_data: ç°æœ‰æ•°æ® {symbol: DataFrame}
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æ›´æ–°åçš„å®Œæ•´æ•°æ®
        """
        if existing_data is None:
            existing_data = {}
        
        # åˆ†æéœ€è¦æ›´æ–°çš„è‚¡ç¥¨
        need_full_download = []  # éœ€è¦å®Œæ•´ä¸‹è½½
        need_incremental = []    # éœ€è¦å¢é‡æ›´æ–°
        up_to_date = []         # å·²æ˜¯æœ€æ–°
        
        current_date = datetime.now().strftime('%Y-%m-%d')
        
        for symbol in symbols:
            if symbol not in existing_data:
                need_full_download.append(symbol)
            else:
                df = existing_data[symbol]
                if df.empty:
                    need_full_download.append(symbol)
                else:
                    # æ£€æŸ¥æœ€æ–°æ—¥æœŸ
                    if hasattr(df.index, 'max'):
                        latest_date = df.index.max().strftime('%Y-%m-%d')
                    else:
                        latest_date = df['date'].max() if 'date' in df.columns else start_date
                    
                    if latest_date < current_date:
                        need_incremental.append((symbol, latest_date))
                    else:
                        up_to_date.append(symbol)
        
        logger.info(f"ğŸ“Š æ•°æ®æ›´æ–°åˆ†æ: å®Œæ•´ä¸‹è½½:{len(need_full_download)} å¢é‡æ›´æ–°:{len(need_incremental)} æœ€æ–°:{len(up_to_date)}")
        
        results = existing_data.copy()
        
        # 1. å®Œæ•´ä¸‹è½½
        if need_full_download:
            logger.info(f"ğŸ”„ å®Œæ•´ä¸‹è½½ {len(need_full_download)} åªè‚¡ç¥¨...")
            full_data = self.batch_get_stock_data(need_full_download, start_date, end_date)
            results.update(full_data)
        
        # 2. å¢é‡æ›´æ–°
        if need_incremental:
            logger.info(f"âš¡ å¢é‡æ›´æ–° {len(need_incremental)} åªè‚¡ç¥¨...")
            for symbol, last_date in need_incremental:
                # ä»æœ€åæ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹
                next_date = (datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
                new_data = self.get_stock_data(symbol, next_date, end_date)
                
                if new_data is not None and not new_data.empty:
                    # åˆå¹¶æ•°æ®
                    if symbol in results:
                        results[symbol] = pd.concat([results[symbol], new_data]).drop_duplicates()
                    else:
                        results[symbol] = new_data
        
        logger.info(f"âœ… æ™ºèƒ½æ‰¹é‡æ›´æ–°å®Œæˆï¼Œæ€»è®¡ {len(results)} åªè‚¡ç¥¨æœ‰æ•°æ®")
        return results

def get_akshare_provider() -> AKShareProvider:
    """è·å–AKShareæä¾›å™¨å®ä¾‹"""
    return AKShareProvider()


# ä¾¿æ·å‡½æ•°
def get_hk_stock_data_akshare(symbol: str, start_date: str = None, end_date: str = None) -> str:
    """
    ä½¿ç”¨AKShareè·å–æ¸¯è‚¡æ•°æ®çš„ä¾¿æ·å‡½æ•°

    Args:
        symbol: æ¸¯è‚¡ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ

    Returns:
        str: æ ¼å¼åŒ–çš„æ¸¯è‚¡æ•°æ®
    """
    try:
        provider = get_akshare_provider()
        data = provider.get_hk_stock_data(symbol, start_date, end_date)

        if data is not None and not data.empty:
            return format_hk_stock_data_akshare(symbol, data, start_date, end_date)
        else:
            return f"âŒ æ— æ³•è·å–æ¸¯è‚¡ {symbol} çš„AKShareæ•°æ®"

    except Exception as e:
        return f"âŒ AKShareæ¸¯è‚¡æ•°æ®è·å–å¤±è´¥: {e}"


def get_hk_stock_info_akshare(symbol: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨AKShareè·å–æ¸¯è‚¡ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°

    Args:
        symbol: æ¸¯è‚¡ä»£ç 

    Returns:
        Dict: æ¸¯è‚¡ä¿¡æ¯
    """
    try:
        provider = get_akshare_provider()
        return provider.get_hk_stock_info(symbol)
    except Exception as e:
        return {
            'symbol': symbol,
            'name': f'æ¸¯è‚¡{symbol}',
            'currency': 'HKD',
            'exchange': 'HKG',
            'source': 'akshare_error',
            'error': str(e)
        }


def format_hk_stock_data_akshare(symbol: str, data: pd.DataFrame, start_date: str, end_date: str) -> str:
    """
    æ ¼å¼åŒ–AKShareæ¸¯è‚¡æ•°æ®ä¸ºæ–‡æœ¬æ ¼å¼

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        data: è‚¡ç¥¨æ•°æ®DataFrame
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ

    Returns:
        str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®æ–‡æœ¬
    """
    if data is None or data.empty:
        return f"âŒ æ— æ³•è·å–æ¸¯è‚¡ {symbol} çš„AKShareæ•°æ®"

    try:
        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå…è®¸å¤±è´¥ï¼‰
        stock_name = f'æ¸¯è‚¡{symbol}'  # é»˜è®¤åç§°
        try:
            provider = get_akshare_provider()
            stock_info = provider.get_hk_stock_info(symbol)
            stock_name = stock_info.get('name', f'æ¸¯è‚¡{symbol}')
            logger.info(f"âœ… æ¸¯è‚¡ä¿¡æ¯è·å–æˆåŠŸ: {stock_name}")
        except Exception as info_error:
            logger.error(f"âš ï¸ æ¸¯è‚¡ä¿¡æ¯è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¿¡æ¯: {info_error}")
            # ç»§ç»­å¤„ç†ï¼Œä½¿ç”¨é»˜è®¤ä¿¡æ¯

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        latest_price = data['Close'].iloc[-1]
        price_change = data['Close'].iloc[-1] - data['Close'].iloc[0]
        price_change_pct = (price_change / data['Close'].iloc[0]) * 100

        avg_volume = data['Volume'].mean() if 'Volume' in data.columns else 0
        max_price = data['High'].max()
        min_price = data['Low'].min()

        # æ ¼å¼åŒ–è¾“å‡º
        formatted_text = f"""
ğŸ‡­ğŸ‡° æ¸¯è‚¡æ•°æ®æŠ¥å‘Š (AKShare)
================

è‚¡ç¥¨ä¿¡æ¯:
- ä»£ç : {symbol}
- åç§°: {stock_name}
- è´§å¸: æ¸¯å¸ (HKD)
- äº¤æ˜“æ‰€: é¦™æ¸¯äº¤æ˜“æ‰€ (HKG)

ä»·æ ¼ä¿¡æ¯:
- æœ€æ–°ä»·æ ¼: HK${latest_price:.2f}
- æœŸé—´æ¶¨è·Œ: HK${price_change:+.2f} ({price_change_pct:+.2f}%)
- æœŸé—´æœ€é«˜: HK${max_price:.2f}
- æœŸé—´æœ€ä½: HK${min_price:.2f}

äº¤æ˜“ä¿¡æ¯:
- æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}
- äº¤æ˜“å¤©æ•°: {len(data)}å¤©
- å¹³å‡æˆäº¤é‡: {avg_volume:,.0f}è‚¡

æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥:
"""

        # æ·»åŠ æœ€è¿‘5å¤©çš„æ•°æ®
        recent_data = data.tail(5)
        for _, row in recent_data.iterrows():
            date = row['Date'].strftime('%Y-%m-%d') if 'Date' in row else row.name.strftime('%Y-%m-%d')
            volume = row.get('Volume', 0)
            formatted_text += f"- {date}: å¼€ç›˜HK${row['Open']:.2f}, æ”¶ç›˜HK${row['Close']:.2f}, æˆäº¤é‡{volume:,.0f}\n"

        formatted_text += f"\næ•°æ®æ¥æº: AKShare (æ¸¯è‚¡)\n"

        return formatted_text

    except Exception as e:
        logger.error(f"âŒ æ ¼å¼åŒ–AKShareæ¸¯è‚¡æ•°æ®å¤±è´¥: {e}")
        return f"âŒ AKShareæ¸¯è‚¡æ•°æ®æ ¼å¼åŒ–å¤±è´¥: {symbol}"


def get_stock_news_em(symbol: str) -> pd.DataFrame:
    """
    ä½¿ç”¨AKShareè·å–ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—»

    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "600000" æˆ– "300059"

    Returns:
        pd.DataFrame: åŒ…å«æ–°é—»æ ‡é¢˜ã€å†…å®¹ã€æ—¥æœŸå’Œé“¾æ¥çš„DataFrame
    """
    start_time = datetime.now()
    logger.info(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] å¼€å§‹è·å–è‚¡ç¥¨ {symbol} çš„ä¸œæ–¹è´¢å¯Œæ–°é—»æ•°æ®")
    
    try:
        provider = get_akshare_provider()
        if not provider.connected:
            logger.error(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] âŒ AKShareæœªè¿æ¥ï¼Œæ— æ³•è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»")
            return pd.DataFrame()

        logger.info(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] ğŸ“° å‡†å¤‡è°ƒç”¨AKShare APIè·å–ä¸ªè‚¡æ–°é—»: {symbol}")

        # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶åŒ…è£…ï¼ˆå…¼å®¹Windowsï¼‰
        import threading
        import time

        result = [None]
        exception = [None]

        def fetch_news():
            try:
                logger.debug(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] çº¿ç¨‹å¼€å§‹æ‰§è¡Œ stock_news_em APIè°ƒç”¨: {symbol}")
                thread_start = time.time()
                result[0] = provider.ak.stock_news_em(symbol=symbol)
                thread_end = time.time()
                logger.debug(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] çº¿ç¨‹æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {thread_end - thread_start:.2f}ç§’")
            except Exception as e:
                logger.error(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")
                exception[0] = e

        # å¯åŠ¨çº¿ç¨‹
        thread = threading.Thread(target=fetch_news)
        thread.daemon = True
        logger.debug(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] å¯åŠ¨çº¿ç¨‹è·å–æ–°é—»æ•°æ®")
        thread.start()

        # ç­‰å¾…30ç§’
        logger.debug(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] ç­‰å¾…çº¿ç¨‹å®Œæˆï¼Œæœ€é•¿ç­‰å¾…30ç§’")
        thread.join(timeout=30)

        if thread.is_alive():
            # è¶…æ—¶äº†
            elapsed_time = (datetime.now() - start_time).total_seconds()
            logger.warning(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] âš ï¸ è·å–è¶…æ—¶ï¼ˆ30ç§’ï¼‰: {symbol}ï¼Œæ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
            raise Exception(f"ä¸œæ–¹è´¢å¯Œä¸ªè‚¡æ–°é—»è·å–è¶…æ—¶ï¼ˆ30ç§’ï¼‰: {symbol}")
        elif exception[0]:
            # æœ‰å¼‚å¸¸
            elapsed_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] âŒ APIè°ƒç”¨å¼‚å¸¸: {exception[0]}ï¼Œæ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
            raise exception[0]
        else:
            # æˆåŠŸ
            news_df = result[0]

        if news_df is not None and not news_df.empty:
            news_count = len(news_df)
            elapsed_time = (datetime.now() - start_time).total_seconds()
            
            # è®°å½•ä¸€äº›æ–°é—»æ ‡é¢˜ç¤ºä¾‹
            sample_titles = [row.get('æ ‡é¢˜', 'æ— æ ‡é¢˜') for _, row in news_df.head(3).iterrows()]
            logger.info(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] æ–°é—»æ ‡é¢˜ç¤ºä¾‹: {', '.join(sample_titles)}")
            
            logger.info(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] âœ… è·å–æˆåŠŸ: {symbol}, å…±{news_count}æ¡è®°å½•ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            return news_df
        else:
            elapsed_time = (datetime.now() - start_time).total_seconds()
            logger.warning(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] âš ï¸ æ•°æ®ä¸ºç©º: {symbol}ï¼ŒAPIè¿”å›æˆåŠŸä½†æ— æ•°æ®ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            return pd.DataFrame()

    except Exception as e:
        elapsed_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"[ä¸œæ–¹è´¢å¯Œæ–°é—»] âŒ è·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}, è€—æ—¶: {elapsed_time:.2f}ç§’")
        return pd.DataFrame()
