#!/usr/bin/env python3
"""
æ‰¹é‡å¹¶è¡Œæ•°æ®æ›´æ–°ç®¡ç†å™¨
å®ç°æ™ºèƒ½æ´»è·ƒåº¦åˆ†ç±»é©±åŠ¨çš„æ‰¹é‡å¹¶è¡Œæ›´æ–°ç³»ç»Ÿ
"""

import asyncio
import concurrent.futures
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import threading
from dataclasses import dataclass
import json

import pandas as pd

from tradingagents.utils.logging_manager import get_logger
from tradingagents.analytics.stock_activity_classifier import get_activity_classifier
from tradingagents.dataflows.historical_data_manager import get_historical_manager
from tradingagents.dataflows.enhanced_data_manager import get_enhanced_data_manager

logger = get_logger('batch_update')


@dataclass
class UpdateTask:
    """æ›´æ–°ä»»åŠ¡æ•°æ®ç±»"""
    symbol: str
    classification: str
    priority: int
    last_update: Optional[datetime]
    estimated_duration: float
    update_frequency: str


class BatchUpdateManager:
    """æ‰¹é‡å¹¶è¡Œæ•°æ®æ›´æ–°ç®¡ç†å™¨"""
    
    def __init__(self, max_workers: int = 10):
        """åˆå§‹åŒ–æ‰¹é‡æ›´æ–°ç®¡ç†å™¨"""
        self.classifier = get_activity_classifier()
        self.historical_manager = get_historical_manager()
        self.data_manager = get_enhanced_data_manager()
        
        self.max_workers = max_workers
        self.update_stats = {
            'total_processed': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0
        }
        
        # æ›´æ–°é¢‘ç‡é…ç½®ï¼ˆå°æ—¶ï¼‰
        self.update_intervals = {
            'active': 24,      # æ´»è·ƒè‚¡ç¥¨ï¼šæ¯å¤©
            'normal': 168,     # æ™®é€šè‚¡ç¥¨ï¼šæ¯å‘¨
            'inactive': 720    # å†·é—¨è‚¡ç¥¨ï¼šæ¯æœˆ
        }
        
        # ä¼˜å…ˆçº§æƒé‡
        self.priority_weights = {
            'active': 100,
            'normal': 50,
            'inactive': 10
        }
        
        logger.info(f"ğŸš€ æ‰¹é‡æ›´æ–°ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å¹¶è¡Œæ•°ï¼š{max_workers}")
    
    def should_update(self, symbol: str, classification: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°"""
        try:
            availability = self.historical_manager.get_data_availability(symbol, "daily")
            
            if not availability['available']:
                return True
            
            last_update = datetime.fromisoformat(availability['last_updated'])
            hours_since_update = (datetime.now() - last_update).total_seconds() / 3600
            
            required_interval = self.update_intervals.get(classification, 168)
            
            return hours_since_update >= required_interval
            
        except Exception as e:
            logger.debug(f"åˆ¤æ–­{symbol}æ˜¯å¦éœ€è¦æ›´æ–°å¤±è´¥: {e}")
            return True
    
    def create_update_tasks(self, symbols: List[str]) -> List[UpdateTask]:
        """åˆ›å»ºæ›´æ–°ä»»åŠ¡åˆ—è¡¨"""
        logger.info(f"ğŸ“‹ ä¸º{len(symbols)}åªè‚¡ç¥¨åˆ›å»ºæ›´æ–°ä»»åŠ¡...")
        
        # æ‰¹é‡åˆ†ç±»è‚¡ç¥¨
        classifications = self.classifier.classify_stocks(symbols)
        
        tasks = []
        
        for classification, symbols_list in classifications.items():
            for symbol in symbols_list:
                if self.should_update(symbol, classification):
                    # è·å–æ›´æ–°é¢„ä¼°æ—¶é—´
                    estimated_time = self._estimate_update_time(symbol)
                    
                    # è·å–æœ€åæ›´æ–°æ—¶é—´
                    availability = self.historical_manager.get_data_availability(symbol, "daily")
                    last_update = None
                    if availability['available']:
                        last_update = datetime.fromisoformat(availability['last_updated'])
                    
                    task = UpdateTask(
                        symbol=symbol,
                        classification=classification,
                        priority=self.priority_weights.get(classification, 50),
                        last_update=last_update,
                        estimated_duration=estimated_time,
                        update_frequency=self.update_intervals.get(classification, 168)
                    )
                    tasks.append(task)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        tasks.sort(key=lambda x: (-x.priority, x.estimated_duration))
        
        logger.info(f"ğŸ“Š åˆ›å»ºæ›´æ–°ä»»åŠ¡ï¼š{len(tasks)}ä¸ªï¼Œè·³è¿‡{len(symbols) - len(tasks)}ä¸ª")
        return tasks
    
    def _estimate_update_time(self, symbol: str) -> float:
        """ä¼°ç®—å•ä¸ªè‚¡ç¥¨æ›´æ–°æ—¶é—´"""
        # åŸºäºå†å²ç»éªŒä¼°ç®—
        try:
            # æ£€æŸ¥ç°æœ‰æ•°æ®é‡
            availability = self.historical_manager.get_data_availability(symbol, "daily")
            
            if not availability['available']:
                return 5.0  # å…¨é‡æ›´æ–°çº¦5ç§’
            
            # è®¡ç®—ç¼ºå¤±å¤©æ•°
            missing_ranges = self.historical_manager.get_missing_date_ranges(
                symbol, "daily", 
                start_date=availability['end_date'],
                end_date=datetime.now().strftime('%Y-%m-%d')
            )
            
            if not missing_ranges:
                return 0.5  # åªéœ€æ£€æŸ¥ï¼Œ0.5ç§’
            
            # ä¼°ç®—ç¼ºå¤±å¤©æ•°
            total_missing_days = 0
            for range_info in missing_ranges:
                start = datetime.strptime(range_info['start'], '%Y-%m-%d')
                end = datetime.strptime(range_info['end'], '%Y-%m-%d')
                total_missing_days += (end - start).days + 1
            
            # æ¯ç¼ºå¤±ä¸€å¤©çº¦0.5ç§’
            return max(0.5, min(5.0, total_missing_days * 0.5))
            
        except Exception:
            return 2.0  # é»˜è®¤2ç§’
    
    def update_single_stock(self, symbol: str, classification: str) -> bool:
        """æ›´æ–°å•ä¸ªè‚¡ç¥¨æ•°æ®"""
        try:
            logger.info(f"ğŸ”„ æ›´æ–°{symbol}({classification})...")
            
            # ç¡®å®šæ›´æ–°èŒƒå›´
            availability = self.historical_manager.get_data_availability(symbol, "daily")
            
            if availability['available']:
                start_date = (datetime.strptime(availability['end_date'], '%Y-%m-%d') + 
                             timedelta(days=1)).strftime('%Y-%m-%d')
            else:
                start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
            
            end_date = datetime.now().strftime('%Y-%m-%d')
            
            # è·å–æœ€æ–°æ•°æ®
            new_data = self.data_manager.get_historical_data(
                symbol, start_date, end_date, "daily"
            )
            
            if new_data is not None and not new_data.empty:
                # ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨
                success = self.historical_manager.save_historical_data(
                    symbol, new_data, "daily"
                )
                
                if success:
                    logger.info(f"âœ… {symbol}æ›´æ–°å®Œæˆï¼š{len(new_data)}æ¡è®°å½•")
                    return True
                else:
                    logger.error(f"âŒ {symbol}ä¿å­˜å¤±è´¥")
                    return False
            else:
                logger.info(f"â„¹ï¸ {symbol}æ— æ–°æ•°æ®éœ€è¦æ›´æ–°")
                return True
                
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°{symbol}å¤±è´¥: {e}")
            return False
    
    def update_batch_parallel(self, tasks: List[UpdateTask]) -> Dict[str, int]:
        """å¹¶è¡Œæ‰¹é‡æ›´æ–°"""
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œæ›´æ–°{len(tasks)}ä¸ªä»»åŠ¡...")
        
        stats = {
            'total': len(tasks),
            'successful': 0,
            'failed': 0,
            'skipped': 0
        }
        
        # æŒ‰æ‰¹æ¬¡å¤„ç†
        batch_size = min(self.max_workers, len(tasks))
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=batch_size) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(self.update_single_stock, task.symbol, task.classification): task
                for task in tasks
            }
            
            # å¤„ç†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    success = future.result()
                    if success:
                        stats['successful'] += 1
                    else:
                        stats['failed'] += 1
                except Exception as e:
                    logger.error(f"âŒ {task.symbol}å¤„ç†å¼‚å¸¸: {e}")
                    stats['failed'] += 1
        
        logger.info(f"ğŸ“Š æ‰¹é‡æ›´æ–°å®Œæˆï¼šæˆåŠŸ{stats['successful']}ä¸ªï¼Œå¤±è´¥{stats['failed']}ä¸ª")
        return stats
    
    def smart_batch_update(self, symbols: List[str], force_update: bool = False) -> Dict[str, Any]:
        """
        æ™ºèƒ½æ‰¹é‡æ›´æ–°ä¸»å‡½æ•°
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°æ‰€æœ‰è‚¡ç¥¨
            
        Returns:
            æ›´æ–°ç»Ÿè®¡ç»“æœ
        """
        start_time = time.time()
        logger.info(f"ğŸ¯ å¼€å§‹æ™ºèƒ½æ‰¹é‡æ›´æ–°ï¼Œå…±{len(symbols)}åªè‚¡ç¥¨...")
        
        # åˆ›å»ºæ›´æ–°ä»»åŠ¡
        if force_update:
            # å¼ºåˆ¶æ›´æ–°æ‰€æœ‰è‚¡ç¥¨
            tasks = []
            for symbol in symbols:
                task = UpdateTask(
                    symbol=symbol,
                    classification='normal',  # é»˜è®¤åˆ†ç±»
                    priority=50,
                    last_update=None,
                    estimated_duration=2.0,
                    update_frequency=168
                )
                tasks.append(task)
        else:
            # æ™ºèƒ½é€‰æ‹©éœ€è¦æ›´æ–°çš„è‚¡ç¥¨
            tasks = self.create_update_tasks(symbols)
        
        if not tasks:
            logger.info("â„¹ï¸ æ²¡æœ‰éœ€è¦æ›´æ–°çš„è‚¡ç¥¨")
            return {
                'total_symbols': len(symbols),
                'updated_symbols': 0,
                'skipped_symbols': len(symbols),
                'successful': 0,
                'failed': 0,
                'duration': 0
            }
        
        # æ‰§è¡Œå¹¶è¡Œæ›´æ–°
        stats = self.update_batch_parallel(tasks)
        
        # è®¡ç®—åˆ†ç±»ç»Ÿè®¡
        classifications = self.classifier.classify_stocks([task.symbol for task in tasks])
        
        duration = time.time() - start_time
        result = {
            'total_symbols': len(symbols),
            'updated_symbols': len(tasks),
            'skipped_symbols': len(symbols) - len(tasks),
            'successful': stats['successful'],
            'failed': stats['failed'],
            'duration': round(duration, 2),
            'classifications': {
                'active': len(classifications.get('active', [])),
                'normal': len(classifications.get('normal', [])),
                'inactive': len(classifications.get('inactive', []))
            },
            'throughput': round(len(tasks) / duration, 2) if duration > 0 else 0
        }
        
        logger.info(f"ğŸ‰ æ™ºèƒ½æ‰¹é‡æ›´æ–°å®Œæˆï¼š{result}")
        return result
    
    def estimate_update_time(self, symbols: List[str]) -> Dict[str, float]:
        """é¢„ä¼°æ›´æ–°æ—¶é—´"""
        tasks = self.create_update_tasks(symbols)
        
        total_time = sum(task.estimated_duration for task in tasks)
        
        # è€ƒè™‘å¹¶è¡Œæ•ˆç‡
        parallel_time = total_time / min(self.max_workers, len(tasks)) if tasks else 0
        
        return {
            'total_tasks': len(tasks),
            'total_estimate': round(total_time, 2),
            'parallel_estimate': round(parallel_time, 2),
            'max_workers': self.max_workers
        }


# å…¨å±€å®ä¾‹
_batch_manager = None


def get_batch_update_manager(max_workers: int = 10) -> BatchUpdateManager:
    """è·å–æ‰¹é‡æ›´æ–°ç®¡ç†å™¨å®ä¾‹"""
    global _batch_manager
    if _batch_manager is None:
        _batch_manager = BatchUpdateManager(max_workers)
    return _batch_manager


def batch_update_stocks(symbols: List[str], force_update: bool = False, max_workers: int = 10) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šæ‰¹é‡æ›´æ–°è‚¡ç¥¨"""
    manager = get_batch_update_manager(max_workers)
    return manager.smart_batch_update(symbols, force_update)


def estimate_batch_time(symbols: List[str], max_workers: int = 10) -> Dict[str, float]:
    """ä¾¿æ·å‡½æ•°ï¼šé¢„ä¼°æ›´æ–°æ—¶é—´"""
    manager = get_batch_update_manager(max_workers)
    return manager.estimate_update_time(symbols)