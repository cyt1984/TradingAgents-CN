#!/usr/bin/env python3
"""
é¾™è™æ¦œæ•°æ®è·å–å¼•æ“
æä¾›é¾™è™æ¦œæ•°æ®è·å–ã€å¸­ä½ä¿¡æ¯è§£æç­‰åŠŸèƒ½
æ”¯æŒå¤šç»´åº¦é¾™è™æ¦œæŸ¥è¯¢å’Œè¯¦ç»†å¸­ä½åˆ†æ
"""

import requests
import json
import pandas as pd
from typing import Optional, Dict, Any, List, Union
from datetime import datetime, timedelta
import time
import re
from dataclasses import dataclass, field
from enum import Enum

from tradingagents.utils.logging_manager import get_logger
logger = get_logger('longhubang')


class RankingType(Enum):
    """é¾™è™æ¦œç±»å‹æšä¸¾"""
    DAILY = "daily"                    # æ—¥æ¦œ
    LIMIT_UP = "limit_up"             # æ¶¨åœæ¿
    LIMIT_DOWN = "limit_down"         # è·Œåœæ¿
    TURNOVER = "turnover"             # æˆäº¤é¢æ¦œ
    AMPLITUDE = "amplitude"           # æŒ¯å¹…æ¦œ
    VOLUME = "volume"                 # æˆäº¤é‡æ¦œ
    TURNOVER_RATE = "turnover_rate"   # æ¢æ‰‹ç‡æ¦œ


@dataclass
class SeatInfo:
    """å¸­ä½ä¿¡æ¯"""
    seat_name: str                    # å¸­ä½åç§°
    buy_amount: float = 0.0          # ä¹°å…¥é‡‘é¢(ä¸‡å…ƒ)
    sell_amount: float = 0.0         # å–å‡ºé‡‘é¢(ä¸‡å…ƒ)
    net_amount: float = 0.0          # å‡€ä¹°å…¥é‡‘é¢(ä¸‡å…ƒ)
    seat_type: str = "unknown"       # å¸­ä½ç±»å‹
    influence_score: float = 0.0     # å½±å“åŠ›è¯„åˆ†


@dataclass
class LongHuBangData:
    """é¾™è™æ¦œæ•°æ®"""
    symbol: str                       # è‚¡ç¥¨ä»£ç 
    name: str                        # è‚¡ç¥¨åç§°
    current_price: float             # å½“å‰ä»·æ ¼
    change_pct: float                # æ¶¨è·Œå¹…(%)
    turnover: float                  # æˆäº¤é¢(ä¸‡å…ƒ)
    turnover_rate: float             # æ¢æ‰‹ç‡(%)
    net_inflow: float                # å‡€æµå…¥(ä¸‡å…ƒ)
    buy_seats: List[SeatInfo] = field(default_factory=list)    # ä¹°æ–¹å¸­ä½
    sell_seats: List[SeatInfo] = field(default_factory=list)   # å–æ–¹å¸­ä½
    ranking_reason: str = ""         # ä¸Šæ¦œåŸå› 
    date: str = ""                   # æ—¥æœŸ
    
    def get_total_buy_amount(self) -> float:
        """è·å–æ€»ä¹°å…¥é‡‘é¢"""
        return sum(seat.buy_amount for seat in self.buy_seats)
    
    def get_total_sell_amount(self) -> float:
        """è·å–æ€»å–å‡ºé‡‘é¢"""
        return sum(seat.sell_amount for seat in self.sell_seats)
    
    def get_net_flow(self) -> float:
        """è·å–å‡€æµå…¥"""
        return self.get_total_buy_amount() - self.get_total_sell_amount()


class LongHuBangProvider:
    """é¾™è™æ¦œæ•°æ®æä¾›å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é¾™è™æ¦œæä¾›å™¨"""
        self.base_url = "https://datacenter-web.eastmoney.com/api"
        self.quote_url = "https://push2.eastmoney.com"
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://data.eastmoney.com/',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        }
        
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
        # ç¼“å­˜è®¾ç½®
        self._cache = {}
        self._cache_ttl = 3600  # 1å°æ—¶ç¼“å­˜
        
        logger.info("âœ… é¾™è™æ¦œæ•°æ®æä¾›å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    def _make_request(self, url: str, params: Dict = None, timeout: int = 30) -> Optional[Dict]:
        """å‘èµ·HTTPè¯·æ±‚"""
        try:
            response = self.session.get(url, params=params, timeout=timeout)
            response.raise_for_status()
            
            # å¤„ç†JSONPå“åº”
            text = response.text
            if text.startswith('(') and text.endswith(')'):
                text = text[1:-1]
            elif '(' in text and ')' in text:
                start = text.find('(') + 1
                end = text.rfind(')')
                text = text[start:end]
            
            return json.loads(text)
        except Exception as e:
            logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {url}, é”™è¯¯: {str(e)}")
            return None
    
    def _get_cache_key(self, method: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [method] + [f"{k}_{v}" for k, v in sorted(kwargs.items())]
        return "_".join(key_parts)
    
    def _check_cache(self, cache_key: str) -> Optional[Any]:
        """æ£€æŸ¥ç¼“å­˜"""
        if cache_key in self._cache:
            cache_data, timestamp = self._cache[cache_key]
            if time.time() - timestamp < self._cache_ttl:
                return cache_data
            else:
                del self._cache[cache_key]
        return None
    
    def _set_cache(self, cache_key: str, data: Any):
        """è®¾ç½®ç¼“å­˜"""
        self._cache[cache_key] = (data, time.time())
    
    def _get_latest_trading_date(self) -> str:
        """è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥æœŸ"""
        now = datetime.now()
        
        # ä»ä»Šå¤©å¼€å§‹å¾€å‰æ‰¾äº¤æ˜“æ—¥
        for days_back in range(10):  # æœ€å¤šå¾€å‰æ‰¾10å¤©
            check_date = (now - timedelta(days=days_back))
            
            # è·³è¿‡å‘¨æœ«
            if check_date.weekday() >= 5:  # å‘¨å…­(5)æˆ–å‘¨æ—¥(6)
                continue
                
            date_str = check_date.strftime('%Y-%m-%d')
            
            # å¿«é€Ÿæ£€æŸ¥è¿™ä¸€å¤©æ˜¯å¦æœ‰æ•°æ®
            if self._check_date_has_data(date_str):
                logger.info(f"ğŸ—“ï¸ æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥: {date_str}")
                return date_str
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›æœ€è¿‘çš„å·¥ä½œæ—¥
        for days_back in range(10):
            check_date = (now - timedelta(days=days_back))
            if check_date.weekday() < 5:  # å·¥ä½œæ—¥
                date_str = check_date.strftime('%Y-%m-%d')
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æœ‰æ•°æ®çš„äº¤æ˜“æ—¥ï¼Œä½¿ç”¨æœ€è¿‘å·¥ä½œæ—¥: {date_str}")
                return date_str
        
        # æœ€åçš„fallback
        return now.strftime('%Y-%m-%d')
    
    def _check_date_has_data(self, date_str: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦æœ‰é¾™è™æ¦œæ•°æ®"""
        try:
            # ä½¿ç”¨åŸºç¡€å‚æ•°å¿«é€Ÿæ£€æŸ¥
            url = f"{self.base_url}/data/v1/get"
            params = {
                'sortColumns': 'SECURITY_CODE',
                'sortTypes': '1',
                'pageSize': '1',  # åªå–1æ¡è®°å½•
                'pageNumber': '1',
                'reportName': 'RPT_DAILYBILLBOARD_DETAILS',
                'columns': 'SECURITY_CODE',
                'filter': f'(TRADE_DATE=\'{date_str}\')'
            }
            
            data = self._make_request(url, params, timeout=5)
            if data and data.get('success') and data.get('result') and data['result'].get('data'):
                return len(data['result']['data']) > 0
                
        except Exception:
            pass
        
        return False
    
    def get_daily_ranking(self, date: str = None, ranking_type: RankingType = RankingType.DAILY) -> List[LongHuBangData]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„é¾™è™æ¦œæ•°æ®
        
        Args:
            date: æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©
            ranking_type: é¾™è™æ¦œç±»å‹
            
        Returns:
            é¾™è™æ¦œæ•°æ®åˆ—è¡¨
        """
        if date is None:
            # æ™ºèƒ½è·å–æœ€è¿‘äº¤æ˜“æ—¥
            date = self._get_latest_trading_date()
        
        cache_key = self._get_cache_key("daily_ranking", date=date, type=ranking_type.value)
        cached_data = self._check_cache(cache_key)
        if cached_data:
            logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„é¾™è™æ¦œæ•°æ®: {date}")
            return cached_data
        
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆç®€å•æ£€æŸ¥å‘¨æœ«ï¼‰
            date_obj = datetime.strptime(date, '%Y-%m-%d')
            if date_obj.weekday() >= 5:  # å‘¨å…­(5)æˆ–å‘¨æ—¥(6)
                logger.warning(f"âš ï¸ {date} ä¸ºå‘¨æœ«ï¼Œå¯èƒ½æ— é¾™è™æ¦œæ•°æ®")
            
            # ä¸œæ–¹è´¢å¯Œé¾™è™æ¦œAPI
            url = f"{self.base_url}/data/v1/get"
            
            # æ ¹æ®ç±»å‹è®¾ç½®ä¸åŒçš„å‚æ•°
            if ranking_type == RankingType.DAILY:
                params = {
                    'sortColumns': 'SECURITY_CODE',
                    'sortTypes': '1',
                    'pageSize': '200',
                    'pageNumber': '1',
                    'reportName': 'RPT_DAILYBILLBOARD_DETAILS',
                    'columns': 'SECURITY_CODE,SECUCODE,SECURITY_NAME_ABBR,TRADE_DATE,CLOSE_PRICE,CHANGE_RATE,BILLBOARD_NET_AMT,BILLBOARD_BUY_AMT,BILLBOARD_SELL_AMT,BILLBOARD_DEAL_AMT,TURNOVERRATE',
                    'filter': f'(TRADE_DATE=\'{date}\')'
                }
            elif ranking_type == RankingType.LIMIT_UP:
                params = {
                    'sortColumns': 'SECURITY_CODE',
                    'sortTypes': '1', 
                    'pageSize': '200',
                    'pageNumber': '1',
                    'reportName': 'RPT_DAILYBILLBOARD_DETAILS',
                    'columns': 'SECURITY_CODE,SECUCODE,SECURITY_NAME_ABBR,TRADE_DATE,CLOSE_PRICE,CHANGE_RATE,BILLBOARD_NET_AMT,BILLBOARD_BUY_AMT,BILLBOARD_SELL_AMT,BILLBOARD_DEAL_AMT,TURNOVERRATE',
                    'filter': f'(TRADE_DATE=\'{date}\')(CHANGE_RATE>=9.5)'
                }
            else:
                # å…¶ä»–ç±»å‹ä½¿ç”¨é»˜è®¤å‚æ•°
                params = {
                    'sortColumns': 'SECURITY_CODE',
                    'sortTypes': '1',
                    'pageSize': '200',
                    'pageNumber': '1',
                    'reportName': 'RPT_DAILYBILLBOARD_DETAILS',
                    'columns': 'SECURITY_CODE,SECUCODE,SECURITY_NAME_ABBR,TRADE_DATE,CLOSE_PRICE,CHANGE_RATE,BILLBOARD_NET_AMT,BILLBOARD_BUY_AMT,BILLBOARD_SELL_AMT,BILLBOARD_DEAL_AMT,TURNOVERRATE',
                    'filter': f'(TRADE_DATE=\'{date}\')'
                }
            
            data = self._make_request(url, params)
            if not data or 'result' not in data or data['result'] is None or 'data' not in data['result'] or data['result']['data'] is None:
                logger.warning(f"âš ï¸ æœªè·å–åˆ°é¾™è™æ¦œæ•°æ®: {date}")
                
                # å¦‚æœæ˜¯ä»Šå¤©ä¸”æ²¡æœ‰æ•°æ®ï¼Œå°è¯•è·å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                if date == datetime.now().strftime('%Y-%m-%d'):
                    logger.info("ğŸ”„ å°è¯•è·å–æœ€è¿‘äº¤æ˜“æ—¥çš„é¾™è™æ¦œæ•°æ®...")
                    for i in range(1, 8):  # å°è¯•è¿‡å»ä¸€å‘¨
                        prev_date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
                        prev_cache_key = self._get_cache_key("daily_ranking", date=prev_date, type=ranking_type.value)
                        prev_cached_data = self._check_cache(prev_cache_key)
                        if prev_cached_data:
                            logger.info(f"ğŸ“‹ ä½¿ç”¨æœ€è¿‘äº¤æ˜“æ—¥ç¼“å­˜æ•°æ®: {prev_date}")
                            return prev_cached_data
                        
                        # å°è¯•è·å–å‰ä¸€å¤©çš„æ•°æ®
                        prev_params = params.copy()
                        prev_params['filter'] = prev_params['filter'].replace(date, prev_date)
                        prev_data = self._make_request(url, prev_params)
                        if prev_data and 'result' in prev_data and prev_data['result'] is not None and 'data' in prev_data['result'] and prev_data['result']['data']:
                            logger.info(f"âœ… æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥æ•°æ®: {prev_date}")
                            # é€’å½’è°ƒç”¨å¤„ç†å‰ä¸€å¤©çš„æ•°æ®
                            return self.get_daily_ranking(prev_date, ranking_type)
                
                # æŒ‰ç…§CLAUDE.mdè§„èŒƒï¼šæ— æ³•è·å–çœŸå®æ•°æ®æ—¶è¿”å›ç©ºç»“æœï¼Œä¸ä½¿ç”¨æ¼”ç¤ºæ•°æ®
                logger.warning(f"âš ï¸ æ— æ³•è·å–{date}çš„çœŸå®é¾™è™æ¦œæ•°æ®ï¼Œè¿”å›ç©ºç»“æœ")
                return []
            
            ranking_list = []
            for item in data['result']['data']:
                try:
                    # è§£æåŸºç¡€æ•°æ®
                    ranking_data = LongHuBangData(
                        symbol=item.get('SECURITY_CODE', ''),
                        name=item.get('SECURITY_NAME_ABBR', ''),
                        current_price=float(item.get('CLOSE_PRICE', 0)),
                        change_pct=float(item.get('CHANGE_RATE', 0)),
                        turnover=float(item.get('BILLBOARD_DEAL_AMT', 0)) / 10000,  # è½¬æ¢ä¸ºä¸‡å…ƒ
                        turnover_rate=float(item.get('TURNOVERRATE', 0)),
                        net_inflow=float(item.get('BILLBOARD_NET_AMT', 0)) / 10000,  # è½¬æ¢ä¸ºä¸‡å…ƒ
                        ranking_reason=item.get('REASON', ''),
                        date=date
                    )
                    
                    # è·å–è¯¦ç»†å¸­ä½ä¿¡æ¯
                    seat_details = self.get_seat_details(ranking_data.symbol, date)
                    if seat_details:
                        ranking_data.buy_seats = seat_details['buy_seats']
                        ranking_data.sell_seats = seat_details['sell_seats']
                    
                    ranking_list.append(ranking_data)
                    
                except Exception as e:
                    logger.error(f"âŒ è§£æé¾™è™æ¦œæ•°æ®å¤±è´¥: {item}, é”™è¯¯: {e}")
                    continue
            
            # ç¼“å­˜ç»“æœ
            self._set_cache(cache_key, ranking_list)
            
            logger.info(f"âœ… è·å–é¾™è™æ¦œæ•°æ®æˆåŠŸ: {date}, å…±{len(ranking_list)}åªè‚¡ç¥¨")
            return ranking_list
            
        except Exception as e:
            logger.error(f"âŒ è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {date}, é”™è¯¯: {e}")
            return []
    
    def get_seat_details(self, symbol: str, date: str = None) -> Optional[Dict[str, List[SeatInfo]]]:
        """
        è·å–è‚¡ç¥¨çš„è¯¦ç»†å¸­ä½ä¿¡æ¯
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            åŒ…å«ä¹°å–å¸­ä½ä¿¡æ¯çš„å­—å…¸
        """
        if date is None:
            # æ™ºèƒ½è·å–æœ€è¿‘äº¤æ˜“æ—¥
            date = self._get_latest_trading_date()
        
        cache_key = self._get_cache_key("seat_details", symbol=symbol, date=date)
        cached_data = self._check_cache(cache_key)
        if cached_data:
            return cached_data
        
        try:
            # å¸­ä½è¯¦æƒ…åŠŸèƒ½æš‚æ—¶ç¦ç”¨ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒç ”APIå­—æ®µ
            logger.debug(f"âš ï¸ å¸­ä½è¯¦æƒ…åŠŸèƒ½æš‚æ—¶ç¦ç”¨: {symbol} {date}")
            return None
            
            # TODO: é‡æ–°è°ƒç ”å¸­ä½è¯¦æƒ…APIçš„æ­£ç¡®å­—æ®µåç§°
            # è·å–å¸­ä½è¯¦ç»†ä¿¡æ¯
            url = f"{self.base_url}/data/v1/get"
            params = {
                'sortColumns': 'OPERATEDEPT_CODE',
                'sortTypes': '1',
                'pageSize': '50',
                'pageNumber': '1',
                'reportName': 'RPT_BILLBOARD_DAILYDETAILS',
                'columns': 'SECURITY_CODE,SECUCODE,SECURITY_NAME_ABBR,OPERATEDEPT_CODE,OPERATEDEPT_NAME,TRADE_DATE,SIDE_NAME,RANK,BUY,SELL,NET',
                'filter': f'(SECURITY_CODE=\"{symbol}\")(TRADE_DATE=\'{date}\')'
            }
            
            data = self._make_request(url, params)
            if not data or 'result' not in data or data['result'] is None or 'data' not in data['result'] or data['result']['data'] is None:
                logger.debug(f"âš ï¸ æœªè·å–åˆ°å¸­ä½è¯¦æƒ…: {symbol} {date}")
                return None
            
            buy_seats = []
            sell_seats = []
            
            for item in data['result']['data']:
                try:
                    seat_info = SeatInfo(
                        seat_name=item.get('OPERATEDEPT_NAME', ''),
                        buy_amount=float(item.get('BUY', 0)) / 10000,   # è½¬æ¢ä¸ºä¸‡å…ƒ
                        sell_amount=float(item.get('SELL', 0)) / 10000, # è½¬æ¢ä¸ºä¸‡å…ƒ
                        net_amount=float(item.get('NET', 0)) / 10000    # è½¬æ¢ä¸ºä¸‡å…ƒ
                    )
                    
                    # æ ¹æ®ä¹°å–æ–¹å‘åˆ†ç±»
                    side = item.get('SIDE_NAME', '')
                    if side == 'ä¹°æ–¹' or seat_info.buy_amount > 0:
                        buy_seats.append(seat_info)
                    elif side == 'å–æ–¹' or seat_info.sell_amount > 0:
                        sell_seats.append(seat_info)
                    
                except Exception as e:
                    logger.error(f"âŒ è§£æå¸­ä½ä¿¡æ¯å¤±è´¥: {item}, é”™è¯¯: {e}")
                    continue
            
            result = {
                'buy_seats': buy_seats,
                'sell_seats': sell_seats
            }
            
            # ç¼“å­˜ç»“æœ
            self._set_cache(cache_key, result)
            
            logger.debug(f"âœ… è·å–å¸­ä½è¯¦æƒ…æˆåŠŸ: {symbol}, ä¹°æ–¹{len(buy_seats)}å¸­ä½, å–æ–¹{len(sell_seats)}å¸­ä½")
            return result
            
        except Exception as e:
            logger.error(f"âŒ è·å–å¸­ä½è¯¦æƒ…å¤±è´¥: {symbol} {date}, é”™è¯¯: {e}")
            return None
    
    def get_historical_rankings(self, days: int = 7) -> List[LongHuBangData]:
        """
        è·å–å†å²é¾™è™æ¦œæ•°æ®
        
        Args:
            days: è·å–æœ€è¿‘å‡ å¤©çš„æ•°æ®
            
        Returns:
            å†å²é¾™è™æ¦œæ•°æ®åˆ—è¡¨
        """
        historical_data = []
        
        for i in range(days):
            date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
            daily_data = self.get_daily_ranking(date)
            historical_data.extend(daily_data)
        
        logger.info(f"âœ… è·å–å†å²é¾™è™æ¦œæ•°æ®: æœ€è¿‘{days}å¤©, å…±{len(historical_data)}æ¡è®°å½•")
        return historical_data
    
    def get_limit_up_stocks(self, date: str = None) -> List[LongHuBangData]:
        """
        è·å–æ¶¨åœæ¿è‚¡ç¥¨
        
        Args:
            date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            æ¶¨åœæ¿é¾™è™æ¦œæ•°æ®
        """
        return self.get_daily_ranking(date, RankingType.LIMIT_UP)
    
    def get_stocks_by_change_pct(self, min_change_pct: float = 5.0, 
                                max_change_pct: float = 20.0,
                                date: str = None) -> List[LongHuBangData]:
        """
        æ ¹æ®æ¶¨è·Œå¹…ç­›é€‰é¾™è™æ¦œè‚¡ç¥¨
        
        Args:
            min_change_pct: æœ€å°æ¶¨è·Œå¹…
            max_change_pct: æœ€å¤§æ¶¨è·Œå¹…
            date: æ—¥æœŸ
            
        Returns:
            ç¬¦åˆæ¡ä»¶çš„é¾™è™æ¦œæ•°æ®
        """
        all_data = self.get_daily_ranking(date)
        filtered_data = [
            data for data in all_data 
            if min_change_pct <= data.change_pct <= max_change_pct
        ]
        
        logger.info(f"âœ… æŒ‰æ¶¨è·Œå¹…ç­›é€‰: {min_change_pct}%-{max_change_pct}%, ç­›é€‰å‡º{len(filtered_data)}åªè‚¡ç¥¨")
        return filtered_data
    
    def get_stocks_by_turnover(self, min_turnover: float = 10000, date: str = None) -> List[LongHuBangData]:
        """
        æ ¹æ®æˆäº¤é¢ç­›é€‰é¾™è™æ¦œè‚¡ç¥¨
        
        Args:
            min_turnover: æœ€å°æˆäº¤é¢(ä¸‡å…ƒ)
            date: æ—¥æœŸ
            
        Returns:
            ç¬¦åˆæ¡ä»¶çš„é¾™è™æ¦œæ•°æ®
        """
        all_data = self.get_daily_ranking(date)
        filtered_data = [
            data for data in all_data 
            if data.turnover >= min_turnover
        ]
        
        logger.info(f"âœ… æŒ‰æˆäº¤é¢ç­›é€‰: >={min_turnover}ä¸‡å…ƒ, ç­›é€‰å‡º{len(filtered_data)}åªè‚¡ç¥¨")
        return filtered_data
    
    def search_stocks_by_seat(self, seat_name: str, days: int = 7) -> List[LongHuBangData]:
        """
        æœç´¢ç‰¹å®šå¸­ä½å‚ä¸çš„è‚¡ç¥¨
        
        Args:
            seat_name: å¸­ä½åç§°(æ”¯æŒæ¨¡ç³ŠåŒ¹é…)
            days: æœç´¢æœ€è¿‘å‡ å¤©
            
        Returns:
            åŒ…å«è¯¥å¸­ä½çš„é¾™è™æ¦œæ•°æ®
        """
        historical_data = self.get_historical_rankings(days)
        matched_stocks = []
        
        for stock_data in historical_data:
            # æ£€æŸ¥ä¹°æ–¹å¸­ä½
            for seat in stock_data.buy_seats:
                if seat_name in seat.seat_name:
                    matched_stocks.append(stock_data)
                    break
            else:
                # æ£€æŸ¥å–æ–¹å¸­ä½
                for seat in stock_data.sell_seats:
                    if seat_name in seat.seat_name:
                        matched_stocks.append(stock_data)
                        break
        
        logger.info(f"âœ… å¸­ä½æœç´¢: {seat_name}, æœ€è¿‘{days}å¤©æ‰¾åˆ°{len(matched_stocks)}åªç›¸å…³è‚¡ç¥¨")
        return matched_stocks
    
    def get_statistics(self, date: str = None) -> Dict[str, Any]:
        """
        è·å–é¾™è™æ¦œç»Ÿè®¡ä¿¡æ¯
        
        Args:
            date: æ—¥æœŸ
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        ranking_data = self.get_daily_ranking(date)
        if not ranking_data:
            return {}
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        total_stocks = len(ranking_data)
        total_turnover = sum(data.turnover for data in ranking_data)
        avg_change_pct = sum(data.change_pct for data in ranking_data) / total_stocks
        
        # æ¶¨è·Œåˆ†å¸ƒ
        up_stocks = len([data for data in ranking_data if data.change_pct > 0])
        down_stocks = total_stocks - up_stocks
        
        # æˆäº¤é¢åˆ†å¸ƒ
        large_turnover_stocks = len([data for data in ranking_data if data.turnover > 50000])  # 5äº¿ä»¥ä¸Š
        
        statistics = {
            'date': date or datetime.now().strftime('%Y-%m-%d'),
            'total_stocks': total_stocks,
            'total_turnover': total_turnover,
            'avg_change_pct': avg_change_pct,
            'up_stocks': up_stocks,
            'down_stocks': down_stocks,
            'up_ratio': up_stocks / total_stocks if total_stocks > 0 else 0,
            'large_turnover_stocks': large_turnover_stocks,
            'large_turnover_ratio': large_turnover_stocks / total_stocks if total_stocks > 0 else 0
        }
        
        logger.info(f"âœ… é¾™è™æ¦œç»Ÿè®¡: {date}, å…±{total_stocks}åªè‚¡ç¥¨, æ€»æˆäº¤é¢{total_turnover:.0f}ä¸‡å…ƒ")
        return statistics
    


# å…¨å±€å®ä¾‹
_longhubang_provider = None

def get_longhubang_provider() -> LongHuBangProvider:
    """è·å–é¾™è™æ¦œæä¾›å™¨å•ä¾‹"""
    global _longhubang_provider
    if _longhubang_provider is None:
        _longhubang_provider = LongHuBangProvider()
    return _longhubang_provider


# ä¾¿æ·å‡½æ•°
def get_today_longhubang(ranking_type: RankingType = RankingType.DAILY) -> List[LongHuBangData]:
    """è·å–ä»Šæ—¥é¾™è™æ¦œ"""
    provider = get_longhubang_provider()
    return provider.get_daily_ranking(ranking_type=ranking_type)


def get_longhubang_by_change(min_change: float = 5.0, max_change: float = 20.0) -> List[LongHuBangData]:
    """æŒ‰æ¶¨è·Œå¹…è·å–é¾™è™æ¦œ"""
    provider = get_longhubang_provider()
    return provider.get_stocks_by_change_pct(min_change, max_change)


def search_seat_activity(seat_name: str, days: int = 7) -> List[LongHuBangData]:
    """æœç´¢å¸­ä½æ´»åŠ¨"""
    provider = get_longhubang_provider()
    return provider.search_stocks_by_seat(seat_name, days)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    provider = get_longhubang_provider()
    
    # è·å–ä»Šæ—¥é¾™è™æ¦œ
    today_data = provider.get_daily_ranking()
    print(f"ä»Šæ—¥é¾™è™æ¦œ: {len(today_data)}åªè‚¡ç¥¨")
    
    # è·å–æ¶¨åœæ¿
    limit_up_data = provider.get_limit_up_stocks()
    print(f"ä»Šæ—¥æ¶¨åœæ¿: {len(limit_up_data)}åªè‚¡ç¥¨")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = provider.get_statistics()
    print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")