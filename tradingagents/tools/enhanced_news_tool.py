#!/usr/bin/env python3
"""
å¢å¼ºæ–°é—»å·¥å…·
é›†æˆå¤šä¸ªæ–°é—»æ•°æ®æºï¼Œæä¾›æ›´ä¸°å¯Œçš„æ–°é—»æ•°æ®
"""

from langchain_core.tools import tool
from typing import Dict, Any, List
import json
from datetime import datetime

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')

# å¯¼å…¥å¢å¼ºæ•°æ®æºç®¡ç†å™¨
from tradingagents.dataflows.enhanced_data_manager import get_enhanced_data_manager

# å¯¼å…¥è‚¡ç¥¨å·¥å…·ç±»
from tradingagents.utils.stock_utils import StockUtils


@tool
def get_enhanced_stock_news(ticker: str, limit: int = 30) -> str:
    """
    è·å–è‚¡ç¥¨çš„å¢å¼ºæ–°é—»æ•°æ®ï¼Œæ•´åˆå¤šä¸ªæ–°é—»æº
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001, AAPL, 0700.HKï¼‰
        limit: è¿”å›æ–°é—»æ•°é‡é™åˆ¶ï¼Œé»˜è®¤30æ¡
    
    Returns:
        str: æ ¼å¼åŒ–çš„æ–°é—»åˆ†ææ•°æ®ï¼ŒåŒ…å«å¤šæ•°æ®æºæ•´åˆçš„æ–°é—»ä¿¡æ¯
    """
    try:
        logger.info(f"ğŸ” å¼€å§‹è·å–å¢å¼ºæ–°é—»æ•°æ®: {ticker}")
        
        # è·å–å¸‚åœºä¿¡æ¯
        market_info = StockUtils.get_market_info(ticker)
        market_name = market_info['market_name']
        
        logger.info(f"ğŸ“Š è‚¡ç¥¨ç±»å‹: {market_name}")
        
        # è·å–å¢å¼ºæ•°æ®ç®¡ç†å™¨
        manager = get_enhanced_data_manager()
        
        # è·å–ç»¼åˆæ–°é—»æ•°æ®
        news_data = manager.get_comprehensive_news(ticker, limit)
        
        if not news_data:
            logger.warning(f"âš ï¸ æœªè·å–åˆ°æ–°é—»æ•°æ®: {ticker}")
            return f"æœªèƒ½è·å–åˆ°è‚¡ç¥¨ {ticker} çš„æ–°é—»æ•°æ®ã€‚è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ã€‚"
        
        # æ ¼å¼åŒ–æ–°é—»æ•°æ®
        formatted_news = format_enhanced_news_data(ticker, news_data, market_info)
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(news_data)} æ¡å¢å¼ºæ–°é—»: {ticker}")
        return formatted_news
        
    except Exception as e:
        logger.error(f"âŒ è·å–å¢å¼ºæ–°é—»å¤±è´¥: {ticker}, é”™è¯¯: {str(e)}")
        return f"è·å–è‚¡ç¥¨ {ticker} çš„æ–°é—»æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool 
def get_enhanced_market_sentiment(ticker: str) -> str:
    """
    è·å–è‚¡ç¥¨çš„å¢å¼ºå¸‚åœºæƒ…ç»ªåˆ†æï¼Œæ•´åˆç¤¾äº¤åª’ä½“æ•°æ®
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001, AAPL, 0700.HKï¼‰
    
    Returns:
        str: æ ¼å¼åŒ–çš„å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š
    """
    try:
        logger.info(f"ğŸ˜Š å¼€å§‹è·å–å¸‚åœºæƒ…ç»ªåˆ†æ: {ticker}")
        
        # è·å–å¸‚åœºä¿¡æ¯
        market_info = StockUtils.get_market_info(ticker)
        
        # è·å–å¢å¼ºæ•°æ®ç®¡ç†å™¨
        manager = get_enhanced_data_manager()
        
        # è·å–ç»¼åˆæƒ…ç»ªåˆ†æ
        sentiment_data = manager.get_comprehensive_sentiment(ticker)
        
        if not sentiment_data:
            logger.warning(f"âš ï¸ æœªè·å–åˆ°æƒ…ç»ªæ•°æ®: {ticker}")
            return f"æœªèƒ½è·å–åˆ°è‚¡ç¥¨ {ticker} çš„å¸‚åœºæƒ…ç»ªæ•°æ®ã€‚"
        
        # è·å–ç¤¾äº¤è®¨è®ºæ•°æ®
        discussions = manager.get_social_discussions(ticker, 20)
        
        # æ ¼å¼åŒ–æƒ…ç»ªåˆ†ææŠ¥å‘Š
        formatted_sentiment = format_sentiment_analysis(ticker, sentiment_data, discussions, market_info)
        
        logger.info(f"âœ… æˆåŠŸè·å–å¸‚åœºæƒ…ç»ªåˆ†æ: {ticker}")
        return formatted_sentiment
        
    except Exception as e:
        logger.error(f"âŒ è·å–å¸‚åœºæƒ…ç»ªåˆ†æå¤±è´¥: {ticker}, é”™è¯¯: {str(e)}")
        return f"è·å–è‚¡ç¥¨ {ticker} çš„å¸‚åœºæƒ…ç»ªåˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool
def get_enhanced_social_discussions(ticker: str, limit: int = 50) -> str:
    """
    è·å–è‚¡ç¥¨çš„ç¤¾äº¤åª’ä½“è®¨è®ºæ•°æ®
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001, AAPL, 0700.HKï¼‰
        limit: è¿”å›è®¨è®ºæ•°é‡é™åˆ¶ï¼Œé»˜è®¤50æ¡
    
    Returns:
        str: æ ¼å¼åŒ–çš„ç¤¾äº¤è®¨è®ºåˆ†ææŠ¥å‘Š
    """
    try:
        logger.info(f"ğŸ’¬ å¼€å§‹è·å–ç¤¾äº¤è®¨è®ºæ•°æ®: {ticker}")
        
        # è·å–å¸‚åœºä¿¡æ¯
        market_info = StockUtils.get_market_info(ticker)
        
        # è·å–å¢å¼ºæ•°æ®ç®¡ç†å™¨
        manager = get_enhanced_data_manager()
        
        # è·å–ç¤¾äº¤è®¨è®ºæ•°æ®
        discussions = manager.get_social_discussions(ticker, limit)
        
        if not discussions:
            logger.warning(f"âš ï¸ æœªè·å–åˆ°è®¨è®ºæ•°æ®: {ticker}")
            return f"æœªèƒ½è·å–åˆ°è‚¡ç¥¨ {ticker} çš„ç¤¾äº¤è®¨è®ºæ•°æ®ã€‚"
        
        # æ ¼å¼åŒ–è®¨è®ºæ•°æ®
        formatted_discussions = format_social_discussions(ticker, discussions, market_info)
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(discussions)} æ¡ç¤¾äº¤è®¨è®º: {ticker}")
        return formatted_discussions
        
    except Exception as e:
        logger.error(f"âŒ è·å–ç¤¾äº¤è®¨è®ºå¤±è´¥: {ticker}, é”™è¯¯: {str(e)}")
        return f"è·å–è‚¡ç¥¨ {ticker} çš„ç¤¾äº¤è®¨è®ºæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def format_enhanced_news_data(ticker: str, news_data: List[Dict], market_info: Dict) -> str:
    """æ ¼å¼åŒ–å¢å¼ºæ–°é—»æ•°æ®"""
    try:
        report = f"""# ğŸ“° {ticker} å¢å¼ºæ–°é—»åˆ†ææŠ¥å‘Š

## ğŸ“Š åŸºæœ¬ä¿¡æ¯
- **è‚¡ç¥¨ä»£ç **: {ticker}
- **å¸‚åœºç±»å‹**: {market_info['market_name']}
- **è´§å¸å•ä½**: {market_info['currency_name']}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ–°é—»æ€»æ•°**: {len(news_data)} æ¡

## ğŸ“° æœ€æ–°æ–°é—»åŠ¨æ€

"""
        
        # æŒ‰æ•°æ®æºåˆ†ç»„æ–°é—»
        news_by_source = {}
        for news in news_data:
            source = news.get('data_source', news.get('source', 'æœªçŸ¥'))
            if source not in news_by_source:
                news_by_source[source] = []
            news_by_source[source].append(news)
        
        # æ˜¾ç¤ºå„æ•°æ®æºçš„æ–°é—»
        for source, source_news in news_by_source.items():
            report += f"### ğŸ“¡ {source} ({len(source_news)} æ¡)\n\n"
            
            for i, news in enumerate(source_news[:10], 1):  # æ¯ä¸ªæºæœ€å¤šæ˜¾ç¤º10æ¡
                title = news.get('title', 'æ— æ ‡é¢˜')
                publish_time = news.get('publish_time', news.get('publish_date', 'æ—¶é—´æœªçŸ¥'))
                summary = news.get('summary', news.get('content', ''))[:200]
                
                report += f"**{i}. {title}**\n"
                report += f"   - å‘å¸ƒæ—¶é—´: {publish_time}\n"
                if summary:
                    report += f"   - å†…å®¹æ‘˜è¦: {summary}...\n"
                report += "\n"
        
        # æ–°é—»ç»Ÿè®¡åˆ†æ
        report += "## ğŸ“Š æ–°é—»åˆ†æç»Ÿè®¡\n\n"
        
        # æ–°é—»æ¥æºåˆ†å¸ƒ
        report += "### æ•°æ®æºåˆ†å¸ƒ\n\n"
        report += "| æ•°æ®æº | æ–°é—»æ•°é‡ | å æ¯” |\n"
        report += "|--------|----------|------|\n"
        
        total_news = len(news_data)
        for source, source_news in news_by_source.items():
            count = len(source_news)
            percentage = (count / total_news * 100) if total_news > 0 else 0
            report += f"| {source} | {count} | {percentage:.1f}% |\n"
        
        # æ–°é—»æ—¶æ•ˆæ€§åˆ†æ
        recent_news = sum(1 for news in news_data if is_recent_news(news))
        report += f"\n### æ—¶æ•ˆæ€§åˆ†æ\n"
        report += f"- **24å°æ—¶å†…æ–°é—»**: {recent_news} æ¡\n"
        report += f"- **æ–°é—»æ—¶æ•ˆæ€§**: {'é«˜' if recent_news > total_news * 0.3 else 'ä¸­ç­‰' if recent_news > 0 else 'ä½'}\n"
        
        # å…³é”®è¯åˆ†æ
        keywords = extract_keywords_from_news(news_data)
        if keywords:
            report += f"\n### çƒ­é—¨å…³é”®è¯\n"
            for i, (keyword, count) in enumerate(keywords[:10], 1):
                report += f"{i}. **{keyword}** ({count}æ¬¡)\n"
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ æ ¼å¼åŒ–æ–°é—»æ•°æ®å¤±è´¥: {str(e)}")
        return f"æ ¼å¼åŒ–æ–°é—»æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def format_sentiment_analysis(ticker: str, sentiment_data: Dict, discussions: List[Dict], market_info: Dict) -> str:
    """æ ¼å¼åŒ–æƒ…ç»ªåˆ†ææŠ¥å‘Š"""
    try:
        overall_sentiment = sentiment_data.get('overall_sentiment', 0)
        confidence = sentiment_data.get('confidence', 0)
        sources = sentiment_data.get('sources', [])
        
        # æƒ…ç»ªç­‰çº§åˆ¤å®š
        if overall_sentiment > 0.3:
            sentiment_level = "ç§¯æä¹è§‚"
            sentiment_emoji = "ğŸ“ˆ"
        elif overall_sentiment > 0.1:
            sentiment_level = "åå‘ç§¯æ"
            sentiment_emoji = "ğŸ”¼"
        elif overall_sentiment > -0.1:
            sentiment_level = "ä¸­æ€§è§‚æœ›"
            sentiment_emoji = "ğŸ”¸"
        elif overall_sentiment > -0.3:
            sentiment_level = "åå‘æ‚²è§‚"
            sentiment_emoji = "ğŸ”½"
        else:
            sentiment_level = "æ¶ˆææ‚²è§‚"
            sentiment_emoji = "ğŸ“‰"
        
        report = f"""# ğŸ˜Š {ticker} å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š

## ğŸ“Š åŸºæœ¬ä¿¡æ¯
- **è‚¡ç¥¨ä»£ç **: {ticker}
- **å¸‚åœºç±»å‹**: {market_info['market_name']}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“ˆ æ•´ä½“æƒ…ç»ªè¯„ä¼°

### ç»¼åˆæƒ…ç»ªè¯„åˆ†
- **æƒ…ç»ªè¯„åˆ†**: {overall_sentiment:.3f} (èŒƒå›´: -1.0 åˆ° 1.0)
- **æƒ…ç»ªç­‰çº§**: {sentiment_emoji} {sentiment_level}
- **ç½®ä¿¡åº¦**: {confidence:.2f}
- **æ•°æ®æº**: {', '.join(sources)}

### æƒ…ç»ªæŒ‡æ ‡è§£è¯»
"""
        
        # æƒ…ç»ªè¯¦ç»†åˆ†æ
        details = sentiment_data.get('details', {})
        for source, source_data in details.items():
            report += f"\n#### ğŸ“¡ {source} æƒ…ç»ªåˆ†æ\n"
            report += f"- **è®¨è®ºæ€»æ•°**: {source_data.get('total_discussions', 0)} æ¡\n"
            report += f"- **ç§¯ææ¯”ä¾‹**: {source_data.get('positive_ratio', 0):.1%}\n"
            report += f"- **æ¶ˆææ¯”ä¾‹**: {source_data.get('negative_ratio', 0):.1%}\n"
            report += f"- **ä¸­æ€§æ¯”ä¾‹**: {source_data.get('neutral_ratio', 0):.1%}\n"
            
            # çƒ­é—¨å…³é”®è¯
            if 'hot_keywords' in source_data:
                keywords = source_data['hot_keywords']
                if keywords:
                    report += f"- **çƒ­é—¨å…³é”®è¯**: {', '.join(keywords[:5])}\n"
        
        # ç¤¾äº¤è®¨è®ºåˆ†æ
        if discussions:
            report += f"\n## ğŸ’¬ ç¤¾äº¤è®¨è®ºçƒ­åº¦åˆ†æ\n\n"
            report += f"### è®¨è®ºæ¦‚å†µ\n"
            report += f"- **è®¨è®ºæ€»æ•°**: {len(discussions)} æ¡\n"
            
            # æŒ‰æ•°æ®æºåˆ†ç±»è®¨è®º
            discussion_by_source = {}
            total_heat = 0
            for disc in discussions:
                source = disc.get('data_source', 'æœªçŸ¥')
                if source not in discussion_by_source:
                    discussion_by_source[source] = []
                discussion_by_source[source].append(disc)
                total_heat += disc.get('heat_score', 0)
            
            report += f"- **å¹³å‡çƒ­åº¦**: {total_heat / len(discussions):.1f}\n"
            report += f"- **æ•°æ®æº**: {', '.join(discussion_by_source.keys())}\n"
            
            # çƒ­é—¨è®¨è®º
            top_discussions = sorted(discussions, key=lambda x: x.get('heat_score', 0), reverse=True)[:5]
            report += f"\n### ğŸ”¥ çƒ­é—¨è®¨è®º\n\n"
            
            for i, disc in enumerate(top_discussions, 1):
                title = disc.get('title', 'æ— æ ‡é¢˜')[:80]
                heat_score = disc.get('heat_score', 0)
                source = disc.get('data_source', 'æœªçŸ¥')
                sentiment_score = disc.get('sentiment_score', 0)
                
                sentiment_icon = "ğŸ“ˆ" if sentiment_score > 0.1 else "ğŸ“‰" if sentiment_score < -0.1 else "â¡ï¸"
                
                report += f"**{i}. {title}...**\n"
                report += f"   - çƒ­åº¦è¯„åˆ†: {heat_score}\n"
                report += f"   - æƒ…ç»ªå€¾å‘: {sentiment_icon} {sentiment_score:.2f}\n"
                report += f"   - æ•°æ®æº: {source}\n\n"
        
        # æŠ•èµ„å»ºè®®
        report += f"\n## ğŸ’¡ åŸºäºæƒ…ç»ªçš„æŠ•èµ„å‚è€ƒ\n\n"
        
        if overall_sentiment > 0.2:
            report += "### ğŸŸ¢ ç§¯æä¿¡å·\n"
            report += "- å¸‚åœºæƒ…ç»ªåå‘ç§¯æï¼ŒæŠ•èµ„è€…ä¿¡å¿ƒè¾ƒå¼º\n"
            report += "- ç¤¾äº¤åª’ä½“è®¨è®ºçƒ­åº¦è¾ƒé«˜ï¼Œå…³æ³¨åº¦æå‡\n"
            report += "- **å‚è€ƒå»ºè®®**: å¯å…³æ³¨çŸ­æœŸä¸Šæ¶¨æœºä¼šï¼Œä½†éœ€æ³¨æ„é£é™©æ§åˆ¶\n"
        elif overall_sentiment < -0.2:
            report += "### ğŸ”´ æ¶ˆæä¿¡å·\n"
            report += "- å¸‚åœºæƒ…ç»ªåå‘æ‚²è§‚ï¼ŒæŠ•èµ„è€…æƒ…ç»ªä½è¿·\n"
            report += "- éœ€å…³æ³¨æ½œåœ¨çš„è´Ÿé¢å› ç´ å’Œé£é™©ç‚¹\n"
            report += "- **å‚è€ƒå»ºè®®**: å»ºè®®è°¨æ…è§‚æœ›ï¼Œç­‰å¾…æƒ…ç»ªæ”¹å–„ä¿¡å·\n"
        else:
            report += "### ğŸŸ¡ ä¸­æ€§è§‚æœ›\n"
            report += "- å¸‚åœºæƒ…ç»ªç›¸å¯¹ä¸­æ€§ï¼ŒæŠ•èµ„è€…è§‚æœ›æƒ…ç»ªè¾ƒé‡\n"
            report += "- ç¼ºä¹æ˜ç¡®çš„æ–¹å‘æ€§ä¿¡å·\n"
            report += "- **å‚è€ƒå»ºè®®**: æŒç»­å…³æ³¨åŸºæœ¬é¢å˜åŒ–å’Œæ¶ˆæ¯é¢åŠ¨æ€\n"
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ æ ¼å¼åŒ–æƒ…ç»ªåˆ†æå¤±è´¥: {str(e)}")
        return f"æ ¼å¼åŒ–æƒ…ç»ªåˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def format_social_discussions(ticker: str, discussions: List[Dict], market_info: Dict) -> str:
    """æ ¼å¼åŒ–ç¤¾äº¤è®¨è®ºæŠ¥å‘Š"""
    try:
        report = f"""# ğŸ’¬ {ticker} ç¤¾äº¤åª’ä½“è®¨è®ºåˆ†æ

## ğŸ“Š åŸºæœ¬ä¿¡æ¯
- **è‚¡ç¥¨ä»£ç **: {ticker}
- **å¸‚åœºç±»å‹**: {market_info['market_name']}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **è®¨è®ºæ€»æ•°**: {len(discussions)} æ¡

## ğŸ”¥ è®¨è®ºçƒ­åº¦æ’è¡Œ

"""
        
        # æŒ‰çƒ­åº¦æ’åºæ˜¾ç¤ºè®¨è®º
        sorted_discussions = sorted(discussions, key=lambda x: x.get('heat_score', 0), reverse=True)
        
        for i, disc in enumerate(sorted_discussions[:20], 1):  # æ˜¾ç¤ºå‰20æ¡
            title = disc.get('title', 'æ— æ ‡é¢˜')
            heat_score = disc.get('heat_score', 0)
            reply_count = disc.get('reply_count', 0)
            read_count = disc.get('read_count', disc.get('view_count', 0))
            source = disc.get('data_source', disc.get('source', 'æœªçŸ¥'))
            sentiment_score = disc.get('sentiment_score', 0)
            
            sentiment_icon = "ğŸ“ˆ" if sentiment_score > 0.1 else "ğŸ“‰" if sentiment_score < -0.1 else "â¡ï¸"
            
            report += f"### {i}. {title}\n"
            report += f"- **çƒ­åº¦è¯„åˆ†**: {heat_score}\n"
            report += f"- **å›å¤æ•°**: {reply_count}\n"
            report += f"- **é˜…è¯»æ•°**: {read_count}\n"
            report += f"- **æƒ…ç»ªå€¾å‘**: {sentiment_icon} {sentiment_score:.2f}\n"
            report += f"- **æ•°æ®æº**: {source}\n\n"
        
        # ç»Ÿè®¡åˆ†æ
        report += "## ğŸ“Š è®¨è®ºç»Ÿè®¡åˆ†æ\n\n"
        
        # æŒ‰æ•°æ®æºåˆ†ç»„
        source_stats = {}
        total_interactions = 0
        sentiment_scores = []
        
        for disc in discussions:
            source = disc.get('data_source', disc.get('source', 'æœªçŸ¥'))
            if source not in source_stats:
                source_stats[source] = {'count': 0, 'total_heat': 0}
            
            source_stats[source]['count'] += 1
            source_stats[source]['total_heat'] += disc.get('heat_score', 0)
            
            total_interactions += disc.get('reply_count', 0) + disc.get('read_count', disc.get('view_count', 0))
            
            sentiment = disc.get('sentiment_score', 0)
            if sentiment != 0:
                sentiment_scores.append(sentiment)
        
        # æ•°æ®æºç»Ÿè®¡
        report += "### æ•°æ®æºåˆ†å¸ƒ\n\n"
        report += "| æ•°æ®æº | è®¨è®ºæ•°é‡ | å¹³å‡çƒ­åº¦ |\n"
        report += "|--------|----------|----------|\n"
        
        for source, stats in source_stats.items():
            avg_heat = stats['total_heat'] / stats['count'] if stats['count'] > 0 else 0
            report += f"| {source} | {stats['count']} | {avg_heat:.1f} |\n"
        
        # æƒ…ç»ªåˆ†å¸ƒ
        if sentiment_scores:
            avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)
            positive_count = sum(1 for s in sentiment_scores if s > 0.1)
            negative_count = sum(1 for s in sentiment_scores if s < -0.1)
            neutral_count = len(sentiment_scores) - positive_count - negative_count
            
            report += f"\n### æƒ…ç»ªåˆ†å¸ƒ\n"
            report += f"- **å¹³å‡æƒ…ç»ª**: {avg_sentiment:.3f}\n"
            report += f"- **ç§¯æè®¨è®º**: {positive_count} æ¡ ({positive_count/len(sentiment_scores):.1%})\n"
            report += f"- **æ¶ˆæè®¨è®º**: {negative_count} æ¡ ({negative_count/len(sentiment_scores):.1%})\n"
            report += f"- **ä¸­æ€§è®¨è®º**: {neutral_count} æ¡ ({neutral_count/len(sentiment_scores):.1%})\n"
        
        report += f"\n### äº’åŠ¨ç»Ÿè®¡\n"
        report += f"- **æ€»äº’åŠ¨æ•°**: {total_interactions:,}\n"
        report += f"- **å¹³å‡äº’åŠ¨æ•°**: {total_interactions/len(discussions):.1f}\n"
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ æ ¼å¼åŒ–ç¤¾äº¤è®¨è®ºå¤±è´¥: {str(e)}")
        return f"æ ¼å¼åŒ–ç¤¾äº¤è®¨è®ºæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def is_recent_news(news: Dict) -> bool:
    """åˆ¤æ–­æ–°é—»æ˜¯å¦ä¸ºæœ€è¿‘24å°æ—¶å†…çš„"""
    try:
        publish_time = news.get('publish_time', news.get('publish_date', ''))
        if not publish_time:
            return False
        
        # ç®€å•çš„æ—¶é—´åˆ¤æ–­ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›
        current_time = datetime.now()
        
        # å¦‚æœåŒ…å«"å°æ—¶å‰"ã€"åˆ†é’Ÿå‰"ç­‰è¯æ±‡ï¼Œè®¤ä¸ºæ˜¯æœ€è¿‘çš„
        if any(keyword in str(publish_time) for keyword in ['å°æ—¶å‰', 'åˆ†é’Ÿå‰', 'åˆšåˆš', 'ä»Šå¤©']):
            return True
        
        return False
        
    except Exception:
        return False


def extract_keywords_from_news(news_data: List[Dict]) -> List[tuple]:
    """ä»æ–°é—»ä¸­æå–å…³é”®è¯"""
    try:
        keyword_freq = {}
        
        for news in news_data:
            title = news.get('title', '')
            content = news.get('summary', news.get('content', ''))
            text = title + ' ' + content
            
            # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥æ”¹è¿›ä¸ºæ›´å¤æ‚çš„NLPæ–¹æ³•ï¼‰
            import re
            words = re.findall(r'[\u4e00-\u9fa5]{2,}', text)  # æå–ä¸­æ–‡è¯æ±‡
            
            for word in words:
                if len(word) >= 2 and word not in ['è‚¡ç¥¨', 'å…¬å¸', 'å¸‚åœº', 'æŠ•èµ„', 'åˆ†æ', 'æŠ¥å‘Š']:
                    keyword_freq[word] = keyword_freq.get(word, 0) + 1
        
        # æŒ‰é¢‘ç‡æ’åº
        return sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)
        
    except Exception:
        return []


def create_enhanced_news_toolkit():
    """åˆ›å»ºå¢å¼ºæ–°é—»å·¥å…·åŒ…"""
    return [
        get_enhanced_stock_news,
        get_enhanced_market_sentiment,
        get_enhanced_social_discussions
    ]