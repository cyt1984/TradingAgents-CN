#!/usr/bin/env python3
"""
æ™ºèƒ½é€‰è‚¡æ ¸å¿ƒå¼•æ“
åŸºäºå¤šæºæ•°æ®èåˆå’Œç»¼åˆè¯„åˆ†ç³»ç»Ÿçš„Aè‚¡é€‰è‚¡å¼•æ“
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Union, Tuple
from datetime import datetime, timedelta
import time
from dataclasses import dataclass, field
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¯¼å…¥ç›¸å…³æ¨¡å—
from .filter_conditions import (
    FilterCondition, FilterGroup, FilterLogic, STOCK_FILTER_FIELDS,
    NumericFilter, EnumFilter, BooleanFilter, FilterOperator
)
from ..analytics.comprehensive_scoring_system import get_comprehensive_scoring_system, ComprehensiveScore
from ..analytics.data_fusion_engine import get_fusion_engine
from ..dataflows.enhanced_data_manager import EnhancedDataManager
from ..utils.logging_manager import get_logger
from .ai_strategies.ai_strategy_manager import get_ai_strategy_manager, AIMode, AISelectionConfig

logger = get_logger('agents')


@dataclass
class SelectionCriteria:
    """é€‰è‚¡æ ‡å‡†"""
    filters: List[Union[FilterCondition, FilterGroup]] = field(default_factory=list)  # ç­›é€‰æ¡ä»¶
    sort_by: Optional[str] = 'overall_score'                     # æ’åºå­—æ®µ
    sort_ascending: bool = False                                 # æ’åºæ–¹å‘
    limit: Optional[int] = 100                                   # ç»“æœæ•°é‡é™åˆ¶
    include_scores: bool = True                                  # æ˜¯å¦åŒ…å«è¯„åˆ†æ•°æ®
    include_basic_info: bool = True                              # æ˜¯å¦åŒ…å«åŸºæœ¬ä¿¡æ¯
    
    # AIå¢å¼ºé€‰é¡¹
    ai_mode: AIMode = AIMode.BASIC                               # AIæ¨¡å¼
    ai_config: Optional[AISelectionConfig] = None               # AIé…ç½®
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'filters': [f.to_dict() if hasattr(f, 'to_dict') else str(f) for f in self.filters],
            'sort_by': self.sort_by,
            'sort_ascending': self.sort_ascending,
            'limit': self.limit,
            'include_scores': self.include_scores,
            'include_basic_info': self.include_basic_info
        }


@dataclass  
class SelectionResult:
    """é€‰è‚¡ç»“æœ"""
    symbols: List[str]                          # è‚¡ç¥¨ä»£ç åˆ—è¡¨
    data: pd.DataFrame                          # è¯¦ç»†æ•°æ®
    summary: Dict[str, Any]                     # ç»Ÿè®¡æ‘˜è¦
    criteria: SelectionCriteria                 # é€‰è‚¡æ ‡å‡†
    execution_time: float                       # æ‰§è¡Œæ—¶é—´
    total_candidates: int                       # å€™é€‰è‚¡ç¥¨æ€»æ•°
    filtered_count: int                         # ç­›é€‰åæ•°é‡
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'symbols': self.symbols,
            'data': self.data.to_dict('records') if not self.data.empty else [],
            'summary': self.summary,
            'criteria': self.criteria.to_dict(),
            'execution_time': self.execution_time,
            'total_candidates': self.total_candidates,
            'filtered_count': self.filtered_count
        }


class StockSelector:
    """æ™ºèƒ½é€‰è‚¡å¼•æ“"""
    
    def __init__(self, cache_enabled: bool = True):
        """
        åˆå§‹åŒ–é€‰è‚¡å¼•æ“
        
        Args:
            cache_enabled: æ˜¯å¦å¯ç”¨ç¼“å­˜æœºåˆ¶
        """
        self.cache_enabled = cache_enabled
        self.data_manager = None
        self.scoring_system = None
        self.fusion_engine = None
        self._stock_cache = {}
        self._cache_timestamp = None
        self._cache_ttl = 300  # ç¼“å­˜5åˆ†é’Ÿ
        
        # AIç­–ç•¥ç®¡ç†å™¨
        self.ai_strategy_manager = None
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()
    
    def _init_components(self):
        """åˆå§‹åŒ–ç›¸å…³ç»„ä»¶"""
        try:
            # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
            self.data_manager = EnhancedDataManager()
            logger.info("âœ… æ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–ç»¼åˆè¯„åˆ†ç³»ç»Ÿ
            self.scoring_system = get_comprehensive_scoring_system()
            logger.info("âœ… ç»¼åˆè¯„åˆ†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ•°æ®èåˆå¼•æ“
            self.fusion_engine = get_fusion_engine()
            logger.info("âœ… æ•°æ®èåˆå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            
            
            # åˆå§‹åŒ–AIç­–ç•¥ç®¡ç†å™¨
            try:
                self.ai_strategy_manager = get_ai_strategy_manager()
                logger.info("âœ… AIç­–ç•¥ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as ai_error:
                logger.warning(f"âš ï¸ AIç­–ç•¥ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨¡å¼: {ai_error}")
                self.ai_strategy_manager = None
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def get_available_fields(self) -> Dict[str, Dict[str, Any]]:
        """è·å–å¯ç”¨çš„ç­›é€‰å­—æ®µ"""
        return STOCK_FILTER_FIELDS.copy()
    
    def create_numeric_filter(
        self, 
        field_name: str, 
        operator: FilterOperator, 
        value: Union[float, int, Tuple[float, float]]
    ) -> NumericFilter:
        """åˆ›å»ºæ•°å€¼ç­›é€‰æ¡ä»¶"""
        field_info = STOCK_FILTER_FIELDS.get(field_name, {})
        return NumericFilter(
            field_name=field_name,
            field_display_name=field_info.get('name', field_name),
            operator=operator,
            value=value,
            description=field_info.get('description', '')
        )
    
    def create_enum_filter(
        self, 
        field_name: str, 
        operator: FilterOperator, 
        value: Union[str, List[str]]
    ) -> EnumFilter:
        """åˆ›å»ºæšä¸¾ç­›é€‰æ¡ä»¶"""
        field_info = STOCK_FILTER_FIELDS.get(field_name, {})
        return EnumFilter(
            field_name=field_name,
            field_display_name=field_info.get('name', field_name),
            operator=operator,
            value=value,
            allowed_values=field_info.get('allowed_values'),
            description=field_info.get('description', '')
        )
    
    def create_boolean_filter(
        self, 
        field_name: str, 
        operator: FilterOperator, 
        value: bool
    ) -> BooleanFilter:
        """åˆ›å»ºå¸ƒå°”ç­›é€‰æ¡ä»¶"""
        field_info = STOCK_FILTER_FIELDS.get(field_name, {})
        return BooleanFilter(
            field_name=field_name,
            field_display_name=field_info.get('name', field_name),
            operator=operator,
            value=value,
            description=field_info.get('description', '')
        )
    
    def _get_stock_list(self) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨åˆ—è¡¨ - ä»…ä½¿ç”¨å…è´¹æ•°æ®æº"""
        # æ£€æŸ¥ç¼“å­˜
        if (self.cache_enabled and 
            self._stock_cache is not None and 
            self._cache_timestamp and 
            time.time() - self._cache_timestamp < self._cache_ttl):
            logger.info("ä»ç¼“å­˜è·å–è‚¡ç¥¨åˆ—è¡¨")
            return self._stock_cache.copy()
        
        try:
            # ä»…ä½¿ç”¨å¢å¼ºæ•°æ®ç®¡ç†å™¨è·å–Aè‚¡æ•°æ®ï¼Œé¿å…Tushareæƒé™é—®é¢˜
            if self.data_manager and hasattr(self.data_manager, 'get_stock_list'):
                stock_data = self.data_manager.get_stock_list('A')
                if stock_data and len(stock_data) > 0:
                    # å°†åˆ—è¡¨è½¬æ¢ä¸ºDataFrame
                    stock_list = pd.DataFrame(stock_data)
                    # é‡å‘½ååˆ—ä»¥ä¿æŒä¸€è‡´æ€§
                    if 'symbol' in stock_list.columns and 'name' in stock_list.columns:
                        stock_list = stock_list.rename(columns={'symbol': 'ts_code', 'name': 'name'})
                    logger.info(f"ä»å¢å¼ºæ•°æ®ç®¡ç†å™¨è·å–Aè‚¡åˆ—è¡¨æˆåŠŸ: {len(stock_list)}åªè‚¡ç¥¨")
                    
                    # æ›´æ–°ç¼“å­˜
                    if self.cache_enabled:
                        self._stock_cache = stock_list.copy()
                        self._cache_timestamp = time.time()
                    
                    return stock_list
            
            logger.warning("è·å–çš„è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _enrich_stock_data(self, stock_data: pd.DataFrame, include_scores: bool = True) -> pd.DataFrame:
        """ä¸°å¯Œè‚¡ç¥¨æ•°æ®"""
        if stock_data.empty:
            return stock_data
        
        enriched_data = stock_data.copy()
        
        # æ·»åŠ ç»¼åˆè¯„åˆ†æ•°æ®
        if include_scores and self.scoring_system:
            try:
                logger.info("ğŸ”„ æ­£åœ¨è·å–ç»¼åˆè¯„åˆ†æ•°æ®...")
                
                # æ‰¹é‡è·å–è¯„åˆ†ï¼ˆé™åˆ¶å¹¶å‘æ•°é‡é¿å…APIé™åˆ¶ï¼‰
                batch_size = 10
                symbols = enriched_data['ts_code'].tolist()
                all_scores = []
                
                for i in range(0, len(symbols), batch_size):
                    batch_symbols = symbols[i:i + batch_size]
                    batch_scores = []
                    
                    for symbol in batch_symbols:
                        try:
                            # è·å–åŸºç¡€æ•°æ®ç”¨äºè¯„åˆ†
                            basic_data = self.data_manager.get_latest_price_data(symbol)
                            if basic_data:
                                score = self.scoring_system.calculate_comprehensive_score(symbol, basic_data)
                                batch_scores.append({
                                    'ts_code': symbol,
                                    'overall_score': score.overall_score,
                                    'grade': score.grade,
                                    'technical_score': score.category_scores.get('technical', {}).get('score', 0),
                                    'fundamental_score': score.category_scores.get('fundamental', {}).get('score', 0),
                                    'sentiment_score': score.category_scores.get('sentiment', {}).get('score', 0),
                                    'quality_score': score.category_scores.get('quality', {}).get('score', 0),
                                    'risk_score': score.category_scores.get('risk', {}).get('score', 0)
                                })
                        except Exception as e:
                            logger.warning(f"âš ï¸ è·å– {symbol} è¯„åˆ†å¤±è´¥: {e}")
                            continue
                    
                    all_scores.extend(batch_scores)
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                    if i + batch_size < len(symbols):
                        time.sleep(0.1)
                
                if all_scores:
                    scores_df = pd.DataFrame(all_scores)
                    enriched_data = enriched_data.merge(scores_df, on='ts_code', how='left')
                    logger.info(f"âœ… æ·»åŠ è¯„åˆ†æ•°æ®æˆåŠŸ: {len(scores_df)}æ¡è®°å½•")
                else:
                    logger.warning("âš ï¸ æœªè·å–åˆ°æœ‰æ•ˆçš„è¯„åˆ†æ•°æ®")
                    
            except Exception as e:
                logger.error(f"âŒ è·å–ç»¼åˆè¯„åˆ†æ•°æ®å¤±è´¥: {e}")
        
        return enriched_data
    
    def _enrich_stock_data_with_ai(self, stock_data: pd.DataFrame, 
                                  ai_config: AISelectionConfig = None) -> pd.DataFrame:
        """ä½¿ç”¨AIå¢å¼ºè‚¡ç¥¨æ•°æ®"""
        if stock_data.empty:
            logger.warning("âš ï¸ è‚¡ç¥¨æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡AIå¢å¼º")
            return stock_data
        
        if not self.ai_strategy_manager:
            logger.warning("âš ï¸ AIç­–ç•¥ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡AIå¢å¼º")
            return stock_data
            
        try:
            logger.info(f"ğŸ¤– å¼€å§‹AIå¢å¼ºæ•°æ®å¤„ç†ï¼Œè‚¡ç¥¨æ•°é‡: {len(stock_data)}")
            
            ai_config = ai_config or AISelectionConfig()
            enriched_data = stock_data.copy()
            
            # æ£€æŸ¥AIå¼•æ“å¯ç”¨æ€§
            ai_status = self.ai_strategy_manager.get_performance_summary()
            available_engines = ai_status.get('engine_availability', {}).get('available_count', 0)
            
            if available_engines == 0:
                logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„AIå¼•æ“ï¼Œä½¿ç”¨åŸºç¡€è¯„åˆ†")
                # æ·»åŠ åŸºç¡€AIè¯„åˆ†åˆ—ä»¥ä¿æŒå…¼å®¹æ€§
                enriched_data['ai_overall_score'] = enriched_data.get('overall_score', 50)
                enriched_data['ai_confidence'] = 0.3
                enriched_data['ai_recommendation'] = 'æ•°æ®ä¸è¶³'
                enriched_data['ai_risk_assessment'] = 'æœªè¯„ä¼°'
                return enriched_data
            
            logger.info(f"ğŸ¤– å‘ç° {available_engines} ä¸ªå¯ç”¨AIå¼•æ“")
            
            # å‡†å¤‡è‚¡ç¥¨æ•°æ®åˆ—è¡¨
            stock_list = []
            for _, row in stock_data.iterrows():
                stock_info = row.to_dict()
                # è·å–é¢å¤–çš„è‚¡ç¥¨æ•°æ®
                symbol = stock_info.get('ts_code', '')
                if symbol:
                    try:
                        # è·å–åŸºç¡€æ•°æ®
                        if hasattr(self, 'data_manager') and self.data_manager:
                            basic_data = self.data_manager.get_latest_price_data(symbol)
                            if basic_data:
                                stock_info.update(basic_data)
                    except Exception as e:
                        logger.debug(f"è·å– {symbol} åŸºç¡€æ•°æ®å¤±è´¥: {e}")
                
                stock_list.append(stock_info)
            
            # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
            total_stocks = len(stock_list)
            if total_stocks <= 10:
                batch_size = total_stocks  # å°æ‰¹é‡ç›´æ¥å¤„ç†
            elif total_stocks <= 50:
                batch_size = 10
            elif total_stocks <= 200:
                batch_size = 15
            else:
                batch_size = 20
            
            logger.info(f"ğŸ¤– ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {batch_size}ï¼Œæ€»æ‰¹æ¬¡: {(total_stocks + batch_size - 1) // batch_size}")
            
            ai_results = []
            successful_batches = 0
            failed_batches = 0
            
            for i in range(0, len(stock_list), batch_size):
                batch = stock_list[i:i + batch_size]
                batch_num = i // batch_size + 1
                
                try:
                    logger.debug(f"ğŸ¤– å¤„ç†æ‰¹æ¬¡ {batch_num}ï¼š{len(batch)} åªè‚¡ç¥¨")
                    
                    # å‡†å¤‡å¸‚åœºæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    market_data = None
                    if ai_config.market_data_required:
                        try:
                            # ç®€å•çš„å¸‚åœºæ•°æ®ï¼ˆå¯ä»¥åç»­æ‰©å±•ï¼‰
                            market_data = {
                                'market_type': 'Aè‚¡',
                                'timestamp': datetime.now(),
                                'news_data': []  # å¯ä»¥æ·»åŠ æ–°é—»æ•°æ®
                            }
                        except Exception:
                            market_data = None
                    
                    batch_results = self.ai_strategy_manager.batch_analyze_stocks(
                        batch, market_data=market_data, config=ai_config
                    )
                    
                    if batch_results:
                        ai_results.extend(batch_results)
                        successful_batches += 1
                        logger.debug(f"âœ… æ‰¹æ¬¡ {batch_num} å¤„ç†æˆåŠŸï¼Œè·å¾— {len(batch_results)} ä¸ªåˆ†æç»“æœ")
                    else:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡ {batch_num} è¿”å›ç©ºç»“æœ")
                        failed_batches += 1
                        
                except Exception as e:
                    logger.warning(f"âŒ AIæ‰¹é‡åˆ†æå¤±è´¥ (æ‰¹æ¬¡ {batch_num}): {e}")
                    failed_batches += 1
                    
                    # ä¸ºå¤±è´¥çš„æ‰¹æ¬¡åˆ›å»ºé»˜è®¤ç»“æœ
                    for stock_info in batch:
                        symbol = stock_info.get('ts_code', stock_info.get('symbol', ''))
                        # åˆ›å»ºç®€å•çš„é»˜è®¤ç»“æœå¯¹è±¡
                        default_result = type('AIResult', (), {
                            'symbol': symbol,
                            'overall_score': enriched_data.loc[enriched_data.get('ts_code', '') == symbol, 'overall_score'].iloc[0] if 'overall_score' in enriched_data.columns and len(enriched_data.loc[enriched_data.get('ts_code', '') == symbol]) > 0 else 50.0,
                            'confidence_level': 0.2,
                            'recommendation': 'æ•°æ®ä¸è¶³',
                            'risk_assessment': 'AIåˆ†æå¤±è´¥',
                            'expert_committee_score': None,
                            'adaptive_strategy_score': None,
                            'pattern_recognition_score': None,
                            'market_regime': None,
                            'detected_patterns': [],
                            'key_factors': ['AIåˆ†æå¤±è´¥'],
                            'processing_time': 0.0
                        })()
                        ai_results.append(default_result)
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡è½½ï¼ˆä»…åœ¨å¤šæ‰¹æ¬¡æ—¶ï¼‰
                if i + batch_size < len(stock_list):
                    import time
                    time.sleep(0.3)
            
            # å¤„ç†ç»Ÿè®¡ä¿¡æ¯
            total_batches = successful_batches + failed_batches
            success_rate = (successful_batches / total_batches * 100) if total_batches > 0 else 0
            
            logger.info(f"ğŸ¤– AIæ‰¹é‡å¤„ç†å®Œæˆ: {successful_batches}/{total_batches} æ‰¹æ¬¡æˆåŠŸ ({success_rate:.1f}%)")
            
            # å°†AIåˆ†æç»“æœåˆå¹¶åˆ°æ•°æ®ä¸­
            if ai_results:
                ai_scores = []
                for ai_result in ai_results:
                    # å®‰å…¨åœ°è·å–å±æ€§å€¼
                    ai_score_entry = {
                        'ts_code': getattr(ai_result, 'symbol', ''),
                        'ai_overall_score': float(getattr(ai_result, 'overall_score', 50.0)),
                        'ai_confidence': float(getattr(ai_result, 'confidence_level', 0.5)),
                        'ai_recommendation': str(getattr(ai_result, 'recommendation', 'è§‚æœ›')),
                        'ai_risk_assessment': str(getattr(ai_result, 'risk_assessment', 'æœªè¯„ä¼°')),
                    }
                    
                    # å¯é€‰çš„AIå¼•æ“ç‰¹å®šè¯„åˆ†
                    if hasattr(ai_result, 'expert_committee_score') and ai_result.expert_committee_score is not None:
                        ai_score_entry['expert_committee_score'] = float(ai_result.expert_committee_score)
                    
                    if hasattr(ai_result, 'adaptive_strategy_score') and ai_result.adaptive_strategy_score is not None:
                        ai_score_entry['adaptive_strategy_score'] = float(ai_result.adaptive_strategy_score)
                        
                    if hasattr(ai_result, 'pattern_recognition_score') and ai_result.pattern_recognition_score is not None:
                        ai_score_entry['pattern_recognition_score'] = float(ai_result.pattern_recognition_score)
                    
                    if hasattr(ai_result, 'market_regime') and ai_result.market_regime:
                        ai_score_entry['market_regime'] = str(ai_result.market_regime)
                    
                    # è½¬æ¢åˆ—è¡¨ä¸ºå­—ç¬¦ä¸²
                    detected_patterns = getattr(ai_result, 'detected_patterns', [])
                    if detected_patterns and isinstance(detected_patterns, (list, tuple)):
                        ai_score_entry['detected_patterns'] = str(detected_patterns)
                    elif detected_patterns:
                        ai_score_entry['detected_patterns'] = str(detected_patterns)
                    
                    key_factors = getattr(ai_result, 'key_factors', [])
                    if key_factors and isinstance(key_factors, (list, tuple)):
                        ai_score_entry['key_factors'] = str(key_factors)
                    elif key_factors:
                        ai_score_entry['key_factors'] = str(key_factors)
                    
                    ai_scores.append(ai_score_entry)
                
                if ai_scores:
                    ai_scores_df = pd.DataFrame(ai_scores)
                    # ä½¿ç”¨å·¦è¿æ¥ç¡®ä¿ä¸ä¸¢å¤±åŸå§‹æ•°æ®
                    enriched_data = enriched_data.merge(ai_scores_df, on='ts_code', how='left')
                    
                    logger.info(f"âœ… AIå¢å¼ºæ•°æ®å¤„ç†å®Œæˆ: {len(ai_scores_df)} æ¡AIåˆ†æç»“æœå·²åˆå¹¶")
                    
                    # å¡«å……ç¼ºå¤±çš„AIåˆ†ææ•°æ®
                    ai_columns = ['ai_overall_score', 'ai_confidence', 'ai_recommendation', 'ai_risk_assessment']
                    for col in ai_columns:
                        if col in enriched_data.columns:
                            if col == 'ai_overall_score':
                                enriched_data[col].fillna(enriched_data.get('overall_score', 50), inplace=True)
                            elif col == 'ai_confidence':
                                enriched_data[col].fillna(0.3, inplace=True)
                            elif col == 'ai_recommendation':
                                enriched_data[col].fillna('æ•°æ®ä¸è¶³', inplace=True)
                            elif col == 'ai_risk_assessment':
                                enriched_data[col].fillna('æœªè¯„ä¼°', inplace=True)
                else:
                    logger.warning("âš ï¸ AIåˆ†æç»“æœå¤„ç†åä¸ºç©º")
            else:
                logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•AIåˆ†æç»“æœï¼Œæ·»åŠ é»˜è®¤AIåˆ—")
                # æ·»åŠ é»˜è®¤AIåˆ—ä»¥ä¿æŒå…¼å®¹æ€§
                enriched_data['ai_overall_score'] = enriched_data.get('overall_score', 50)
                enriched_data['ai_confidence'] = 0.3
                enriched_data['ai_recommendation'] = 'æ•°æ®ä¸è¶³'
                enriched_data['ai_risk_assessment'] = 'æœªåˆ†æ'
            
            return enriched_data
            
        except Exception as e:
            logger.error(f"âŒ AIå¢å¼ºæ•°æ®å¤„ç†å¤±è´¥: {e}")
            return stock_data
    
    def _apply_filters(self, data: pd.DataFrame, filters: List[Union[FilterCondition, FilterGroup]]) -> pd.DataFrame:
        """åº”ç”¨ç­›é€‰æ¡ä»¶"""
        if not filters or data.empty:
            return data
        
        # åˆ›å»ºæ€»çš„ç­›é€‰ç»„
        main_group = FilterGroup(conditions=filters, logic=FilterLogic.AND)
        
        try:
            # åº”ç”¨ç­›é€‰
            filter_mask = main_group.apply_filter(data)
            filtered_data = data[filter_mask].copy()
            
            logger.info(f"ğŸ” ç­›é€‰å®Œæˆ: {len(data)} -> {len(filtered_data)}åªè‚¡ç¥¨")
            return filtered_data
            
        except Exception as e:
            logger.error(f"âŒ åº”ç”¨ç­›é€‰æ¡ä»¶å¤±è´¥: {e}")
            return data
    
    def _generate_summary(self, data: pd.DataFrame, total_candidates: int) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
        if data.empty:
            return {
                'total_candidates': total_candidates,
                'filtered_count': 0,
                'success_rate': 0.0,
                'statistics': {}
            }
        
        summary = {
            'total_candidates': total_candidates,
            'filtered_count': len(data),
            'success_rate': len(data) / max(total_candidates, 1) * 100,
            'statistics': {}
        }
        
        # åŸºç¡€ç»Ÿè®¡
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if col in data.columns and not data[col].isna().all():
                summary['statistics'][col] = {
                    'mean': float(data[col].mean()),
                    'median': float(data[col].median()),
                    'std': float(data[col].std()),
                    'min': float(data[col].min()),
                    'max': float(data[col].max()),
                    'count': int(data[col].count())
                }
        
        # è¡Œä¸šåˆ†å¸ƒ
        if 'industry' in data.columns:
            industry_counts = data['industry'].value_counts().head(10)
            summary['industry_distribution'] = industry_counts.to_dict()
        
        # è¯„çº§åˆ†å¸ƒ
        if 'grade' in data.columns:
            grade_counts = data['grade'].value_counts()
            summary['grade_distribution'] = grade_counts.to_dict()
        
        return summary
    
    def select_stocks(self, criteria: SelectionCriteria) -> SelectionResult:
        """
        æ‰§è¡Œé€‰è‚¡æ“ä½œ
        
        Args:
            criteria: é€‰è‚¡æ ‡å‡†
            
        Returns:
            SelectionResult: é€‰è‚¡ç»“æœ
        """
        start_time = time.time()
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ™ºèƒ½é€‰è‚¡...")
        
        try:
            # 1. è·å–åŸºç¡€è‚¡ç¥¨åˆ—è¡¨
            logger.info("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
            stock_data = self._get_stock_list()
            
            if stock_data.empty:
                logger.warning("âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨æ•°æ®")
                return SelectionResult(
                    symbols=[],
                    data=pd.DataFrame(),
                    summary={'error': 'æœªè·å–åˆ°è‚¡ç¥¨æ•°æ®'},
                    criteria=criteria,
                    execution_time=time.time() - start_time,
                    total_candidates=0,
                    filtered_count=0
                )
            
            total_candidates = len(stock_data)
            logger.info(f"ğŸ“Š å€™é€‰è‚¡ç¥¨æ€»æ•°: {total_candidates}")
            
            # 2. ä¸°å¯Œè‚¡ç¥¨æ•°æ®
            if criteria.include_scores or criteria.include_basic_info:
                logger.info("ğŸ”„ æ­£åœ¨ä¸°å¯Œè‚¡ç¥¨æ•°æ®...")
                
                # åŸºç¡€æ•°æ®ä¸°å¯Œ
                stock_data = self._enrich_stock_data(
                    stock_data, 
                    include_scores=criteria.include_scores
                )
                
                # AIå¢å¼ºæ•°æ®ä¸°å¯Œ
                if criteria.ai_mode != AIMode.BASIC and self.ai_strategy_manager:
                    logger.info(f"ğŸ¤– å¯ç”¨AIå¢å¼ºæ¨¡å¼: {criteria.ai_mode.value}")
                    stock_data = self._enrich_stock_data_with_ai(
                        stock_data,
                        criteria.ai_config
                    )
            
            # 3. åº”ç”¨ç­›é€‰æ¡ä»¶
            if criteria.filters:
                logger.info("ğŸ” æ­£åœ¨åº”ç”¨ç­›é€‰æ¡ä»¶...")
                filtered_data = self._apply_filters(stock_data, criteria.filters)
            else:
                filtered_data = stock_data.copy()
            
            # 4. æ™ºèƒ½æ’åº - ç»“åˆAIè¯„åˆ†å’Œä¼ ç»Ÿè¯„åˆ†
            sort_column = criteria.sort_by
            
            # åˆ›å»ºç»¼åˆè¯„åˆ†åˆ—ç”¨äºæ’åº
            if criteria.ai_mode != AIMode.BASIC and 'ai_overall_score' in filtered_data.columns:
                logger.info("ğŸ¤– ä½¿ç”¨AIå¢å¼ºæ’åºç­–ç•¥")
                
                # è®¡ç®—ç»¼åˆæ™ºèƒ½è¯„åˆ†
                ai_weight = 0.7  # AIè¯„åˆ†æƒé‡70%
                traditional_weight = 0.3  # ä¼ ç»Ÿè¯„åˆ†æƒé‡30%
                
                # æ ‡å‡†åŒ–è¯„åˆ†åˆ°0-100èŒƒå›´
                ai_scores = filtered_data['ai_overall_score'].fillna(50)
                traditional_scores = filtered_data.get('overall_score', pd.Series([50] * len(filtered_data)))
                
                # å¦‚æœæœ‰ç½®ä¿¡åº¦ï¼Œæ ¹æ®ç½®ä¿¡åº¦è°ƒæ•´æƒé‡
                if 'ai_confidence' in filtered_data.columns:
                    confidence_scores = filtered_data['ai_confidence'].fillna(0.5)
                    # é«˜ç½®ä¿¡åº¦æ—¶å¢åŠ AIæƒé‡ï¼Œä½ç½®ä¿¡åº¦æ—¶é™ä½AIæƒé‡
                    dynamic_ai_weight = ai_weight * confidence_scores + (1 - confidence_scores) * 0.4
                    dynamic_traditional_weight = 1 - dynamic_ai_weight
                    
                    filtered_data['intelligent_score'] = (
                        ai_scores * dynamic_ai_weight + 
                        traditional_scores * dynamic_traditional_weight
                    )
                    logger.info("ğŸ¯ ä½¿ç”¨åŠ¨æ€æƒé‡æ™ºèƒ½è¯„åˆ† (åŸºäºAIç½®ä¿¡åº¦)")
                else:
                    # å›ºå®šæƒé‡
                    filtered_data['intelligent_score'] = (
                        ai_scores * ai_weight + 
                        traditional_scores * traditional_weight
                    )
                    logger.info(f"âš–ï¸ ä½¿ç”¨å›ºå®šæƒé‡æ™ºèƒ½è¯„åˆ† (AI:{ai_weight:.1f}, ä¼ ç»Ÿ:{traditional_weight:.1f})")
                
                # ä¼˜å…ˆä½¿ç”¨æ™ºèƒ½è¯„åˆ†æ’åº
                if sort_column in ['overall_score', 'ai_overall_score'] or not sort_column:
                    sort_column = 'intelligent_score'
                    logger.info("ğŸ§  ä½¿ç”¨æ™ºèƒ½ç»¼åˆè¯„åˆ†æ’åº")
            
            # æ‰§è¡Œæ’åº
            if sort_column and sort_column in filtered_data.columns:
                logger.info(f"ğŸ“ˆ æŒ‰ {sort_column} æ’åº...")
                filtered_data = filtered_data.sort_values(
                    by=sort_column, 
                    ascending=criteria.sort_ascending
                )
            elif 'ai_overall_score' in filtered_data.columns:
                # å¦‚æœæŒ‡å®šçš„æ’åºå­—æ®µä¸å­˜åœ¨ï¼Œä½†æœ‰AIè¯„åˆ†ï¼Œåˆ™ä½¿ç”¨AIè¯„åˆ†
                logger.info("ğŸ¤– é»˜è®¤ä½¿ç”¨AIç»¼åˆè¯„åˆ†æ’åº")
                filtered_data = filtered_data.sort_values(
                    by='ai_overall_score',
                    ascending=False
                )
            elif 'overall_score' in filtered_data.columns:
                # æœ€åä½¿ç”¨ä¼ ç»Ÿè¯„åˆ†
                logger.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿç»¼åˆè¯„åˆ†æ’åº")
                filtered_data = filtered_data.sort_values(
                    by='overall_score',
                    ascending=False
                )
            
            # 5. é™åˆ¶ç»“æœæ•°é‡
            if criteria.limit and len(filtered_data) > criteria.limit:
                filtered_data = filtered_data.head(criteria.limit)
                logger.info(f"âœ‚ï¸ é™åˆ¶ç»“æœæ•°é‡ä¸º: {criteria.limit}")
            
            # 6. ç”Ÿæˆç»“æœ
            symbols = filtered_data['ts_code'].tolist() if 'ts_code' in filtered_data.columns else []
            summary = self._generate_summary(filtered_data, total_candidates)
            
            execution_time = time.time() - start_time
            
            result = SelectionResult(
                symbols=symbols,
                data=filtered_data,
                summary=summary,
                criteria=criteria,
                execution_time=execution_time,
                total_candidates=total_candidates,
                filtered_count=len(filtered_data)
            )
            
            logger.info(f"âœ… é€‰è‚¡å®Œæˆ: {len(symbols)}åªè‚¡ç¥¨, è€—æ—¶ {execution_time:.2f}ç§’")
            return result
            
        except Exception as e:
            logger.error(f"âŒ é€‰è‚¡æ“ä½œå¤±è´¥: {e}")
            return SelectionResult(
                symbols=[],
                data=pd.DataFrame(),
                summary={'error': str(e)},
                criteria=criteria,
                execution_time=time.time() - start_time,
                total_candidates=0,
                filtered_count=0
            )
    
    def quick_select(
        self, 
        min_score: float = 70.0, 
        min_market_cap: float = 50.0,
        max_pe_ratio: float = 30.0,
        grades: List[str] = None,
        limit: int = 50
    ) -> SelectionResult:
        """
        å¿«é€Ÿé€‰è‚¡ - ä½¿ç”¨é¢„è®¾çš„å¸¸ç”¨æ¡ä»¶
        
        Args:
            min_score: æœ€å°ç»¼åˆè¯„åˆ†
            min_market_cap: æœ€å°å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
            max_pe_ratio: æœ€å¤§å¸‚ç›ˆç‡
            grades: æŠ•èµ„ç­‰çº§åˆ—è¡¨
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            SelectionResult: é€‰è‚¡ç»“æœ
        """
        filters = []
        
        # ç»¼åˆè¯„åˆ†ç­›é€‰
        filters.append(self.create_numeric_filter(
            'overall_score', FilterOperator.GREATER_EQUAL, min_score
        ))
        
        # å¸‚å€¼ç­›é€‰
        if min_market_cap > 0:
            filters.append(self.create_numeric_filter(
                'market_cap', FilterOperator.GREATER_EQUAL, min_market_cap
            ))
        
        # å¸‚ç›ˆç‡ç­›é€‰
        if max_pe_ratio > 0:
            filters.append(self.create_numeric_filter(
                'pe_ratio', FilterOperator.LESS_EQUAL, max_pe_ratio
            ))
        
        # æŠ•èµ„ç­‰çº§ç­›é€‰
        if grades:
            filters.append(self.create_enum_filter(
                'grade', FilterOperator.IN, grades
            ))
        
        # æ£€æŸ¥AIæ˜¯å¦å¯ç”¨ï¼Œè‡ªåŠ¨å¯ç”¨AIå¢å¼ºæ¨¡å¼
        ai_mode = AIMode.BASIC
        if self.ai_strategy_manager:
            ai_status = self.ai_strategy_manager.get_performance_summary()
            if ai_status.get('ai_enabled', False):
                ai_mode = AIMode.AI_ENHANCED
                logger.info("ğŸ¤– å¿«é€Ÿé€‰è‚¡è‡ªåŠ¨å¯ç”¨AIå¢å¼ºæ¨¡å¼")
        
        criteria = SelectionCriteria(
            filters=filters,
            sort_by='overall_score',  # å°†åœ¨AIå¢å¼ºæ—¶è‡ªåŠ¨è½¬æ¢ä¸ºæ™ºèƒ½è¯„åˆ†
            sort_ascending=False,
            limit=limit,
            include_scores=True,
            include_basic_info=True,
            ai_mode=ai_mode,
            ai_config=AISelectionConfig(
                ai_mode=ai_mode,
                min_ai_score=min_score,
                min_confidence=0.6,
                parallel_processing=True,
                enable_caching=True
            ) if ai_mode != AIMode.BASIC else None
        )
        
        return self.select_stocks(criteria)
    
    def ai_enhanced_select(self,
                          ai_mode: AIMode = AIMode.AI_ENHANCED,
                          min_ai_score: float = 70.0,
                          min_confidence: float = 0.6,
                          max_risk_level: str = "ä¸­ç­‰",
                          limit: int = 50) -> SelectionResult:
        """
        AIå¢å¼ºé€‰è‚¡ - ä½¿ç”¨AIç­–ç•¥è¿›è¡Œæ™ºèƒ½é€‰è‚¡
        
        Args:
            ai_mode: AIæ¨¡å¼
            min_ai_score: æœ€å°AIè¯„åˆ†
            min_confidence: æœ€å°ç½®ä¿¡åº¦
            max_risk_level: æœ€å¤§é£é™©çº§åˆ«
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            SelectionResult: AIé€‰è‚¡ç»“æœ
        """
        if not self.ai_strategy_manager:
            logger.warning("âš ï¸ AIç­–ç•¥ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºç¡€é€‰è‚¡æ¨¡å¼")
            return self.quick_select(min_score=min_ai_score, limit=limit)
        
        # åˆ›å»ºAIé…ç½®
        ai_config = AISelectionConfig(
            ai_mode=ai_mode,
            min_ai_score=min_ai_score,
            min_confidence=min_confidence,
            max_risk_level=max_risk_level,
            enable_caching=True,
            parallel_processing=True
        )
        
        # åŸºç¡€ç­›é€‰æ¡ä»¶ (ä½¿ç”¨AIè¯„åˆ†)
        filters = []
        
        # åŸºç¡€æ¡ä»¶ä¿è¯æ•°æ®è´¨é‡
        filters.append(self.create_numeric_filter(
            'market_cap', FilterOperator.GREATER_EQUAL, 10.0  # è‡³å°‘10äº¿å¸‚å€¼
        ))
        
        criteria = SelectionCriteria(
            filters=filters,
            sort_by='ai_overall_score',  # ä½¿ç”¨AIè¯„åˆ†æ’åº
            sort_ascending=False,
            limit=limit,
            include_scores=True,
            include_basic_info=True,
            ai_mode=ai_mode,
            ai_config=ai_config
        )
        
        return self.select_stocks(criteria)
    
    def expert_committee_select(self,
                              min_expert_score: float = 75.0,
                              min_consensus: str = "åŸºæœ¬ä¸€è‡´",
                              limit: int = 30) -> SelectionResult:
        """
        ä¸“å®¶å§”å‘˜ä¼šé€‰è‚¡ - åŸºäºAIä¸“å®¶å§”å‘˜ä¼šçš„é›†ä½“å†³ç­–
        
        Args:
            min_expert_score: ä¸“å®¶å§”å‘˜ä¼šæœ€å°è¯„åˆ†
            min_consensus: æœ€å°ä¸€è‡´æ€§è¦æ±‚
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            SelectionResult: ä¸“å®¶å§”å‘˜ä¼šé€‰è‚¡ç»“æœ
        """
        ai_config = AISelectionConfig(
            ai_mode=AIMode.EXPERT_COMMITTEE,
            expert_committee_weight=1.0,
            min_ai_score=min_expert_score,
            min_confidence=0.7,
            enable_caching=True
        )
        
        criteria = SelectionCriteria(
            filters=[],
            sort_by='expert_committee_score',
            sort_ascending=False,
            limit=limit,
            include_scores=True,
            include_basic_info=True,
            ai_mode=AIMode.EXPERT_COMMITTEE,
            ai_config=ai_config
        )
        
        return self.select_stocks(criteria)
    
    def adaptive_strategy_select(self,
                               market_data: Dict[str, Any] = None,
                               limit: int = 40) -> SelectionResult:
        """
        è‡ªé€‚åº”ç­–ç•¥é€‰è‚¡ - æ ¹æ®å¸‚åœºç¯å¢ƒè‡ªåŠ¨è°ƒæ•´é€‰è‚¡ç­–ç•¥
        
        Args:
            market_data: å¸‚åœºæ•°æ® (ç”¨äºç¯å¢ƒæ£€æµ‹)
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            SelectionResult: è‡ªé€‚åº”ç­–ç•¥é€‰è‚¡ç»“æœ
        """
        ai_config = AISelectionConfig(
            ai_mode=AIMode.ADAPTIVE,
            adaptive_strategy_weight=1.0,
            min_ai_score=65.0,
            min_confidence=0.6,
            market_data_required=True
        )
        
        criteria = SelectionCriteria(
            filters=[],
            sort_by='adaptive_strategy_score',
            sort_ascending=False,
            limit=limit,
            include_scores=True,
            include_basic_info=True,
            ai_mode=AIMode.ADAPTIVE,
            ai_config=ai_config
        )
        
        return self.select_stocks(criteria)
    
    def pattern_based_select(self,
                           pattern_types: List[str] = None,
                           min_pattern_score: float = 70.0,
                           limit: int = 35) -> SelectionResult:
        """
        åŸºäºæ¨¡å¼è¯†åˆ«çš„é€‰è‚¡ - å¯»æ‰¾å…·æœ‰ç‰¹å®šæŠ€æœ¯æ¨¡å¼çš„è‚¡ç¥¨
        
        Args:
            pattern_types: æœŸæœ›çš„æ¨¡å¼ç±»å‹åˆ—è¡¨
            min_pattern_score: æœ€å°æ¨¡å¼è¯„åˆ†
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            SelectionResult: æ¨¡å¼é©±åŠ¨é€‰è‚¡ç»“æœ
        """
        ai_config = AISelectionConfig(
            ai_mode=AIMode.PATTERN_BASED,
            pattern_recognition_weight=1.0,
            min_ai_score=min_pattern_score,
            min_confidence=0.65,
            pattern_analysis_enabled=True
        )
        
        criteria = SelectionCriteria(
            filters=[],
            sort_by='pattern_recognition_score',
            sort_ascending=False,
            limit=limit,
            include_scores=True,
            include_basic_info=True,
            ai_mode=AIMode.PATTERN_BASED,
            ai_config=ai_config
        )
        
        return self.select_stocks(criteria)
    
    def full_ai_select(self,
                      min_overall_score: float = 80.0,
                      min_confidence: float = 0.7,
                      risk_tolerance: str = "ä¸­ç­‰",
                      limit: int = 20) -> SelectionResult:
        """
        å®Œæ•´AIé€‰è‚¡ - ä½¿ç”¨æ‰€æœ‰AIå¼•æ“è¿›è¡Œå…¨é¢åˆ†æ
        
        Args:
            min_overall_score: æœ€å°ç»¼åˆè¯„åˆ†
            min_confidence: æœ€å°ç½®ä¿¡åº¦
            risk_tolerance: é£é™©æ‰¿å—åº¦
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            SelectionResult: å®Œæ•´AIé€‰è‚¡ç»“æœ
        """
        ai_config = AISelectionConfig(
            ai_mode=AIMode.FULL_AI,
            min_ai_score=min_overall_score,
            min_confidence=min_confidence,
            max_risk_level=risk_tolerance,
            parallel_processing=True,
            timeout_seconds=60.0,  # å®Œæ•´AIåˆ†æéœ€è¦æ›´å¤šæ—¶é—´
            market_data_required=True,
            news_analysis_enabled=True,
            pattern_analysis_enabled=True,
            similarity_analysis_enabled=True
        )
        
        criteria = SelectionCriteria(
            filters=[],
            sort_by='ai_overall_score',
            sort_ascending=False,
            limit=limit,
            include_scores=True,
            include_basic_info=True,
            ai_mode=AIMode.FULL_AI,
            ai_config=ai_config
        )
        
        return self.select_stocks(criteria)
    
    def get_ai_performance_summary(self) -> Dict[str, Any]:
        """
        è·å–AIé€‰è‚¡å¼•æ“æ€§èƒ½æ‘˜è¦
        
        Returns:
            AIå¼•æ“æ€§èƒ½æ•°æ®
        """
        if self.ai_strategy_manager:
            return self.ai_strategy_manager.get_performance_summary()
        else:
            return {
                'status': 'AIç­–ç•¥ç®¡ç†å™¨æœªåˆå§‹åŒ–',
                'ai_enabled': False
            }
    
    def clear_ai_cache(self):
        """
        æ¸…ç†AIåˆ†æç¼“å­˜
        """
        if self.ai_strategy_manager:
            self.ai_strategy_manager.clear_cache()
            logger.info("ğŸ§¹ AIåˆ†æç¼“å­˜å·²æ¸…ç†")
        else:
            logger.warning("âš ï¸ AIç­–ç•¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")


# å…¨å±€é€‰è‚¡å¼•æ“å®ä¾‹
_stock_selector = None

def get_stock_selector(cache_enabled: bool = True) -> StockSelector:
    """è·å–å…¨å±€é€‰è‚¡å¼•æ“å®ä¾‹"""
    global _stock_selector
    if _stock_selector is None:
        _stock_selector = StockSelector(cache_enabled=cache_enabled)
    return _stock_selector