#!/usr/bin/env python3
"""
AIåˆ†ææ‰¹æ¬¡å¹¶è¡Œå¤„ç†å™¨
é€šè¿‡æ‰¹é‡å¹¶è¡Œå¤„ç†æ˜¾è‘—æå‡AIè‚¡ç¥¨åˆ†æçš„é€Ÿåº¦å’Œæ•ˆç‡

æ ¸å¿ƒåŠŸèƒ½:
1. æ™ºèƒ½æ‰¹æ¬¡åˆ†ç»„ - æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
2. å¹¶è¡Œå¤„ç†ç®¡ç† - å¤šçº¿ç¨‹/å¼‚æ­¥å¤„ç†å¤šä¸ªæ‰¹æ¬¡
3. å¤±è´¥é‡è¯•æœºåˆ¶ - è‡ªåŠ¨é‡è¯•å¤±è´¥çš„åˆ†æä»»åŠ¡
4. è¿›åº¦è·Ÿè¸ªæŠ¥å‘Š - å®æ—¶åé¦ˆå¤„ç†è¿›åº¦
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Union, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import time
import logging
import asyncio
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from queue import Queue, Empty
import psutil
import gc
from functools import partial

from ..utils.logging_manager import get_logger

# å¯¼å…¥åˆ†æå¸ˆç±» - å¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ¨¡æ‹Ÿç±»
try:
    from ..agents.analysts.fundamentals_analyst import FundamentalsAnalyst
except ImportError:
    class FundamentalsAnalyst:
        def analyze(self, symbol): return {'score': 50, 'recommendation': 'HOLD'}

try:
    from ..agents.analysts.technical_analyst import TechnicalAnalyst
except ImportError:
    class TechnicalAnalyst:
        def analyze(self, symbol): return {'score': 50, 'recommendation': 'HOLD'}

try:
    from ..agents.analysts.news_analyst import NewsAnalyst
except ImportError:
    class NewsAnalyst:
        def analyze(self, symbol): return {'score': 50, 'recommendation': 'HOLD'}

# å¯¼å…¥é›ªçƒæ•°æ®æä¾›å™¨
try:
    from ..dataflows.xueqiu_utils import get_xueqiu_provider
    XUEQIU_AVAILABLE = True
except ImportError:
    XUEQIU_AVAILABLE = False
    logger = get_logger('batch_ai_processor')
    logger.warning("âš ï¸ é›ªçƒæ•°æ®æä¾›å™¨ä¸å¯ç”¨ï¼Œå°†è·³è¿‡ç¤¾äº¤æƒ…ç»ªåˆ†æ")

logger = get_logger('batch_ai_processor')


class ProcessingStrategy(Enum):
    """å¤„ç†ç­–ç•¥æšä¸¾"""
    SEQUENTIAL = "sequential"          # é¡ºåºå¤„ç†
    THREADED = "threaded"             # å¤šçº¿ç¨‹å¤„ç†
    ASYNC = "async"                   # å¼‚æ­¥å¤„ç†
    HYBRID = "hybrid"                 # æ··åˆç­–ç•¥


@dataclass
class BatchConfig:
    """æ‰¹å¤„ç†é…ç½®"""
    batch_size: int = 20              # æ¯æ‰¹æ¬¡å¤„ç†æ•°é‡
    max_workers: int = 8              # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
    strategy: ProcessingStrategy = ProcessingStrategy.HYBRID
    max_retries: int = 3              # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay: float = 1.0          # é‡è¯•å»¶è¿Ÿ(ç§’)
    timeout_per_batch: int = 300      # æ¯æ‰¹æ¬¡è¶…æ—¶æ—¶é—´(ç§’)
    memory_threshold: float = 0.85    # å†…å­˜ä½¿ç”¨é˜ˆå€¼
    enable_progress_tracking: bool = True  # å¯ç”¨è¿›åº¦è·Ÿè¸ª
    enable_auto_scaling: bool = True  # å¯ç”¨è‡ªåŠ¨æ‰©ç¼©å®¹
    cache_results: bool = True        # ç¼“å­˜ç»“æœ
    
    # åˆ†æå™¨é…ç½®
    enable_fundamentals: bool = True   # å¯ç”¨åŸºæœ¬é¢åˆ†æ
    enable_technical: bool = True      # å¯ç”¨æŠ€æœ¯é¢åˆ†æ
    enable_news: bool = True          # å¯ç”¨æ–°é—»åˆ†æ
    enable_social: bool = True         # å¯ç”¨ç¤¾äº¤æƒ…ç»ªåˆ†æ
    analysis_depth: str = "standard"  # åˆ†ææ·±åº¦: light/standard/deep
    
    # ç¤¾äº¤æ•°æ®é…ç½®
    social_weight: float = 0.2        # ç¤¾äº¤æ•°æ®æƒé‡
    min_discussions: int = 10         # æœ€å°è®¨è®ºæ•°é‡é˜ˆå€¼
    sentiment_threshold: float = 0.3  # æƒ…ç»ªæ˜¾è‘—æ€§é˜ˆå€¼


@dataclass
class BatchResult:
    """æ‰¹å¤„ç†ç»“æœ"""
    symbol: str                       # è‚¡ç¥¨ä»£ç 
    analysis_result: Dict[str, Any]   # åˆ†æç»“æœ
    processing_time: float            # å¤„ç†æ—¶é—´
    retry_count: int                  # é‡è¯•æ¬¡æ•°
    success: bool                     # æ˜¯å¦æˆåŠŸ
    error_message: str = ""           # é”™è¯¯ä¿¡æ¯
    analyst_results: Dict[str, Any] = field(default_factory=dict)  # å„åˆ†æå¸ˆç»“æœ


@dataclass
class ProcessingReport:
    """å¤„ç†æŠ¥å‘Š"""
    total_stocks: int                 # æ€»è‚¡ç¥¨æ•°
    processed_stocks: int             # å·²å¤„ç†æ•°é‡
    successful_stocks: int            # æˆåŠŸå¤„ç†æ•°é‡
    failed_stocks: int               # å¤±è´¥æ•°é‡
    total_time: float                # æ€»è€—æ—¶
    average_time_per_stock: float    # å¹³å‡æ¯åªè‚¡ç¥¨è€—æ—¶
    throughput: float                # å¤„ç†ååé‡(è‚¡ç¥¨/ç§’)
    memory_peak: float               # å†…å­˜å³°å€¼ä½¿ç”¨ç‡
    batch_stats: Dict[str, Any] = field(default_factory=dict)  # æ‰¹æ¬¡ç»Ÿè®¡


class BatchAIProcessor:
    """AIæ‰¹æ¬¡å¹¶è¡Œå¤„ç†å™¨"""
    
    def __init__(self, config: BatchConfig = None):
        """
        åˆå§‹åŒ–æ‰¹æ¬¡å¤„ç†å™¨
        
        Args:
            config: æ‰¹å¤„ç†é…ç½®
        """
        self.config = config or BatchConfig()
        self._results_cache = {}
        self._processing_queue = Queue()
        self._results_queue = Queue()
        self._progress_lock = threading.Lock()
        self._memory_monitor = threading.Thread(target=self._monitor_memory, daemon=True)
        self._stop_monitoring = False
        
        # åˆå§‹åŒ–åˆ†æå¸ˆ
        self.analysts = {}
        if self.config.enable_fundamentals:
            self.analysts['fundamentals'] = FundamentalsAnalyst()
        if self.config.enable_technical:
            self.analysts['technical'] = TechnicalAnalyst()
        if self.config.enable_news:
            self.analysts['news'] = NewsAnalyst()
        
        # åˆå§‹åŒ–é›ªçƒæ•°æ®æä¾›å™¨
        self.xueqiu_provider = None
        if self.config.enable_social and XUEQIU_AVAILABLE:
            try:
                self.xueqiu_provider = get_xueqiu_provider()
                logger.info("âœ… é›ªçƒæ•°æ®æä¾›å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ é›ªçƒæ•°æ®æä¾›å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.config.enable_social = False
            
        # å¯åŠ¨å†…å­˜ç›‘æ§
        self._memory_monitor.start()
        
        logger.info(f"ğŸš€ AIæ‰¹æ¬¡å¹¶è¡Œå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“Š é…ç½®: æ‰¹æ¬¡å¤§å°={self.config.batch_size}, å·¥ä½œçº¿ç¨‹={self.config.max_workers}, ç­–ç•¥={self.config.strategy.value}")
    
    def process_stocks(self, stock_symbols: List[str], 
                      analysis_callback: Callable[[str], Dict[str, Any]] = None) -> ProcessingReport:
        """
        æ‰¹é‡å¤„ç†è‚¡ç¥¨åˆ†æ
        
        Args:
            stock_symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            analysis_callback: è‡ªå®šä¹‰åˆ†æå›è°ƒå‡½æ•°
            
        Returns:
            ProcessingReport: å¤„ç†æŠ¥å‘Š
        """
        start_time = time.time()
        total_stocks = len(stock_symbols)
        
        logger.info(f"ğŸ¯ å¼€å§‹AIæ‰¹é‡åˆ†æ: {total_stocks}åªè‚¡ç¥¨")
        logger.info(f"ğŸ”„ å¤„ç†ç­–ç•¥: {self.config.strategy.value}")
        
        # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡é…ç½®
        if self.config.enable_auto_scaling:
            self._adjust_batch_config(total_stocks)
        
        try:
            # åˆ›å»ºæ‰¹æ¬¡
            batches = self._create_batches(stock_symbols)
            logger.info(f"ğŸ“¦ åˆ›å»ºæ‰¹æ¬¡: {len(batches)}ä¸ªæ‰¹æ¬¡, å¹³å‡æ¯æ‰¹{self.config.batch_size}åªè‚¡ç¥¨")
            
            # æ‰§è¡Œæ‰¹é‡å¤„ç†
            all_results = {}
            processing_stats = {
                'processed': 0,
                'successful': 0,
                'failed': 0,
                'batches_completed': 0,
                'start_time': start_time
            }
            
            if self.config.strategy == ProcessingStrategy.THREADED:
                all_results = self._process_batches_threaded(batches, analysis_callback, processing_stats)
            elif self.config.strategy == ProcessingStrategy.ASYNC:
                all_results = self._process_batches_async(batches, analysis_callback, processing_stats)
            elif self.config.strategy == ProcessingStrategy.HYBRID:
                all_results = self._process_batches_hybrid(batches, analysis_callback, processing_stats)
            else:
                all_results = self._process_batches_sequential(batches, analysis_callback, processing_stats)
            
            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            total_time = time.time() - start_time
            report = ProcessingReport(
                total_stocks=total_stocks,
                processed_stocks=processing_stats['processed'],
                successful_stocks=processing_stats['successful'],
                failed_stocks=processing_stats['failed'],
                total_time=total_time,
                average_time_per_stock=total_time / max(total_stocks, 1),
                throughput=processing_stats['successful'] / max(total_time, 1),
                memory_peak=self._get_memory_usage(),
                batch_stats={
                    'total_batches': len(batches),
                    'completed_batches': processing_stats['batches_completed'],
                    'avg_batch_time': total_time / max(len(batches), 1),
                    'results_cached': len(self._results_cache)
                }
            )
            
            logger.info(f"âœ… AIæ‰¹é‡åˆ†æå®Œæˆ!")
            logger.info(f"ğŸ“ˆ å¤„ç†ç»“æœ: æ€»æ•°:{total_stocks} æˆåŠŸ:{processing_stats['successful']} å¤±è´¥:{processing_stats['failed']}")
            logger.info(f"â±ï¸  è€—æ—¶: {total_time:.1f}ç§’, ååé‡: {report.throughput:.1f}è‚¡ç¥¨/ç§’")
            logger.info(f"ğŸ’¾ å†…å­˜å³°å€¼: {report.memory_peak:.1f}%")
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ AIæ‰¹é‡åˆ†æå¤±è´¥: {e}")
            total_time = time.time() - start_time
            return ProcessingReport(
                total_stocks=total_stocks,
                processed_stocks=0,
                successful_stocks=0,
                failed_stocks=total_stocks,
                total_time=total_time,
                average_time_per_stock=0,
                throughput=0,
                memory_peak=self._get_memory_usage(),
                batch_stats={'error': str(e)}
            )
    
    def _create_batches(self, stock_symbols: List[str]) -> List[List[str]]:
        """åˆ›å»ºå¤„ç†æ‰¹æ¬¡"""
        batches = []
        batch_size = self.config.batch_size
        
        for i in range(0, len(stock_symbols), batch_size):
            batch = stock_symbols[i:i + batch_size]
            batches.append(batch)
        
        return batches
    
    def _process_batches_threaded(self, batches: List[List[str]], 
                                 analysis_callback: Callable,
                                 stats: Dict[str, Any]) -> Dict[str, BatchResult]:
        """å¤šçº¿ç¨‹æ‰¹æ¬¡å¤„ç†"""
        all_results = {}
        
        with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            # æäº¤æ‰€æœ‰æ‰¹æ¬¡ä»»åŠ¡
            future_to_batch = {
                executor.submit(self._process_single_batch, batch, analysis_callback): batch_idx
                for batch_idx, batch in enumerate(batches)
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_batch):
                batch_idx = future_to_batch[future]
                try:
                    batch_results = future.result(timeout=self.config.timeout_per_batch)
                    all_results.update(batch_results)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    with self._progress_lock:
                        stats['processed'] += len(batch_results)
                        stats['successful'] += sum(1 for r in batch_results.values() if r.success)
                        stats['failed'] += sum(1 for r in batch_results.values() if not r.success)
                        stats['batches_completed'] += 1
                        
                        if self.config.enable_progress_tracking:
                            self._log_progress(stats, len(batches))
                        
                        # å†…å­˜æ¸…ç†
                        if stats['batches_completed'] % 5 == 0:
                            gc.collect()
                    
                except Exception as e:
                    logger.error(f"âŒ æ‰¹æ¬¡ {batch_idx} å¤„ç†å¤±è´¥: {e}")
                    stats['failed'] += len(batches[batch_idx])
        
        return all_results
    
    def _process_batches_async(self, batches: List[List[str]], 
                              analysis_callback: Callable,
                              stats: Dict[str, Any]) -> Dict[str, BatchResult]:
        """å¼‚æ­¥æ‰¹æ¬¡å¤„ç†"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            return loop.run_until_complete(
                self._async_process_batches(batches, analysis_callback, stats)
            )
        finally:
            loop.close()
    
    async def _async_process_batches(self, batches: List[List[str]], 
                                   analysis_callback: Callable,
                                   stats: Dict[str, Any]) -> Dict[str, BatchResult]:
        """å¼‚æ­¥æ‰¹æ¬¡å¤„ç†å®ç°"""
        all_results = {}
        semaphore = asyncio.Semaphore(self.config.max_workers)
        
        async def process_batch_with_semaphore(batch):
            async with semaphore:
                return await self._async_process_single_batch(batch, analysis_callback)
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [process_batch_with_semaphore(batch) for batch in batches]
        
        # æ‰§è¡Œä»»åŠ¡
        for i, task in enumerate(asyncio.as_completed(tasks)):
            try:
                batch_results = await task
                all_results.update(batch_results)
                
                # æ›´æ–°ç»Ÿè®¡
                stats['processed'] += len(batch_results)
                stats['successful'] += sum(1 for r in batch_results.values() if r.success)
                stats['failed'] += sum(1 for r in batch_results.values() if not r.success)
                stats['batches_completed'] += 1
                
                if self.config.enable_progress_tracking:
                    self._log_progress(stats, len(batches))
                
            except Exception as e:
                logger.error(f"âŒ å¼‚æ­¥æ‰¹æ¬¡ {i} å¤„ç†å¤±è´¥: {e}")
                stats['failed'] += len(batches[i])
        
        return all_results
    
    def _process_batches_hybrid(self, batches: List[List[str]], 
                               analysis_callback: Callable,
                               stats: Dict[str, Any]) -> Dict[str, BatchResult]:
        """æ··åˆç­–ç•¥æ‰¹æ¬¡å¤„ç† - ç»“åˆçº¿ç¨‹æ± å’Œå¼‚æ­¥"""
        logger.info("ğŸ­ ä½¿ç”¨æ··åˆç­–ç•¥å¤„ç†æ‰¹æ¬¡...")
        
        # å¯¹äºå°æ‰¹æ¬¡ä½¿ç”¨çº¿ç¨‹æ± ï¼Œå¤§æ‰¹æ¬¡ä½¿ç”¨å¼‚æ­¥
        small_batches = [b for b in batches if len(b) <= 10]
        large_batches = [b for b in batches if len(b) > 10]
        
        all_results = {}
        
        # å¤„ç†å°æ‰¹æ¬¡ï¼ˆçº¿ç¨‹æ± ï¼‰
        if small_batches:
            logger.info(f"ğŸ”„ çº¿ç¨‹æ± å¤„ç† {len(small_batches)} ä¸ªå°æ‰¹æ¬¡...")
            small_results = self._process_batches_threaded(small_batches, analysis_callback, stats)
            all_results.update(small_results)
        
        # å¤„ç†å¤§æ‰¹æ¬¡ï¼ˆå¼‚æ­¥ï¼‰
        if large_batches:
            logger.info(f"âš¡ å¼‚æ­¥å¤„ç† {len(large_batches)} ä¸ªå¤§æ‰¹æ¬¡...")
            large_results = self._process_batches_async(large_batches, analysis_callback, stats)
            all_results.update(large_results)
        
        return all_results
    
    def _process_batches_sequential(self, batches: List[List[str]], 
                                   analysis_callback: Callable,
                                   stats: Dict[str, Any]) -> Dict[str, BatchResult]:
        """é¡ºåºæ‰¹æ¬¡å¤„ç†"""
        all_results = {}
        
        for batch_idx, batch in enumerate(batches):
            try:
                batch_results = self._process_single_batch(batch, analysis_callback)
                all_results.update(batch_results)
                
                # æ›´æ–°ç»Ÿè®¡
                stats['processed'] += len(batch_results)
                stats['successful'] += sum(1 for r in batch_results.values() if r.success)
                stats['failed'] += sum(1 for r in batch_results.values() if not r.success)
                stats['batches_completed'] += 1
                
                if self.config.enable_progress_tracking:
                    self._log_progress(stats, len(batches))
                
            except Exception as e:
                logger.error(f"âŒ é¡ºåºæ‰¹æ¬¡ {batch_idx} å¤„ç†å¤±è´¥: {e}")
                stats['failed'] += len(batch)
        
        return all_results
    
    def _process_single_batch(self, batch: List[str], 
                             analysis_callback: Callable) -> Dict[str, BatchResult]:
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        batch_results = {}
        batch_start = time.time()
        
        logger.debug(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡: {len(batch)}åªè‚¡ç¥¨")
        
        for symbol in batch:
            result = self._analyze_single_stock(symbol, analysis_callback)
            batch_results[symbol] = result
        
        batch_time = time.time() - batch_start
        logger.debug(f"âœ… æ‰¹æ¬¡å®Œæˆ: {len(batch)}åªè‚¡ç¥¨, è€—æ—¶{batch_time:.1f}ç§’")
        
        return batch_results
    
    async def _async_process_single_batch(self, batch: List[str], 
                                        analysis_callback: Callable) -> Dict[str, BatchResult]:
        """å¼‚æ­¥å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        batch_results = {}
        
        tasks = []
        for symbol in batch:
            task = asyncio.create_task(self._async_analyze_single_stock(symbol, analysis_callback))
            tasks.append((symbol, task))
        
        for symbol, task in tasks:
            try:
                result = await task
                batch_results[symbol] = result
            except Exception as e:
                logger.error(f"âŒ å¼‚æ­¥åˆ†æ {symbol} å¤±è´¥: {e}")
                batch_results[symbol] = BatchResult(
                    symbol=symbol,
                    analysis_result={},
                    processing_time=0,
                    retry_count=0,
                    success=False,
                    error_message=str(e)
                )
        
        return batch_results
    
    def _analyze_single_stock(self, symbol: str, 
                             analysis_callback: Callable = None) -> BatchResult:
        """åˆ†æå•åªè‚¡ç¥¨"""
        start_time = time.time()
        retry_count = 0
        
        # æ£€æŸ¥ç¼“å­˜
        if self.config.cache_results and symbol in self._results_cache:
            cached_result = self._results_cache[symbol]
            logger.debug(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜ç»“æœ: {symbol}")
            return cached_result
        
        while retry_count <= self.config.max_retries:
            try:
                if analysis_callback:
                    # ä½¿ç”¨è‡ªå®šä¹‰åˆ†æå›è°ƒ
                    analysis_result = analysis_callback(symbol)
                else:
                    # ä½¿ç”¨å†…ç½®åˆ†æå¸ˆ
                    analysis_result = self._run_builtin_analysis(symbol)
                
                processing_time = time.time() - start_time
                result = BatchResult(
                    symbol=symbol,
                    analysis_result=analysis_result,
                    processing_time=processing_time,
                    retry_count=retry_count,
                    success=True,
                    analyst_results=analysis_result.get('analyst_results', {})
                )
                
                # ç¼“å­˜ç»“æœ
                if self.config.cache_results:
                    self._results_cache[symbol] = result
                
                return result
                
            except Exception as e:
                retry_count += 1
                error_msg = str(e)
                
                if retry_count <= self.config.max_retries:
                    logger.warning(f"âš ï¸ {symbol} åˆ†æå¤±è´¥ï¼Œé‡è¯• {retry_count}/{self.config.max_retries}: {error_msg}")
                    time.sleep(self.config.retry_delay * retry_count)  # æŒ‡æ•°é€€é¿
                else:
                    logger.error(f"âŒ {symbol} åˆ†ææœ€ç»ˆå¤±è´¥: {error_msg}")
                    
                    processing_time = time.time() - start_time
                    return BatchResult(
                        symbol=symbol,
                        analysis_result={},
                        processing_time=processing_time,
                        retry_count=retry_count - 1,
                        success=False,
                        error_message=error_msg
                    )
    
    async def _async_analyze_single_stock(self, symbol: str, 
                                        analysis_callback: Callable = None) -> BatchResult:
        """å¼‚æ­¥åˆ†æå•åªè‚¡ç¥¨"""
        # å¯¹äºå¼‚æ­¥ç‰ˆæœ¬ï¼Œä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥åˆ†æ
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None, 
            self._analyze_single_stock, 
            symbol, 
            analysis_callback
        )
    
    def _run_builtin_analysis(self, symbol: str) -> Dict[str, Any]:
        """è¿è¡Œå†…ç½®åˆ†æå¸ˆåˆ†æ"""
        analysis_result = {
            'symbol': symbol,
            'analysis_timestamp': datetime.now().isoformat(),
            'analyst_results': {},
            'combined_score': 0.0,
            'recommendation': 'HOLD',
            'social_signals': []  # æ·»åŠ ç¤¾äº¤ä¿¡å·åˆ—è¡¨
        }
        
        scores = {}  # ä½¿ç”¨å­—å…¸å­˜å‚¨å„ç»´åº¦åˆ†æ•°
        weights = {}  # å­˜å‚¨å„ç»´åº¦æƒé‡
        
        # åŸºæœ¬é¢åˆ†æ (æƒé‡30%)
        if 'fundamentals' in self.analysts:
            try:
                fund_result = self.analysts['fundamentals'].analyze(symbol)
                analysis_result['analyst_results']['fundamentals'] = fund_result
                if fund_result and 'score' in fund_result:
                    scores['fundamentals'] = fund_result['score']
                    weights['fundamentals'] = 0.30
            except Exception as e:
                logger.debug(f"âš ï¸ {symbol} åŸºæœ¬é¢åˆ†æå¤±è´¥: {e}")
        
        # æŠ€æœ¯é¢åˆ†æ (æƒé‡25%)
        if 'technical' in self.analysts:
            try:
                tech_result = self.analysts['technical'].analyze(symbol)
                analysis_result['analyst_results']['technical'] = tech_result
                if tech_result and 'score' in tech_result:
                    scores['technical'] = tech_result['score']
                    weights['technical'] = 0.25
            except Exception as e:
                logger.debug(f"âš ï¸ {symbol} æŠ€æœ¯é¢åˆ†æå¤±è´¥: {e}")
        
        # æ–°é—»åˆ†æ (æƒé‡20%)
        if 'news' in self.analysts:
            try:
                news_result = self.analysts['news'].analyze(symbol)
                analysis_result['analyst_results']['news'] = news_result
                if news_result and 'score' in news_result:
                    scores['news'] = news_result['score']
                    weights['news'] = 0.20
            except Exception as e:
                logger.debug(f"âš ï¸ {symbol} æ–°é—»åˆ†æå¤±è´¥: {e}")
        
        # é›ªçƒç¤¾äº¤æƒ…ç»ªåˆ†æ (æƒé‡20-25%)
        if self.config.enable_social and self.xueqiu_provider:
            try:
                # è·å–é›ªçƒæƒ…ç»ªæ•°æ®
                xueqiu_sentiment = self.xueqiu_provider.get_stock_sentiment(symbol, days=7)
                
                if xueqiu_sentiment and xueqiu_sentiment.get('total_discussions', 0) >= self.config.min_discussions:
                    # è®¡ç®—ç¤¾äº¤æƒ…ç»ªåˆ†æ•°
                    social_score = self._calculate_social_score(xueqiu_sentiment)
                    scores['social'] = social_score
                    weights['social'] = self.config.social_weight
                    
                    # ä¿å­˜åŸå§‹æ•°æ®
                    analysis_result['analyst_results']['social'] = {
                        'xueqiu_sentiment': xueqiu_sentiment,
                        'social_score': social_score,
                        'data_source': 'xueqiu'
                    }
                    
                    # ç”Ÿæˆç¤¾äº¤ä¿¡å·
                    social_signals = self._generate_social_signals(xueqiu_sentiment)
                    analysis_result['social_signals'] = social_signals
                    
                    logger.debug(f"ğŸ“± {symbol} ç¤¾äº¤æƒ…ç»ªåˆ†æ: è®¨è®ºæ•°={xueqiu_sentiment.get('total_discussions')}, æƒ…ç»ªåˆ†={social_score:.2f}")
                else:
                    logger.debug(f"âš ï¸ {symbol} è®¨è®ºæ•°é‡ä¸è¶³ï¼Œè·³è¿‡ç¤¾äº¤åˆ†æ")
                    
            except Exception as e:
                logger.debug(f"âš ï¸ {symbol} ç¤¾äº¤æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
        
        # è®¡ç®—åŠ æƒç»¼åˆè¯„åˆ†
        if scores:
            # å½’ä¸€åŒ–æƒé‡
            total_weight = sum(weights.values())
            if total_weight > 0:
                weighted_score = sum(scores[k] * weights[k] for k in scores) / total_weight
                analysis_result['combined_score'] = weighted_score
            else:
                # ç®€å•å¹³å‡
                analysis_result['combined_score'] = sum(scores.values()) / len(scores) if scores else 50
            
            # ç”Ÿæˆæ¨è
            if analysis_result['combined_score'] >= 70:
                analysis_result['recommendation'] = 'BUY'
            elif analysis_result['combined_score'] <= 30:
                analysis_result['recommendation'] = 'SELL'
            else:
                analysis_result['recommendation'] = 'HOLD'
            
            # å¦‚æœæœ‰å¼ºçƒˆçš„ç¤¾äº¤ä¿¡å·ï¼Œå¯èƒ½è°ƒæ•´æ¨è
            if 'HIGH_HEAT_WARNING' in analysis_result['social_signals']:
                if analysis_result['recommendation'] == 'BUY':
                    analysis_result['recommendation'] = 'HOLD'  # é™çº§ä¸ºæŒæœ‰
                    analysis_result['recommendation_note'] = 'ç¤¾äº¤çƒ­åº¦è¿‡é«˜ï¼Œå»ºè®®è°¨æ…'
            elif 'SENTIMENT_SURGE' in analysis_result['social_signals']:
                if analysis_result['recommendation'] == 'HOLD':
                    analysis_result['recommendation'] = 'BUY'  # å‡çº§ä¸ºä¹°å…¥
                    analysis_result['recommendation_note'] = 'æƒ…ç»ªç§¯æè½¬å˜ï¼Œå€¼å¾—å…³æ³¨'
        
        return analysis_result
    
    def _calculate_social_score(self, sentiment_data: Dict[str, Any]) -> float:
        """è®¡ç®—ç¤¾äº¤æƒ…ç»ªåˆ†æ•°"""
        score = 50.0  # åŸºç¡€åˆ†
        
        # æƒ…ç»ªå€¾å‘ (æƒé‡40%)
        sentiment_score = sentiment_data.get('sentiment_score', 0)
        if sentiment_score > self.config.sentiment_threshold:
            score += 20  # ç§¯ææƒ…ç»ª
        elif sentiment_score < -self.config.sentiment_threshold:
            score -= 20  # æ¶ˆææƒ…ç»ª
        else:
            score += sentiment_score * 20  # ä¸­æ€§æŒ‰æ¯”ä¾‹
        
        # è®¨è®ºçƒ­åº¦ (æƒé‡30%)
        discussions = sentiment_data.get('total_discussions', 0)
        if discussions > 100:
            score += 15  # é«˜çƒ­åº¦
        elif discussions > 50:
            score += 10  # ä¸­ç­‰çƒ­åº¦
        elif discussions > 20:
            score += 5   # ä¸€èˆ¬çƒ­åº¦
        
        # äº’åŠ¨ç¨‹åº¦ (æƒé‡20%)
        avg_interactions = sentiment_data.get('avg_interactions', 0)
        if avg_interactions > 50:
            score += 10
        elif avg_interactions > 20:
            score += 5
        
        # ç§¯ææ¯”ä¾‹ (æƒé‡10%)
        positive_ratio = sentiment_data.get('positive_ratio', 0)
        score += (positive_ratio - 0.5) * 20  # åç¦»ä¸­æ€§çš„ç¨‹åº¦
        
        return max(0, min(100, score))
    
    def _generate_social_signals(self, sentiment_data: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆç¤¾äº¤ä¿¡å·"""
        signals = []
        
        # çƒ­åº¦ä¿¡å·
        discussions = sentiment_data.get('total_discussions', 0)
        if discussions > 200:
            signals.append('EXTREME_HEAT')
        elif discussions > 100:
            signals.append('HIGH_HEAT')
        
        # æƒ…ç»ªä¿¡å·
        sentiment_score = sentiment_data.get('sentiment_score', 0)
        if sentiment_score > 0.5:
            signals.append('STRONG_BULLISH')
        elif sentiment_score > 0.3:
            signals.append('BULLISH')
        elif sentiment_score < -0.5:
            signals.append('STRONG_BEARISH')
        elif sentiment_score < -0.3:
            signals.append('BEARISH')
        
        # äº’åŠ¨ä¿¡å·
        avg_interactions = sentiment_data.get('avg_interactions', 0)
        if avg_interactions > 100:
            signals.append('HIGH_ENGAGEMENT')
        
        # é¢„è­¦ä¿¡å·
        if discussions > 300 and sentiment_score > 0.7:
            signals.append('HIGH_HEAT_WARNING')  # è¿‡çƒ­é¢„è­¦
        elif discussions > 50 and abs(sentiment_score) > 0.5:
            signals.append('SENTIMENT_SURGE')  # æƒ…ç»ªçªå˜
        
        return signals
    
    def _adjust_batch_config(self, total_stocks: int):
        """æ ¹æ®è‚¡ç¥¨æ•°é‡å’Œç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´æ‰¹æ¬¡é…ç½®"""
        # è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
        cpu_count = psutil.cpu_count()
        memory_gb = psutil.virtual_memory().total / (1024**3)
        
        # åŸºäºç³»ç»Ÿèµ„æºè°ƒæ•´å·¥ä½œçº¿ç¨‹æ•°
        optimal_workers = min(
            cpu_count * 2,  # CPUæ ¸å¿ƒæ•°çš„2å€
            int(memory_gb),  # æ¯GBå†…å­˜ä¸€ä¸ªçº¿ç¨‹
            total_stocks // 10,  # æ¯10åªè‚¡ç¥¨ä¸€ä¸ªçº¿ç¨‹
            32  # æœ€å¤§é™åˆ¶
        )
        
        if optimal_workers != self.config.max_workers:
            logger.info(f"ğŸ”§ è‡ªåŠ¨è°ƒæ•´å·¥ä½œçº¿ç¨‹: {self.config.max_workers} -> {optimal_workers}")
            self.config.max_workers = max(1, optimal_workers)
        
        # åŸºäºè‚¡ç¥¨æ•°é‡è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if total_stocks < 100:
            optimal_batch_size = 10
        elif total_stocks < 500:
            optimal_batch_size = 20
        elif total_stocks < 1000:
            optimal_batch_size = 30
        else:
            optimal_batch_size = 50
        
        if optimal_batch_size != self.config.batch_size:
            logger.info(f"ğŸ”§ è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°: {self.config.batch_size} -> {optimal_batch_size}")
            self.config.batch_size = optimal_batch_size
    
    def _log_progress(self, stats: Dict[str, Any], total_batches: int):
        """è®°å½•å¤„ç†è¿›åº¦"""
        elapsed_time = time.time() - stats['start_time']
        progress_pct = stats['batches_completed'] / total_batches * 100
        throughput = stats['successful'] / max(elapsed_time, 1)
        
        logger.info(f"ğŸ“ˆ æ‰¹æ¬¡è¿›åº¦: {stats['batches_completed']}/{total_batches} ({progress_pct:.1f}%) "
                   f"æˆåŠŸ:{stats['successful']} å¤±è´¥:{stats['failed']} "
                   f"ååé‡:{throughput:.1f}è‚¡ç¥¨/ç§’")
    
    def _monitor_memory(self):
        """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        while not self._stop_monitoring:
            try:
                memory_usage = self._get_memory_usage()
                if memory_usage > self.config.memory_threshold:
                    logger.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory_usage:.1f}% > {self.config.memory_threshold*100}%")
                    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
                
                time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                logger.error(f"âŒ å†…å­˜ç›‘æ§å¤±è´¥: {e}")
                break
    
    def _get_memory_usage(self) -> float:
        """è·å–å†…å­˜ä½¿ç”¨ç‡"""
        try:
            return psutil.virtual_memory().percent / 100.0
        except:
            return 0.0
    
    def __del__(self):
        """ææ„å‡½æ•°"""
        self._stop_monitoring = True
        if hasattr(self, '_memory_monitor') and self._memory_monitor.is_alive():
            self._memory_monitor.join(timeout=1)


# å…¨å±€æ‰¹å¤„ç†å™¨å®ä¾‹
_batch_processor = None

def get_batch_ai_processor(config: BatchConfig = None) -> BatchAIProcessor:
    """è·å–å…¨å±€æ‰¹å¤„ç†å™¨å®ä¾‹"""
    global _batch_processor
    if _batch_processor is None:
        _batch_processor = BatchAIProcessor(config)
    return _batch_processor