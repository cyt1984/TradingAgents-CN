#!/usr/bin/env python3
"""
Kimi K2 æ¨¡å‹é€‚é…å™¨
æ”¯æŒæœˆä¹‹æš—é¢ Kimi K2 æ¨¡å‹çš„é€‚é…å™¨å®ç°
"""

import os
import time
from typing import Any, Dict, List, Optional, Union
from langchain_core.messages import BaseMessage
from langchain_core.outputs import ChatResult
from langchain_core.callbacks import CallbackManagerForLLMRun

# å¯¼å…¥åŸºç±»
from .openai_compatible_base import OpenAICompatibleBase

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')

# å¯¼å…¥tokenè·Ÿè¸ªå™¨
try:
    from tradingagents.config.config_manager import token_tracker
    TOKEN_TRACKING_ENABLED = True
except ImportError:
    TOKEN_TRACKING_ENABLED = False


class ChatKimi(OpenAICompatibleBase):
    """
    Kimi K2 æ¨¡å‹é€‚é…å™¨
    åŸºäº OpenAI å…¼å®¹æ¥å£å®ç°
    """
    
    def __init__(
        self,
        model: str = "moonshot-v1-8k",
        api_key: Optional[str] = None,
        base_url: str = "https://api.moonshot.cn/v1",
        temperature: float = 0.1,
        max_tokens: Optional[int] = 4096,
        **kwargs
    ):
        """
        åˆå§‹åŒ– Kimi K2 é€‚é…å™¨
        
        Args:
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "moonshot-v1-8k"
            api_key: APIå¯†é’¥ï¼Œå¦‚ä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡ KIMI_API_KEY è·å–
            base_url: APIåŸºç¡€URL
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            **kwargs: å…¶ä»–å‚æ•°
        """
        
        # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        if api_key is None:
            api_key = os.getenv("KIMI_API_KEY")
            if not api_key:
                raise ValueError(
                    "Kimi APIå¯†é’¥æœªæä¾›ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ KIMI_API_KEY æˆ–åœ¨åˆå§‹åŒ–æ—¶æä¾› api_key å‚æ•°ã€‚"
                )
        
        # è°ƒç”¨åŸºç±»åˆå§‹åŒ–
        super().__init__(
            provider_name="kimi",
            model=model,
            api_key_env_var="KIMI_API_KEY",
            base_url=base_url,
            api_key=api_key,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs
        )
        
        # Kimiç‰¹å®šé…ç½®
        self.supports_system_message = True
        self.supports_function_calling = True
        self.context_window = 200000  # Kimi K2 æ”¯æŒ20ä¸‡tokenä¸Šä¸‹æ–‡
        self.max_output_tokens = max_tokens or 4096
        
        logger.info(f"[SUCCESS] Kimi K2 adapter initialized successfully")
        logger.info(f"   Model: {self.model_name}")
        logger.info(f"   Base URL: {self.openai_api_base}")
        logger.info(f"   Context window: {self.context_window:,} tokens")
    
    def _create_chat_result(self, response: Any) -> ChatResult:
        """
        åˆ›å»ºèŠå¤©ç»“æœï¼ŒåŒ…å«tokenä½¿ç”¨ç»Ÿè®¡
        """
        try:
            result = super()._create_chat_result(response)
            
            # è®°å½•tokenä½¿ç”¨æƒ…å†µ
            if TOKEN_TRACKING_ENABLED and hasattr(response, 'usage'):
                usage = response.usage
                input_tokens = getattr(usage, 'prompt_tokens', 0)
                output_tokens = getattr(usage, 'completion_tokens', 0)
                total_tokens = getattr(usage, 'total_tokens', input_tokens + output_tokens)
                
                # è®°å½•åˆ°tokenè·Ÿè¸ªå™¨
                token_tracker.record_usage(
                    provider="Kimi",
                    model=self.model_name,
                    input_tokens=input_tokens,
                    output_tokens=output_tokens,
                    total_tokens=total_tokens
                )
                
                logger.debug(f"Kimi token usage: input={input_tokens}, output={output_tokens}, total={total_tokens}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºKimièŠå¤©ç»“æœå¤±è´¥: {e}")
            raise
    
    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> ChatResult:
        """
        ç”ŸæˆèŠå¤©å›å¤
        """
        start_time = time.time()
        
        try:
            logger.debug(f"ğŸš€ å¼€å§‹Kimi K2ç”Ÿæˆï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
            
            # è°ƒç”¨åŸºç±»æ–¹æ³•
            result = super()._generate(messages, stop, run_manager, **kwargs)
            
            end_time = time.time()
            generation_time = end_time - start_time
            
            logger.info(f"âœ… Kimi K2ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {generation_time:.2f}ç§’")
            
            return result
            
        except Exception as e:
            end_time = time.time()
            generation_time = end_time - start_time
            
            logger.error(f"âŒ Kimi K2ç”Ÿæˆå¤±è´¥ï¼Œè€—æ—¶: {generation_time:.2f}ç§’ï¼Œé”™è¯¯: {e}")
            raise
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        """
        return {
            "provider": "kimi",
            "model": self.model_name,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "context_window": self.context_window,
            "supports_function_calling": self.supports_function_calling,
            "supports_system_message": self.supports_system_message,
            "base_url": str(getattr(self, 'openai_api_base', getattr(self, 'base_url', 'https://api.moonshot.cn/v1')))
        }
    
    @classmethod
    def get_available_models(cls) -> List[str]:
        """
        è·å–å¯ç”¨çš„ Kimi æ¨¡å‹åˆ—è¡¨
        """
        return [
            "moonshot-v1-8k",          # Kimi 8Kä¸Šä¸‹æ–‡ç‰ˆæœ¬
            "moonshot-v1-32k",         # Kimi 32Kä¸Šä¸‹æ–‡ç‰ˆæœ¬
            "moonshot-v1-128k",        # Kimi 128Kä¸Šä¸‹æ–‡ç‰ˆæœ¬
            "kimi-k2-0711-preview",    # Kimi K2 0711é¢„è§ˆç‰ˆ
            "kimi-k2-turbo-preview"    # Kimi K2 Turboé¢„è§ˆç‰ˆ
        ]
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """
        ä¼°ç®—ä½¿ç”¨æˆæœ¬ï¼ˆäººæ°‘å¸ï¼‰
        åŸºäº Kimi çš„å®šä»·ç­–ç•¥
        """
        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®ä¸åŒçš„å®šä»·
        model_pricing = {
            "moonshot-v1-8k": {"input": 0.012, "output": 0.012},
            "moonshot-v1-32k": {"input": 0.024, "output": 0.024},
            "moonshot-v1-128k": {"input": 0.06, "output": 0.06},
            "kimi-k2-0711-preview": {"input": 0.06, "output": 0.06},
            "kimi-k2-turbo-preview": {"input": 0.03, "output": 0.03}
        }
        
        # è·å–å½“å‰æ¨¡å‹çš„å®šä»·
        pricing = model_pricing.get(self.model_name, {"input": 0.01, "output": 0.03})
        
        input_cost = (input_tokens / 1000) * pricing["input"]
        output_cost = (output_tokens / 1000) * pricing["output"]
        total_cost = input_cost + output_cost
        
        return total_cost


def create_kimi_adapter(
    model: str = "moonshot-v1-8k",
    temperature: float = 0.1,
    max_tokens: Optional[int] = 4096,
    **kwargs
) -> ChatKimi:
    """
    åˆ›å»º Kimi é€‚é…å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        model: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        ChatKimi: Kimié€‚é…å™¨å®ä¾‹
    """
    return ChatKimi(
        model=model,
        temperature=temperature,
        max_tokens=max_tokens,
        **kwargs
    )


# ä¸ºäº†å…¼å®¹æ€§ï¼Œæä¾›å¤šä¸ªåˆ«å
ChatMoonshot = ChatKimi  # æœˆä¹‹æš—é¢åˆ«å
create_moonshot_adapter = create_kimi_adapter  # æœˆä¹‹æš—é¢åˆ«å


def get_kimi_adapter(
    model: str = "moonshot-v1-8k",
    temperature: float = 0.1,
    max_tokens: Optional[int] = 4096
) -> ChatKimi:
    """
    è·å– Kimi é€‚é…å™¨å®ä¾‹
    
    Args:
        model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "moonshot-v1-8k"
        temperature: æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ 0.1
        max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°ï¼Œé»˜è®¤ 4096
    
    Returns:
        ChatKimi: Kimié€‚é…å™¨å®ä¾‹
    """
    try:
        adapter = create_kimi_adapter(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        logger.info(f"âœ… Kimié€‚é…å™¨åˆ›å»ºæˆåŠŸ: {model}")
        return adapter
        
    except Exception as e:
        logger.error(f"âŒ Kimié€‚é…å™¨åˆ›å»ºå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    try:
        # åˆ›å»ºé€‚é…å™¨
        kimi = create_kimi_adapter()
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        info = kimi.get_model_info()
        print("Kimi æ¨¡å‹ä¿¡æ¯:")
        for key, value in info.items():
            print(f"  {key}: {value}")
        
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        models = kimi.get_available_models()
        print(f"\nå¯ç”¨æ¨¡å‹: {', '.join(models)}")
        
        # æˆæœ¬ä¼°ç®—ç¤ºä¾‹
        cost = kimi.estimate_cost(1000, 500)
        print(f"\næˆæœ¬ä¼°ç®— (1000è¾“å…¥+500è¾“å‡ºtokens): Â¥{cost:.4f}")
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")