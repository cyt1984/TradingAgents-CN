#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å½“å‰å¯ç”¨çš„AIæ¨¡å‹
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_available_ai_models():
    """æµ‹è¯•å½“å‰å¯ç”¨çš„AIæ¨¡å‹"""
    print("æ£€æŸ¥å½“å‰å¯ç”¨çš„AIæ¨¡å‹...")
    print("=" * 60)
    
    try:
        from tradingagents.llm_adapters.dynamic_llm_manager import get_llm_manager
        
        # è·å–LLMç®¡ç†å™¨
        llm_manager = get_llm_manager()
        
        # è·å–æ‰€æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬æœªå¯ç”¨çš„ï¼‰
        all_models = llm_manager.get_available_models()
        print(f"æ‰€æœ‰é…ç½®çš„æ¨¡å‹æ•°é‡: {len(all_models)}")
        
        # è·å–å·²å¯ç”¨çš„æ¨¡å‹
        enabled_models = llm_manager.get_enabled_models()
        print(f"å·²å¯ç”¨çš„æ¨¡å‹æ•°é‡: {len(enabled_models)}")
        print()
        
        # æŒ‰ä¾›åº”å•†åˆ†ç»„æ˜¾ç¤º
        providers = {}
        for model_key, model_info in all_models.items():
            provider = model_info.get('provider', 'unknown')
            if provider not in providers:
                providers[provider] = []
            providers[provider].append((model_key, model_info))
        
        # æ˜¾ç¤ºå„ä¾›åº”å•†çš„æ¨¡å‹
        for provider, models in providers.items():
            print(f"ğŸ“± {provider.upper()} ä¾›åº”å•†:")
            
            for model_key, model_info in models:
                display_name = model_info.get('display_name', model_info.get('model_name', 'N/A'))
                enabled = model_info.get('enabled', False)
                has_key = model_info.get('has_api_key', False)
                
                # çŠ¶æ€æŒ‡ç¤º
                if enabled and has_key:
                    status = "å¯ç”¨"
                    icon = "âœ…"
                elif has_key:
                    status = "æœ‰å¯†é’¥ä½†æœªå¯ç”¨"
                    icon = "ğŸ”§"
                else:
                    status = "æœªé…ç½®APIå¯†é’¥"
                    icon = "âŒ"
                
                print(f"  {icon} {display_name} ({model_info.get('model_name', 'N/A')}) - {status}")
                
                if model_info.get('description'):
                    print(f"     æè¿°: {model_info.get('description')}")
            print()
        
        # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
        current_config = llm_manager.get_current_config()
        if current_config:
            print(f"ğŸ¯ å½“å‰ä½¿ç”¨çš„æ¨¡å‹:")
            print(f"   ä¾›åº”å•†: {current_config.provider}")
            print(f"   æ¨¡å‹å: {current_config.model_name}")
            print(f"   æ˜¾ç¤ºå: {current_config.display_name}")
        else:
            print("âš ï¸ å½“å‰æœªè®¾ç½®é»˜è®¤æ¨¡å‹")
        
        print("\n" + "=" * 60)
        print("ç»“è®º:")
        if len(enabled_models) > 1:
            print(f"  âœ… ç³»ç»Ÿå·²é…ç½® {len(enabled_models)} ä¸ªå¯ç”¨æ¨¡å‹")
            print("  ğŸ” å¦‚æœæ™ºèƒ½é€‰è‚¡ç•Œé¢åªæ˜¾ç¤ºOpenAIæ¨¡å‹ï¼Œå¯èƒ½æ˜¯Webç•Œé¢æ˜¾ç¤ºé—®é¢˜")
        else:
            print(f"  âš ï¸ åªæœ‰ {len(enabled_models)} ä¸ªå¯ç”¨æ¨¡å‹")
            print("  ğŸ’¡ è¯·æ£€æŸ¥å…¶ä»–ä¾›åº”å•†çš„APIå¯†é’¥é…ç½®")
        
        return True
        
    except Exception as e:
        print(f"æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_available_ai_models()
    sys.exit(0 if success else 1)