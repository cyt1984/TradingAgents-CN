#!/usr/bin/env python3
"""
é˜¶æ®µ2 AIå¢å¼ºé€‰è‚¡ç³»ç»Ÿé›†æˆæµ‹è¯•
æµ‹è¯•AIä¸“å®¶å§”å‘˜ä¼šã€æ¨¡å¼è¯†åˆ«ã€è‡ªé€‚åº”å¼•æ“å’Œç›¸ä¼¼æ€§æ¨èçš„é›†æˆåŠŸèƒ½
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from datetime import datetime, timedelta
from typing import Dict, List, Any
import json

# å¯¼å…¥AIå¢å¼ºé€‰è‚¡æ¨¡å—
from tradingagents.selectors.ai_strategies.expert_committee import AIExpertCommittee, ExpertAnalysisResult
from tradingagents.selectors.ai_strategies.pattern_recognizer import PatternRecognizer, PatternType
from tradingagents.selectors.ai_strategies.adaptive_engine import AdaptiveEngine, MarketRegime, StrategyType
from tradingagents.selectors.ai_strategies.similarity_engine import SimilarityEngine, SimilarityDimension

# å¯¼å…¥åŸºç¡€é€‰è‚¡æ¨¡å—
from tradingagents.selectors.stock_selector import StockSelector
from tradingagents.selectors.filter_conditions import SelectionCriteria, NumericFilter, FilterOperator

# å¯¼å…¥å·¥å…·å’Œé…ç½®
from tradingagents.utils.logging_manager import get_logger

logger = get_logger('agents')


def create_test_stock_data() -> List[Dict[str, Any]]:
    """åˆ›å»ºæµ‹è¯•è‚¡ç¥¨æ•°æ®"""
    return [
        {
            'symbol': '000001',
            'name': 'å¹³å®‰é“¶è¡Œ',
            'current_price': 12.50,
            'change_pct': 2.5,
            'volume': 150000000,
            'turnover': 1875000000,
            'market_cap': 24150000000,
            'pe_ratio': 5.2,
            'pb_ratio': 0.65,
            'roe': 0.12,
            'roa': 0.008,
            'debt_ratio': 0.9,
            'revenue_growth': 0.08,
            'profit_growth': 0.15,
            'industry': 'é‡‘èé“¶è¡Œ',
            'score': 78.5,
            'technical_score': 72,
            'fundamental_score': 85,
            'sentiment_score': 68,
            'quality_score': 80,
            'risk_level': 0.4,
            'volatility': 0.25
        },
        {
            'symbol': '000002',
            'name': 'ä¸‡ç§‘A',
            'current_price': 15.80,
            'change_pct': -1.2,
            'volume': 85000000,
            'turnover': 1343000000,
            'market_cap': 175000000000,
            'pe_ratio': 8.5,
            'pb_ratio': 1.2,
            'roe': 0.15,
            'roa': 0.05,
            'debt_ratio': 0.75,
            'revenue_growth': -0.05,
            'profit_growth': -0.12,
            'industry': 'æˆ¿åœ°äº§',
            'score': 65.2,
            'technical_score': 58,
            'fundamental_score': 70,
            'sentiment_score': 55,
            'quality_score': 75,
            'risk_level': 0.6,
            'volatility': 0.32
        },
        {
            'symbol': '000858',
            'name': 'äº”ç²®æ¶²',
            'current_price': 168.50,
            'change_pct': 3.8,
            'volume': 12000000,
            'turnover': 2022000000,
            'market_cap': 650000000000,
            'pe_ratio': 25.6,
            'pb_ratio': 5.8,
            'roe': 0.22,
            'roa': 0.15,
            'debt_ratio': 0.35,
            'revenue_growth': 0.12,
            'profit_growth': 0.18,
            'industry': 'é£Ÿå“é¥®æ–™',
            'score': 85.3,
            'technical_score': 88,
            'fundamental_score': 90,
            'sentiment_score': 82,
            'quality_score': 85,
            'risk_level': 0.3,
            'volatility': 0.28
        },
        {
            'symbol': '002027',
            'name': 'åˆ†ä¼—ä¼ åª’',
            'current_price': 6.85,
            'change_pct': 5.2,
            'volume': 185000000,
            'turnover': 1267250000,
            'market_cap': 95000000000,
            'pe_ratio': 18.5,
            'pb_ratio': 2.1,
            'roe': 0.18,
            'roa': 0.12,
            'debt_ratio': 0.25,
            'revenue_growth': 0.25,
            'profit_growth': 0.35,
            'industry': 'ä¼ åª’å¹¿å‘Š',
            'score': 82.7,
            'technical_score': 85,
            'fundamental_score': 82,
            'sentiment_score': 88,
            'quality_score': 78,
            'risk_level': 0.5,
            'volatility': 0.35
        },
        {
            'symbol': '600036',
            'name': 'æ‹›å•†é“¶è¡Œ',
            'current_price': 42.30,
            'change_pct': 1.8,
            'volume': 25000000,
            'turnover': 1057500000,
            'market_cap': 1080000000000,
            'pe_ratio': 6.8,
            'pb_ratio': 1.1,
            'roe': 0.16,
            'roa': 0.012,
            'debt_ratio': 0.88,
            'revenue_growth': 0.10,
            'profit_growth': 0.12,
            'industry': 'é‡‘èé“¶è¡Œ',
            'score': 88.2,
            'technical_score': 82,
            'fundamental_score': 92,
            'sentiment_score': 85,
            'quality_score': 90,
            'risk_level': 0.3,
            'volatility': 0.22
        },
        {
            'symbol': '600519',
            'name': 'è´µå·èŒ…å°',
            'current_price': 1680.00,
            'change_pct': 2.1,
            'volume': 2500000,
            'turnover': 4200000000,
            'market_cap': 2100000000000,
            'pe_ratio': 32.5,
            'pb_ratio': 8.2,
            'roe': 0.28,
            'roa': 0.20,
            'debt_ratio': 0.15,
            'revenue_growth': 0.15,
            'profit_growth': 0.18,
            'industry': 'é£Ÿå“é¥®æ–™',
            'score': 92.8,
            'technical_score': 90,
            'fundamental_score': 95,
            'sentiment_score': 92,
            'quality_score': 95,
            'risk_level': 0.2,
            'volatility': 0.25
        }
    ]


def create_test_price_data(symbol: str) -> List[Dict[str, Any]]:
    """åˆ›å»ºæµ‹è¯•ä»·æ ¼å†å²æ•°æ®"""
    base_price = {
        '000001': 12.00,
        '000002': 16.00,
        '000858': 160.00,
        '002027': 6.50,
        '600036': 41.00,
        '600519': 1650.00
    }.get(symbol, 50.0)
    
    price_data = []
    current_price = base_price
    
    # ç”Ÿæˆ30å¤©çš„ä»·æ ¼æ•°æ®
    for i in range(30):
        # ç®€å•çš„éšæœºæ³¢åŠ¨
        change = (hash(f"{symbol}_{i}") % 200 - 100) / 10000  # -1% to +1%
        current_price *= (1 + change)
        
        price_data.append({
            'date': (datetime.now() - timedelta(days=29-i)).strftime('%Y-%m-%d'),
            'open': current_price * 0.999,
            'high': current_price * 1.015,
            'low': current_price * 0.985,
            'close': current_price,
            'volume': 50000000 + (hash(f"{symbol}_vol_{i}") % 100000000)
        })
    
    return price_data


def create_test_market_data() -> Dict[str, Any]:
    """åˆ›å»ºæµ‹è¯•å¸‚åœºæ•°æ®"""
    return {
        'index_name': 'ä¸Šè¯æŒ‡æ•°',
        'current_value': 3250.5,
        'change_pct': 1.2,
        'price_data': [
            {'date': (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d'),
             'close': 3200 + i * 2 + (hash(f"market_{i}") % 100 - 50),
             'volume': 400000000000 + (hash(f"market_vol_{i}") % 100000000000)}
            for i in range(30)
        ]
    }


def create_test_news_data() -> List[Dict[str, Any]]:
    """åˆ›å»ºæµ‹è¯•æ–°é—»æ•°æ®"""
    return [
        {
            'title': 'å¤®è¡Œå®£å¸ƒé™å‡†0.5ä¸ªç™¾åˆ†ç‚¹ï¼Œé‡Šæ”¾æµåŠ¨æ€§çº¦1ä¸‡äº¿å…ƒ',
            'content': 'ä¸­å›½äººæ°‘é“¶è¡Œå†³å®šä¸‹è°ƒé‡‘èæœºæ„å­˜æ¬¾å‡†å¤‡é‡‘ç‡0.5ä¸ªç™¾åˆ†ç‚¹ï¼Œé‡Šæ”¾é•¿æœŸæµåŠ¨æ€§çº¦1ä¸‡äº¿å…ƒ...',
            'source': 'æ–°åç¤¾',
            'sentiment': 0.7,
            'timestamp': datetime.now() - timedelta(hours=2)
        },
        {
            'title': 'ç§‘æŠ€è‚¡é›†ä½“ä¸Šæ¶¨ï¼Œäººå·¥æ™ºèƒ½æ¿å—é¢†æ¶¨',
            'content': 'ä»Šæ—¥Aè‚¡å¸‚åœºç§‘æŠ€è‚¡è¡¨ç°å¼ºåŠ²ï¼Œäººå·¥æ™ºèƒ½ã€èŠ¯ç‰‡ã€æ–°èƒ½æºç­‰æ¿å—å‡æœ‰ä¸é”™æ¶¨å¹…...',
            'source': 'è´¢è”ç¤¾',
            'sentiment': 0.8,
            'timestamp': datetime.now() - timedelta(hours=4)
        },
        {
            'title': 'æˆ¿åœ°äº§æ”¿ç­–è¾¹é™…æ”¾æ¾ï¼Œå¤šåœ°è°ƒæ•´é™è´­æ”¿ç­–',
            'content': 'è¿‘æœŸå¤šä¸ªåŸå¸‚ç›¸ç»§è°ƒæ•´æˆ¿åœ°äº§é™è´­æ”¿ç­–ï¼Œå¸‚åœºé¢„æœŸæ”¿ç­–å°†è¿›ä¸€æ­¥ä¼˜åŒ–...',
            'source': 'è¯åˆ¸æ—¶æŠ¥',
            'sentiment': 0.6,
            'timestamp': datetime.now() - timedelta(hours=6)
        }
    ]


def test_ai_expert_committee():
    """æµ‹è¯•AIä¸“å®¶å§”å‘˜ä¼šåŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ¤– æµ‹è¯•AIä¸“å®¶å§”å‘˜ä¼š")
    print("="*50)
    
    try:
        # åˆå§‹åŒ–ä¸“å®¶å§”å‘˜ä¼š
        committee = AIExpertCommittee()
        
        # æµ‹è¯•æ•°æ®
        test_symbol = '002027'
        stock_data = {
            'tushare': create_test_stock_data()[3],  # åˆ†ä¼—ä¼ åª’æ•°æ®
            'akshare': create_test_stock_data()[3]
        }
        news_data = create_test_news_data()
        
        # æ‰§è¡Œä¸“å®¶å§”å‘˜ä¼šåˆ†æ
        print(f"åˆ†æè‚¡ç¥¨: {test_symbol}")
        result = committee.analyze_stock_committee(test_symbol, stock_data, news_data)
        
        # è¾“å‡ºç»“æœ
        print(f"âœ… ä¸“å®¶å§”å‘˜ä¼šåˆ†æå®Œæˆ")
        print(f"   è‚¡ç¥¨ä»£ç : {result['symbol']}")
        print(f"   å§”å‘˜ä¼šå†³ç­–: {result['committee_decision']['recommendation']}")
        print(f"   ç»¼åˆè¯„åˆ†: {result['committee_decision']['score']}")
        print(f"   ç½®ä¿¡åº¦: {result['committee_decision']['confidence']:.3f}")
        print(f"   ä¸€è‡´æ€§æ°´å¹³: {result['committee_decision']['consensus_level']}")
        print(f"   å‚ä¸ä¸“å®¶æ•°: {len(result['expert_analyses'])}")
        print(f"   å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
        
        # æ˜¾ç¤ºä¸“å®¶åˆ†æç»“æœ
        if result['expert_analyses']:
            print("\nğŸ“Š ä¸“å®¶åˆ†æç»“æœ:")
            for expert_name, analysis in result['expert_analyses'].items():
                if hasattr(analysis, 'score'):
                    print(f"   {expert_name}: è¯„åˆ†={analysis.score:.1f}, ç½®ä¿¡åº¦={analysis.confidence:.3f}, å»ºè®®={analysis.recommendation}")
        
        # æ˜¾ç¤ºæœ€ç»ˆæ¨è
        final_rec = result['final_recommendation']
        print(f"\nğŸ¯ æœ€ç»ˆæ¨è:")
        print(f"   æ“ä½œå»ºè®®: {final_rec['action']}")
        print(f"   ç½®ä¿¡æ°´å¹³: {final_rec['confidence_level']:.3f}")
        print(f"   é£é™©è¯„ä¼°: {final_rec['risk_assessment']}")
        print(f"   å»ºè®®ä»“ä½: {final_rec['suggested_allocation']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ AIä¸“å®¶å§”å‘˜ä¼šæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_pattern_recognizer():
    """æµ‹è¯•æ¨¡å¼è¯†åˆ«åŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ” æµ‹è¯•æ¨¡å¼è¯†åˆ«å¼•æ“")
    print("="*50)
    
    try:
        # åˆå§‹åŒ–æ¨¡å¼è¯†åˆ«å¼•æ“
        recognizer = PatternRecognizer()
        
        # æµ‹è¯•æ•°æ®
        test_symbol = '000858'
        price_data = create_test_price_data(test_symbol)
        volume_data = [p['volume'] for p in price_data]
        
        # æ‰§è¡Œæ¨¡å¼è¯†åˆ«
        print(f"è¯†åˆ«è‚¡ç¥¨æ¨¡å¼: {test_symbol}")
        patterns = recognizer.recognize_patterns(test_symbol, price_data, volume_data)
        
        # è¾“å‡ºç»“æœ
        print(f"âœ… æ¨¡å¼è¯†åˆ«å®Œæˆ")
        print(f"   å‘ç°æ¨¡å¼æ•°é‡: {len(patterns)}")
        
        if patterns:
            print("\nğŸ“ˆ è¯†åˆ«åˆ°çš„æ¨¡å¼:")
            for i, pattern in enumerate(patterns, 1):
                print(f"   {i}. {pattern.pattern_type.value}")
                print(f"      å¼ºåº¦: {pattern.strength:.1f}")
                print(f"      ç½®ä¿¡åº¦: {pattern.confidence:.3f}")
                print(f"      æŒç»­å¤©æ•°: {pattern.duration_days}")
                print(f"      æè¿°: {pattern.description}")
                print(f"      é¢„æœŸæ–¹å‘: {pattern.expected_direction}")
                print(f"      é£é™©çº§åˆ«: {pattern.risk_level}")
                
                # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                if pattern.key_metrics:
                    print(f"      å…³é”®æŒ‡æ ‡: {json.dumps(pattern.key_metrics, indent=8, ensure_ascii=False)}")
                print()
        
        # æµ‹è¯•æ¨¡å¼é¢„æµ‹
        if patterns:
            prediction = recognizer.predict_next_patterns(test_symbol, patterns)
            print(f"ğŸ”® æ¨¡å¼é¢„æµ‹:")
            print(f"   é¢„æµ‹æ–¹å‘: {prediction['prediction']}")
            print(f"   é¢„æµ‹ç½®ä¿¡åº¦: {prediction['confidence']:.3f}")
            print(f"   åŸºäºæ¨¡å¼: {prediction['based_on_pattern']}")
            print(f"   æ—¶é—´èŒƒå›´: {prediction['time_horizon']}å¤©")
            print(f"   é£é™©çº§åˆ«: {prediction['risk_level']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å¼è¯†åˆ«æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_adaptive_engine():
    """æµ‹è¯•è‡ªé€‚åº”å¼•æ“åŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸŒ¡ï¸ æµ‹è¯•è‡ªé€‚åº”é€‰è‚¡å¼•æ“")
    print("="*50)
    
    try:
        # åˆå§‹åŒ–è‡ªé€‚åº”å¼•æ“
        adaptive_engine = AdaptiveEngine()
        
        # æµ‹è¯•æ•°æ®
        market_data = create_test_market_data()
        stock_candidates = create_test_stock_data()
        
        # æµ‹è¯•å¸‚åœºç¯å¢ƒæ£€æµ‹
        print("æ£€æµ‹å¸‚åœºç¯å¢ƒ...")
        market_regime = adaptive_engine.detect_market_regime(market_data)
        print(f"âœ… å¸‚åœºç¯å¢ƒæ£€æµ‹å®Œæˆ: {market_regime.value}")
        
        # é€‰æ‹©æœ€ä¼˜ç­–ç•¥
        print("é€‰æ‹©æœ€ä¼˜ç­–ç•¥...")
        optimal_strategy = adaptive_engine.select_optimal_strategy(market_regime)
        print(f"âœ… ç­–ç•¥é€‰æ‹©å®Œæˆ: {optimal_strategy.strategy_type.value}")
        print(f"   é¢„æœŸæ”¶ç›Š: {optimal_strategy.expected_performance:.2%}")
        print(f"   å†å²å‡†ç¡®ç‡: {optimal_strategy.historical_accuracy:.2%}")
        print(f"   é£é™©æ‰¿å—åº¦: {optimal_strategy.risk_tolerance:.2%}")
        print(f"   ç½®ä¿¡åº¦è¦æ±‚: {optimal_strategy.confidence_threshold:.2%}")
        
        # è·å–è‡ªé€‚åº”æ¨è
        print("ç”Ÿæˆè‡ªé€‚åº”æ¨è...")
        recommendations = adaptive_engine.get_adaptive_recommendations(market_data, stock_candidates)
        
        print(f"âœ… è‡ªé€‚åº”æ¨èå®Œæˆ")
        print(f"   å¸‚åœºç¯å¢ƒ: {recommendations['market_regime']}")
        print(f"   é€‰å®šç­–ç•¥: {recommendations['selected_strategy']['type']}")
        print(f"   æ¨èè‚¡ç¥¨æ•°: {len(recommendations['recommended_stocks'])}")
        print(f"   æ€»å€™é€‰æ•°: {recommendations['adaptation_metrics']['total_candidates']}")
        print(f"   ç­›é€‰åæ•°: {recommendations['adaptation_metrics']['filtered_candidates']}")
        print(f"   ç­–ç•¥å‡†ç¡®ç‡: {recommendations['adaptation_metrics']['strategy_accuracy']:.2%}")
        
        # æ˜¾ç¤ºæ¨èè‚¡ç¥¨
        if recommendations['recommended_stocks']:
            print("\nğŸ¯ æ¨èè‚¡ç¥¨ (å‰5å):")
            for i, stock in enumerate(recommendations['recommended_stocks'][:5], 1):
                print(f"   {i}. {stock['symbol']} - {stock.get('name', 'N/A')}")
                print(f"      è‡ªé€‚åº”è¯„åˆ†: {stock.get('adaptive_score', 0):.1f}")
                print(f"      åŸºç¡€è¯„åˆ†: {stock.get('score', 0):.1f}")
                print(f"      é£é™©çº§åˆ«: {stock.get('risk_level', 0):.2f}")
        
        # æ˜¾ç¤ºé£é™©è¯„ä¼°
        risk_assessment = recommendations['risk_assessment']
        print(f"\nâš ï¸ é£é™©è¯„ä¼°:")
        print(f"   æ•´ä½“é£é™©: {risk_assessment['overall_risk']}")
        print(f"   å¹³å‡é£é™©è¯„åˆ†: {risk_assessment['average_risk_score']}")
        print(f"   å¹³å‡æ³¢åŠ¨ç‡: {risk_assessment['average_volatility']:.2%}")
        
        # æ˜¾ç¤ºç­–ç•¥æ¨ç†
        print(f"\nğŸ’¡ ç­–ç•¥æ¨ç†:")
        reasoning = recommendations['strategy_reasoning']
        print(reasoning[:500] + "..." if len(reasoning) > 500 else reasoning)
        
        return True
        
    except Exception as e:
        print(f"âŒ è‡ªé€‚åº”å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_similarity_engine():
    """æµ‹è¯•ç›¸ä¼¼æ€§å¼•æ“åŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ”— æµ‹è¯•ç›¸ä¼¼è‚¡ç¥¨æ¨èå¼•æ“")
    print("="*50)
    
    try:
        # åˆå§‹åŒ–ç›¸ä¼¼æ€§å¼•æ“
        similarity_engine = SimilarityEngine()
        
        # æµ‹è¯•æ•°æ®
        target_symbol = '600036'  # æ‹›å•†é“¶è¡Œ
        target_data = create_test_stock_data()[4]
        candidate_stocks = create_test_stock_data()
        
        # å¯»æ‰¾ç›¸ä¼¼è‚¡ç¥¨
        print(f"å¯»æ‰¾ä¸ {target_symbol} ç›¸ä¼¼çš„è‚¡ç¥¨...")
        similarities = similarity_engine.find_similar_stocks(
            target_symbol, target_data, candidate_stocks, top_k=5
        )
        
        print(f"âœ… ç›¸ä¼¼è‚¡ç¥¨æŸ¥æ‰¾å®Œæˆ")
        print(f"   ç›®æ ‡è‚¡ç¥¨: {target_symbol} - {target_data['name']}")
        print(f"   å‘ç°ç›¸ä¼¼è‚¡ç¥¨: {len(similarities)}")
        
        # æ˜¾ç¤ºç›¸ä¼¼è‚¡ç¥¨
        if similarities:
            print("\nğŸ¯ ç›¸ä¼¼è‚¡ç¥¨æ¨è:")
            for i, sim in enumerate(similarities, 1):
                print(f"   {i}. {sim.similar_symbol}")
                print(f"      ç»¼åˆç›¸ä¼¼åº¦: {sim.overall_similarity:.3f}")
                print(f"      æ¨èå¼ºåº¦: {sim.recommendation_strength:.3f}")
                print(f"      é£é™©å·®å¼‚: {sim.risk_differential:.3f}")
                print(f"      é¢„æœŸç›¸å…³æ€§: {sim.expected_correlation:.3f}")
                
                # æ˜¾ç¤ºåŒ¹é…åŸå› 
                if sim.match_reasons:
                    print(f"      åŒ¹é…åŸå› : {', '.join(sim.match_reasons[:3])}")
                
                # æ˜¾ç¤ºå„ç»´åº¦è¯„åˆ†
                if sim.dimension_scores:
                    print("      ç»´åº¦è¯„åˆ†:")
                    sorted_dims = sorted(
                        sim.dimension_scores.items(),
                        key=lambda x: x[1].score,
                        reverse=True
                    )
                    for dim, score in sorted_dims[:3]:
                        print(f"        {dim.value}: {score.score:.3f} (æƒé‡: {score.weight:.2f})")
                print()
        
        # æµ‹è¯•èšç±»åˆ†æ
        print("æ„å»ºç›¸ä¼¼æ€§èšç±»...")
        cluster_info = similarity_engine.build_similarity_clusters(candidate_stocks, n_clusters=3)
        
        if 'error' not in cluster_info:
            print(f"âœ… èšç±»åˆ†æå®Œæˆ")
            print(f"   æ€»è‚¡ç¥¨æ•°: {cluster_info['total_stocks']}")
            print(f"   é›†ç¾¤æ•°é‡: {cluster_info['n_clusters']}")
            print(f"   é›†ç¾¤åˆ†å¸ƒ: {cluster_info['cluster_sizes']}")
            
            # åŸºäºèšç±»æ¨è
            cluster_recommendations = similarity_engine.recommend_from_cluster(
                target_symbol, cluster_info, top_k=3
            )
            if cluster_recommendations:
                print(f"   èšç±»æ¨è: {cluster_recommendations}")
        
        # è·å–ç›¸ä¼¼æ€§æ´å¯Ÿ
        if similarities:
            print("åˆ†æç›¸ä¼¼æ€§æ´å¯Ÿ...")
            insights = similarity_engine.get_similarity_insights(similarities)
            
            print(f"âœ… ç›¸ä¼¼æ€§æ´å¯Ÿåˆ†æ")
            print(f"   ç›¸ä¼¼è‚¡ç¥¨æ€»æ•°: {insights['total_similar_stocks']}")
            print(f"   å¹³å‡ç›¸ä¼¼åº¦: {insights['avg_similarity']:.3f}")
            print(f"   æœ€é«˜ç›¸ä¼¼åº¦: {insights['max_similarity']:.3f}")
            print(f"   é«˜ç›¸ä¼¼åº¦è‚¡ç¥¨æ•°: {insights['high_similarity_count']}")
            print(f"   ä¸­ç­‰ç›¸ä¼¼åº¦è‚¡ç¥¨æ•°: {insights['medium_similarity_count']}")
            
            # æ˜¾ç¤ºç»´åº¦åˆ†æ
            if insights['dimension_analysis']:
                print("   ç»´åº¦è´¡çŒ®åˆ†æ:")
                for dim, analysis in insights['dimension_analysis'].items():
                    print(f"     {dim}: å¹³å‡{analysis['avg_score']:.3f}, è´¡çŒ®{analysis['contribution']:.3f}")
            
            # æ˜¾ç¤ºå¸¸è§åŒ¹é…åŸå› 
            if insights['top_match_reasons']:
                print("   ä¸»è¦åŒ¹é…åŸå› :")
                for reason, count in insights['top_match_reasons'][:3]:
                    print(f"     {reason}: {count}æ¬¡")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç›¸ä¼¼æ€§å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_integrated_selection():
    """æµ‹è¯•å®Œæ•´é›†æˆé€‰è‚¡æµç¨‹"""
    print("\n" + "="*50)
    print("ğŸš€ æµ‹è¯•å®Œæ•´AIå¢å¼ºé€‰è‚¡æµç¨‹")
    print("="*50)
    
    try:
        # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
        print("åˆå§‹åŒ–AIé€‰è‚¡ç»„ä»¶...")
        expert_committee = AIExpertCommittee()
        pattern_recognizer = PatternRecognizer()
        adaptive_engine = AdaptiveEngine()
        similarity_engine = SimilarityEngine()
        stock_selector = StockSelector()
        
        # æµ‹è¯•æ•°æ®
        test_stocks = create_test_stock_data()
        market_data = create_test_market_data()
        news_data = create_test_news_data()
        
        print("âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        
        # ç¬¬1æ­¥ï¼šåŸºç¡€é€‰è‚¡ç­›é€‰
        print("\nç¬¬1æ­¥ï¼šæ‰§è¡ŒåŸºç¡€é€‰è‚¡ç­›é€‰...")
        selection_criteria = SelectionCriteria(
            min_score=70.0,
            max_risk_level=0.6,
            filters=[
                NumericFilter("market_cap", "å¸‚å€¼", FilterOperator.GREATER, 10000000000),  # å¤§äº100äº¿
                NumericFilter("pe_ratio", "PEæ¯”ç‡", FilterOperator.LESS, 30),
                NumericFilter("roe", "ROE", FilterOperator.GREATER, 0.10)
            ],
            max_results=10
        )
        
        base_result = stock_selector.select_stocks(selection_criteria, test_stocks)
        print(f"âœ… åŸºç¡€ç­›é€‰å®Œæˆï¼Œé€šè¿‡è‚¡ç¥¨æ•°: {len(base_result.selected_stocks)}")
        
        # ç¬¬2æ­¥ï¼šAIä¸“å®¶å§”å‘˜ä¼šåˆ†æ
        print("\nç¬¬2æ­¥ï¼šAIä¸“å®¶å§”å‘˜ä¼šæ·±åº¦åˆ†æ...")
        expert_results = {}
        
        for stock_data in base_result.selected_stocks[:3]:  # åˆ†æå‰3åª
            symbol = stock_data['symbol']
            print(f"   åˆ†æ {symbol}...")
            
            # æ„é€ å¤šæºæ•°æ®æ ¼å¼
            multi_source_data = {
                'primary': stock_data,
                'secondary': stock_data  # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ˜¯ä¸åŒæ•°æ®æº
            }
            
            expert_result = expert_committee.analyze_stock_committee(
                symbol, multi_source_data, news_data
            )
            expert_results[symbol] = expert_result
        
        print(f"âœ… AIä¸“å®¶åˆ†æå®Œæˆï¼Œåˆ†æè‚¡ç¥¨æ•°: {len(expert_results)}")
        
        # ç¬¬3æ­¥ï¼šæ¨¡å¼è¯†åˆ«åˆ†æ
        print("\nç¬¬3æ­¥ï¼šæ‰§è¡Œæ¨¡å¼è¯†åˆ«åˆ†æ...")
        pattern_results = {}
        
        for symbol in expert_results.keys():
            price_data = create_test_price_data(symbol)
            volume_data = [p['volume'] for p in price_data]
            
            patterns = pattern_recognizer.recognize_patterns(symbol, price_data, volume_data)
            if patterns:
                pattern_results[symbol] = patterns
                print(f"   {symbol}: å‘ç° {len(patterns)} ä¸ªæ¨¡å¼")
        
        print(f"âœ… æ¨¡å¼è¯†åˆ«å®Œæˆï¼Œå‘ç°æ¨¡å¼çš„è‚¡ç¥¨æ•°: {len(pattern_results)}")
        
        # ç¬¬4æ­¥ï¼šè‡ªé€‚åº”ç­–ç•¥ä¼˜åŒ–
        print("\nç¬¬4æ­¥ï¼šåº”ç”¨è‡ªé€‚åº”ç­–ç•¥ä¼˜åŒ–...")
        adaptive_recommendations = adaptive_engine.get_adaptive_recommendations(
            market_data, list(test_stocks)
        )
        print(f"âœ… è‡ªé€‚åº”ä¼˜åŒ–å®Œæˆ")
        print(f"   å¸‚åœºç¯å¢ƒ: {adaptive_recommendations['market_regime']}")
        print(f"   æ¨èç­–ç•¥: {adaptive_recommendations['selected_strategy']['type']}")
        
        # ç¬¬5æ­¥ï¼šç›¸ä¼¼è‚¡ç¥¨æ¨è
        print("\nç¬¬5æ­¥ï¼šç”Ÿæˆç›¸ä¼¼è‚¡ç¥¨æ¨è...")
        similarity_results = {}
        
        # ä¸ºæ¯åªé€šè¿‡ä¸“å®¶åˆ†æçš„è‚¡ç¥¨æ‰¾ç›¸ä¼¼è‚¡ç¥¨
        for symbol, expert_result in expert_results.items():
            if expert_result['committee_decision']['score'] > 80:  # é«˜è¯„åˆ†è‚¡ç¥¨
                target_data = next(s for s in test_stocks if s['symbol'] == symbol)
                similarities = similarity_engine.find_similar_stocks(
                    symbol, target_data, test_stocks, top_k=3
                )
                if similarities:
                    similarity_results[symbol] = similarities
                    print(f"   {symbol}: æ‰¾åˆ° {len(similarities)} åªç›¸ä¼¼è‚¡ç¥¨")
        
        print(f"âœ… ç›¸ä¼¼è‚¡ç¥¨æ¨èå®Œæˆï¼Œæ¨èç»„æ•°: {len(similarity_results)}")
        
        # ç¬¬6æ­¥ï¼šç”Ÿæˆç»¼åˆæŠ•èµ„å»ºè®®
        print("\nç¬¬6æ­¥ï¼šç”Ÿæˆç»¼åˆæŠ•èµ„å»ºè®®...")
        
        final_recommendations = []
        
        for symbol, expert_result in expert_results.items():
            recommendation = {
                'symbol': symbol,
                'name': next(s['name'] for s in test_stocks if s['symbol'] == symbol),
                'expert_score': expert_result['committee_decision']['score'],
                'expert_recommendation': expert_result['committee_decision']['recommendation'],
                'expert_confidence': expert_result['committee_decision']['confidence'],
                'patterns': len(pattern_results.get(symbol, [])),
                'similar_stocks': len(similarity_results.get(symbol, [])),
                'final_rating': 'A'  # ç®€åŒ–è¯„çº§
            }
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            base_score = expert_result['committee_decision']['score']
            pattern_bonus = len(pattern_results.get(symbol, [])) * 2
            similarity_bonus = len(similarity_results.get(symbol, [])) * 1
            
            comprehensive_score = base_score + pattern_bonus + similarity_bonus
            recommendation['comprehensive_score'] = min(100, comprehensive_score)
            
            final_recommendations.append(recommendation)
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        final_recommendations.sort(key=lambda x: x['comprehensive_score'], reverse=True)
        
        print(f"âœ… ç»¼åˆæŠ•èµ„å»ºè®®ç”Ÿæˆå®Œæˆ")
        print(f"\nğŸ† æœ€ç»ˆæ¨èç»“æœ (AIå¢å¼ºé€‰è‚¡):")
        print("-" * 80)
        print(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<8} {'è‚¡ç¥¨åç§°':<12} {'ç»¼åˆè¯„åˆ†':<8} {'ä¸“å®¶å»ºè®®':<12} {'æ¨¡å¼æ•°':<6} {'ç›¸ä¼¼è‚¡':<6}")
        print("-" * 80)
        
        for i, rec in enumerate(final_recommendations, 1):
            print(f"{i:<4} {rec['symbol']:<8} {rec['name']:<12} "
                  f"{rec['comprehensive_score']:<8.1f} {rec['expert_recommendation']:<12} "
                  f"{rec['patterns']:<6} {rec['similar_stocks']:<6}")
        
        # æ˜¾ç¤ºè¯¦ç»†åˆ†ææ‘˜è¦
        print(f"\nğŸ“Š AIå¢å¼ºé€‰è‚¡åˆ†ææ‘˜è¦:")
        print(f"   åŸºç¡€ç­›é€‰é€šè¿‡: {len(base_result.selected_stocks)} åª")
        print(f"   AIä¸“å®¶æ·±åº¦åˆ†æ: {len(expert_results)} åª")
        print(f"   æ¨¡å¼è¯†åˆ«è¦†ç›–: {len(pattern_results)} åª")
        print(f"   ç›¸ä¼¼æ¨èç»„æ•°: {len(similarity_results)} ç»„")
        print(f"   æœ€ç»ˆæ¨èè‚¡ç¥¨: {len(final_recommendations)} åª")
        print(f"   å¹³å‡ç»¼åˆè¯„åˆ†: {sum(r['comprehensive_score'] for r in final_recommendations)/len(final_recommendations):.1f}")
        
        # æ˜¾ç¤ºç­–ç•¥å»ºè®®
        strategy_info = adaptive_recommendations['selected_strategy']
        print(f"\nğŸ’¡ ç­–ç•¥å»ºè®®:")
        print(f"   å½“å‰å¸‚åœºç¯å¢ƒ: {adaptive_recommendations['market_regime']}")
        print(f"   å»ºè®®ç­–ç•¥ç±»å‹: {strategy_info['type']}")
        print(f"   ç­–ç•¥ç½®ä¿¡åº¦: {strategy_info['confidence']:.2%}")
        print(f"   é£é™©æ‰¿å—åº¦: {strategy_info['risk_tolerance']:.2%}")
        print(f"   é¢„æœŸæ”¶ç›Šç‡: {strategy_info['expected_performance']:.2%}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹é˜¶æ®µ2 AIå¢å¼ºé€‰è‚¡ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print("=" * 60)
    
    test_results = []
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("AIä¸“å®¶å§”å‘˜ä¼š", test_ai_expert_committee),
        ("æ¨¡å¼è¯†åˆ«å¼•æ“", test_pattern_recognizer),
        ("è‡ªé€‚åº”é€‰è‚¡å¼•æ“", test_adaptive_engine),
        ("ç›¸ä¼¼è‚¡ç¥¨æ¨è", test_similarity_engine),
        ("å®Œæ•´é›†æˆæµç¨‹", test_integrated_selection)
    ]
    
    for test_name, test_func in tests:
        print(f"\nå¼€å§‹æµ‹è¯•: {test_name}")
        result = test_func()
        test_results.append((test_name, result))
        
        if result:
            print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
        else:
            print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    passed_count = sum(1 for _, result in test_results if result)
    total_count = len(test_results)
    
    print(f"æ€»æµ‹è¯•é¡¹ç›®: {total_count}")
    print(f"é€šè¿‡æµ‹è¯•: {passed_count}")
    print(f"å¤±è´¥æµ‹è¯•: {total_count - passed_count}")
    print(f"é€šè¿‡ç‡: {passed_count/total_count:.1%}")
    
    print("\nè¯¦ç»†ç»“æœ:")
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name:<20} {status}")
    
    if passed_count == total_count:
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é˜¶æ®µ2 AIå¢å¼ºé€‰è‚¡ç³»ç»Ÿé›†æˆæµ‹è¯•æˆåŠŸï¼")
        return True
    else:
        print(f"\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)