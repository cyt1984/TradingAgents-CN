#!/usr/bin/env python3
"""
é€‰è‚¡é¡µé¢ç»„ä»¶
æä¾›æ™ºèƒ½é€‰è‚¡åŠŸèƒ½çš„å®Œæ•´Webç•Œé¢
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
from typing import Dict, List, Any, Optional
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from tradingagents.utils.logging_manager import get_logger
logger = get_logger('web')

def render_selection_help():
    """æ¸²æŸ“é€‰è‚¡å¸®åŠ©ä¿¡æ¯"""
    with st.expander("â“ ä½¿ç”¨å¸®åŠ©", expanded=False):
        st.markdown("""
        ### ğŸ¯ å¿«é€Ÿé€‰è‚¡
        - **ç»¼åˆè¯„åˆ†**: 0-100åˆ†ï¼Œæ¨èâ‰¥70åˆ†
        - **å¸‚å€¼**: å»ºè®®â‰¥50äº¿ï¼Œè¿‡æ»¤å°ç›˜è‚¡é£é™©
        - **å¸‚ç›ˆç‡**: å»ºè®®â‰¤30å€ï¼Œé¿å…é«˜ä¼°å€¼é£é™©  
        - **æŠ•èµ„ç­‰çº§**: A+/Açº§ä¸ºä¼˜è´¨è‚¡ç¥¨
        
        ### ğŸ”§ è‡ªå®šä¹‰ç­›é€‰
        - å¯è®¾ç½®å¤šä¸ªç­›é€‰æ¡ä»¶
        - æ”¯æŒæ•°å€¼æ¯”è¾ƒæ“ä½œ
        - å¯è‡ªå®šä¹‰æ’åºå­—æ®µ
        - ç»“æœæ•°é‡å¯è°ƒæ•´
        
        ### ğŸ“Š ç»“æœè¯´æ˜
        - **å€™é€‰æ€»æ•°**: ç³»ç»Ÿä¸­æ‰€æœ‰å¯ç”¨è‚¡ç¥¨æ•°é‡
        - **ç­›é€‰ç»“æœ**: ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æ•°é‡
        - **æˆåŠŸç‡**: ç­›é€‰é€šè¿‡ç‡
        - **æ‰§è¡Œæ—¶é—´**: é€‰è‚¡è€—æ—¶
        """)

def render_stock_selector_page():
    """æ¸²æŸ“é€‰è‚¡é¡µé¢"""
    st.markdown("# ğŸ¯ æ™ºèƒ½é€‰è‚¡ç³»ç»Ÿ")
    st.markdown("åŸºäºå¤šæºæ•°æ®èåˆå’Œç»¼åˆè¯„åˆ†çš„å¤šå¸‚åœºæ™ºèƒ½é€‰è‚¡å¼•æ“")
    
    # ä»session stateè·å–ä¾§è¾¹æ é…ç½®å¹¶åº”ç”¨åˆ°æ™ºèƒ½é€‰è‚¡ç³»ç»Ÿ
    llm_provider = st.session_state.get('llm_provider')
    llm_model = st.session_state.get('llm_model')
    
    # ç¡®ä¿é…ç½®ä¼ é€’ç»™åç«¯LLMç®¡ç†å™¨
    if llm_provider and llm_model:
        try:
            from tradingagents.llm_adapters.dynamic_llm_manager import get_llm_manager
            llm_manager = get_llm_manager()
            
            # æ ¹æ®ä¾§è¾¹æ é…ç½®è®¾ç½®LLMæ¨¡å‹
            model_mapping = {
                ("dashscope", "qwen-turbo"): "dashscope_qwen_turbo",
                ("dashscope", "qwen-plus-latest"): "dashscope_qwen_plus", 
                ("dashscope", "qwen-max"): "dashscope_qwen_max",
                ("deepseek", "deepseek-chat"): "deepseek_chat",
                ("kimi", "moonshot-v1-8k"): "kimi_chat",
                ("kimi", "moonshot-v1-32k"): "kimi_chat",
                ("kimi", "moonshot-v1-128k"): "kimi_chat",
                ("kimi", "kimi-k2-0711-preview"): "kimi_chat",
                ("kimi", "kimi-k2-turbo-preview"): "kimi_chat",
                ("google", "gemini-2.0-flash"): "google_gemini_pro",
                ("google", "gemini-1.5-pro"): "google_gemini_pro",
                ("google", "gemini-1.5-flash"): "google_gemini_pro",
                ("glm", "glm-4-plus"): "glm_chat",
                ("glm", "glm-4"): "glm_chat", 
                ("glm", "glm-4-air"): "glm_chat",
                ("glm", "glm-4-flash"): "glm_chat",
                ("openrouter", None): "openrouter_claude"  # OpenRouterä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
            }
            
            # æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å‹é”®
            model_key = None
            for (provider, model), key in model_mapping.items():
                if provider == llm_provider and (model is None or model == llm_model):
                    model_key = key
                    break
            
            # å¯¹äºOpenRouterï¼Œä½¿ç”¨å®é™…çš„æ¨¡å‹åç§°
            if llm_provider == "openrouter" and llm_model:
                # åˆ›å»ºä¸€ä¸ªOpenRouterçš„ä¸´æ—¶é…ç½®
                from tradingagents.llm_adapters.dynamic_llm_manager import LLMConfig
                openrouter_config = LLMConfig(
                    provider="openrouter",
                    model_name=llm_model,
                    base_url="https://openrouter.ai/api/v1",
                    display_name=f"OpenRouter - {llm_model}",
                    description=f"OpenRouteræ¨¡å‹: {llm_model}"
                )
                # æ·»åŠ åˆ°å¯ç”¨é…ç½®ä¸­
                llm_manager.available_configs["openrouter_custom"] = openrouter_config
                model_key = "openrouter_custom"
            
            if not model_key:
                model_key = "openai_gpt4o"  # é»˜è®¤å›é€€
                
            # è®¾ç½®å½“å‰æ¨¡å‹
            success = llm_manager.set_current_model(model_key)
            if success:
                logger.info(f"âœ… [æ™ºèƒ½é€‰è‚¡] AIæ¨¡å‹å·²è®¾ç½®: {llm_provider} - {llm_model} -> {model_key}")
            else:
                logger.warning(f"âš ï¸ [æ™ºèƒ½é€‰è‚¡] AIæ¨¡å‹è®¾ç½®å¤±è´¥: {model_key}")
                
        except Exception as e:
            logger.error(f"âŒ [æ™ºèƒ½é€‰è‚¡] LLMé…ç½®åº”ç”¨å¤±è´¥: {e}")
    else:
        logger.warning("âš ï¸ [æ™ºèƒ½é€‰è‚¡] ä¾§è¾¹æ LLMé…ç½®ä¸å®Œæ•´")
    
    # æ·»åŠ ä½¿ç”¨å¸®åŠ©
    render_selection_help()
    st.markdown("---")
    
    # æ£€æŸ¥é€‰è‚¡å¼•æ“å¯ç”¨æ€§
    try:
        from tradingagents.selectors.stock_selector import get_stock_selector
        from tradingagents.selectors.filter_conditions import FilterOperator
        from tradingagents.selectors.ai_strategies.ai_strategy_manager import AIMode
        
        selector = get_stock_selector()
        ai_status = selector.get_ai_performance_summary()
        
        # æ˜¾ç¤ºAIå¼•æ“è¯¦ç»†çŠ¶æ€
        with st.container():
            col1, col2 = st.columns([2, 1])
            
            with col1:
                if ai_status.get('ai_enabled', False):
                    availability = ai_status.get('engine_availability', {})
                    available_count = availability.get('available_count', 0)
                    total_count = availability.get('total_count', 4)
                    availability_rate = availability.get('availability_rate', 0)
                    
                    if availability_rate >= 75:
                        st.success(f"ğŸš€ AIä¸“å®¶ç³»ç»Ÿå·²å°±ç»ª ({available_count}/{total_count} ä¸ªå¼•æ“å¯ç”¨)")
                    elif availability_rate >= 50:
                        st.warning(f"âš¡ AIç³»ç»Ÿéƒ¨åˆ†å¯ç”¨ ({available_count}/{total_count} ä¸ªå¼•æ“å¯ç”¨)")
                    else:
                        st.warning(f"ğŸ”§ AIç³»ç»ŸåŠŸèƒ½å—é™ ({available_count}/{total_count} ä¸ªå¼•æ“å¯ç”¨)")
                    
                    # æ˜¾ç¤ºå¼•æ“çŠ¶æ€è¯¦æƒ…
                    engines_status = ai_status.get('ai_engines_status', {})
                    status_text = []
                    if engines_status.get('expert_committee'):
                        status_text.append("ğŸ‘¥ ä¸“å®¶å§”å‘˜ä¼š")
                    if engines_status.get('adaptive_engine'):
                        status_text.append("ğŸ”„ è‡ªé€‚åº”ç­–ç•¥")
                    if engines_status.get('pattern_recognizer'):
                        status_text.append("ğŸ“ˆ æ¨¡å¼è¯†åˆ«")
                    if engines_status.get('similarity_engine'):
                        status_text.append("ğŸ” ç›¸ä¼¼æ€§åˆ†æ")
                    
                    if status_text:
                        st.info(f"ğŸ¤– å¯ç”¨AIåŠŸèƒ½ï¼š{' â€¢ '.join(status_text)}")
                else:
                    st.success("âœ… åŸºç¡€é€‰è‚¡å¼•æ“å·²å°±ç»ª")
                    st.warning("âš ï¸ AIå¢å¼ºåŠŸèƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€é€‰è‚¡æ¨¡å¼")
            
            with col2:
                # AIæ¨¡å‹é€‰æ‹©å’Œæ€§èƒ½ç›‘æ§
                if ai_status.get('ai_enabled', False):
                    # AIæ¨¡å‹é€‰æ‹©
                    with st.expander("ğŸ¤– AIæ¨¡å‹é€‰æ‹©", expanded=False):
                        render_ai_model_selector(selector)
                    
                    with st.expander("ğŸ“Š AIæ€§èƒ½ç›‘æ§", expanded=False):
                        total_analyses = ai_status.get('total_analyses', 0)
                        cache_hit_rate = ai_status.get('cache_hit_rate', 0)
                        avg_time = ai_status.get('average_processing_time', 0)
                        
                        st.metric("å·²åˆ†æè‚¡ç¥¨", f"{total_analyses}")
                        st.metric("ç¼“å­˜å‘½ä¸­ç‡", f"{cache_hit_rate:.1f}%")
                        st.metric("å¹³å‡è€—æ—¶", f"{avg_time:.2f}s")
                        
                        # AIè°ƒè¯•å·¥å…·
                        st.markdown("---")
                        st.markdown("**ğŸ”§ è°ƒè¯•å·¥å…·**")
                        
                        col_debug1, col_debug2 = st.columns(2)
                        
                        with col_debug1:
                            if st.button("ğŸ” ç³»ç»Ÿæ£€æŸ¥", help="æ£€æŸ¥AIå¼•æ“çŠ¶æ€"):
                                run_ai_system_check()
                        
                        with col_debug2:
                            if st.button("ğŸ§¹ æ¸…ç†ç¼“å­˜", help="æ¸…ç†AIåˆ†æç¼“å­˜"):
                                clear_ai_caches()
                else:
                    # å³ä½¿AIæœªå¯ç”¨ï¼Œä¹Ÿæ˜¾ç¤ºæ¨¡å‹é€‰æ‹©ï¼ˆå¯èƒ½æœ‰åŠ©äºå¯åŠ¨AIï¼‰
                    with st.expander("ğŸ¤– AIæ¨¡å‹è®¾ç½®", expanded=False):
                        st.info("âš ï¸ AIåŠŸèƒ½æœªå¯ç”¨ï¼Œä½†æ‚¨å¯ä»¥é…ç½®AIæ¨¡å‹")
                        render_ai_model_selector(selector)
        
    except Exception as e:
        st.error(f"âŒ é€‰è‚¡å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        st.info("ğŸ’¡ è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®å’Œä¾èµ–")
        return
    
    # æ·»åŠ å¸‚åœºé€‰æ‹©
    st.markdown("### ğŸŒ å¸‚åœºé€‰æ‹©")
    market_type = st.selectbox(
        "é€‰æ‹©å¸‚åœº",
        ["Aè‚¡", "ç¾è‚¡", "æ¸¯è‚¡"],
        index=0,
        help="é€‰æ‹©è¦åˆ†æçš„è‚¡ç¥¨å¸‚åœº"
    )
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("### ğŸ“Š ç­›é€‰æ¡ä»¶è®¾ç½®")
        
        # é€‰è‚¡æ¨¡å¼é€‰æ‹©
        mode = st.selectbox(
            "é€‰è‚¡æ¨¡å¼",
            ["é¾™è™æ¦œå¢å¼ºé€‰è‚¡", "å¿«é€Ÿé€‰è‚¡", "AIå¢å¼ºé€‰è‚¡", "ä¸“å®¶å§”å‘˜ä¼š", "è‡ªé€‚åº”ç­–ç•¥", "æ¨¡å¼è¯†åˆ«", "å®Œæ•´AIåˆ†æ", "è‡ªå®šä¹‰ç­›é€‰"],
            help="é€‰æ‹©ä¸åŒçš„é€‰è‚¡ç­–ç•¥ï¼Œé¾™è™æ¦œæ¨¡å¼å¤§å¹…æå‡æ€§èƒ½ï¼ŒAIæ¨¡å¼æä¾›æ›´æ™ºèƒ½çš„åˆ†æ"
        )
        
        if mode == "é¾™è™æ¦œå¢å¼ºé€‰è‚¡":
            render_longhubang_enhanced_form()
        elif mode == "å¿«é€Ÿé€‰è‚¡":
            render_quick_selection_form()
        elif mode == "AIå¢å¼ºé€‰è‚¡":
            render_ai_enhanced_form()
        elif mode == "ä¸“å®¶å§”å‘˜ä¼š":
            render_expert_committee_form()
        elif mode == "è‡ªé€‚åº”ç­–ç•¥":
            render_adaptive_strategy_form()
        elif mode == "æ¨¡å¼è¯†åˆ«":
            render_pattern_based_form()
        elif mode == "å®Œæ•´AIåˆ†æ":
            render_full_ai_form()
        else:
            render_custom_selection_form()
    
    with col2:
        st.markdown("### ğŸ“ˆ é€‰è‚¡ç»“æœ")
        
        # é€‰è‚¡æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹é€‰è‚¡", type="primary", use_container_width=True):
            with st.spinner("ğŸ” æ­£åœ¨é€‰è‚¡ä¸­..."):
                execute_stock_selection(selector, mode)
        
        # ä¿å­˜å¸‚åœºç±»å‹åˆ°session state
        st.session_state.market_type = market_type
        
        # æ˜¾ç¤ºé€‰è‚¡ç»“æœ
        display_selection_results()

def render_quick_selection_form():
    """æ¸²æŸ“å¿«é€Ÿé€‰è‚¡è¡¨å•"""
    st.markdown("#### ğŸ¯ å¿«é€Ÿé€‰è‚¡å‚æ•°")
    
    # ç»¼åˆè¯„åˆ†
    min_score = st.slider(
        "æœ€å°ç»¼åˆè¯„åˆ†",
        min_value=0,
        max_value=100,
        value=70,
        step=5,
        help="é€‰æ‹©ç»¼åˆè¯„åˆ†æœ€ä½è¦æ±‚"
    )
    
    # å¸‚å€¼è¦æ±‚
    min_market_cap = st.number_input(
        "æœ€å°å¸‚å€¼ (äº¿å…ƒ)",
        min_value=0.0,
        max_value=10000.0,
        value=50.0,
        step=10.0,
        help="è®¾ç½®å¸‚å€¼é—¨æ§›"
    )
    
    # å¸‚ç›ˆç‡ä¸Šé™
    max_pe_ratio = st.number_input(
        "æœ€å¤§å¸‚ç›ˆç‡",
        min_value=0.0,
        max_value=100.0,
        value=30.0,
        step=5.0,
        help="è®¾ç½®å¸‚ç›ˆç‡ä¸Šé™"
    )
    
    # æŠ•èµ„ç­‰çº§
    grades = st.multiselect(
        "æŠ•èµ„ç­‰çº§",
        options=['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-'],
        default=['A+', 'A'],
        help="é€‰æ‹©æœŸæœ›çš„æŠ•èµ„ç­‰çº§"
    )
    
    # ç»“æœæ•°é‡
    limit = st.selectbox(
        "è¿”å›æ•°é‡",
        options=[10, 20, 50, 100],
        index=1,
        help="é€‰æ‹©è¿”å›çš„è‚¡ç¥¨æ•°é‡"
    )
    
    # ä¿å­˜åˆ°session state
    st.session_state.quick_params = {
        'min_score': min_score,
        'min_market_cap': min_market_cap,
        'max_pe_ratio': max_pe_ratio,
        'grades': grades,
        'limit': limit
    }

def render_longhubang_enhanced_form():
    """æ¸²æŸ“é¾™è™æ¦œå¢å¼ºé€‰è‚¡è¡¨å•"""
    st.markdown("#### ğŸ‰ é¾™è™æ¦œå¢å¼ºé€‰è‚¡")
    st.success("ğŸš€ **æ€§èƒ½çªç ´**: ä»5000+è‚¡ç¥¨æ‰«æ â†’ 50-200åªé¾™è™æ¦œè‚¡ç¥¨ï¼Œå¤„ç†æ—¶é—´å¤§å¹…å‡å°‘ï¼")
    st.info("ğŸ’¡ **æ ¸å¿ƒä¼˜åŠ¿**: èšç„¦çƒ­é—¨èµ„é‡‘æµå…¥è‚¡ç¥¨ï¼Œåˆ†æçŸ¥åå¸­ä½ä¹°å–ä¿¡å·")
    
    # é¾™è™æ¦œç±»å‹é€‰æ‹©
    ranking_type_map = {
        "æ—¥æ¦œ": "daily",
        "æ¶¨åœæ¿": "limit_up", 
        "è·Œåœæ¿": "limit_down",
        "æˆäº¤é¢æ¦œ": "turnover",
        "æŒ¯å¹…æ¦œ": "amplitude",
        "æˆäº¤é‡æ¦œ": "volume",
        "æ¢æ‰‹ç‡æ¦œ": "turnover_rate"
    }
    
    ranking_type_display = st.selectbox(
        "é¾™è™æ¦œç±»å‹",
        options=list(ranking_type_map.keys()),
        index=0,
        help="é€‰æ‹©è¦åˆ†æçš„é¾™è™æ¦œç±»å‹ï¼Œæ—¥æ¦œåŒ…å«æ‰€æœ‰ä¸Šæ¦œè‚¡ç¥¨"
    )
    
    # æ—¥æœŸé€‰æ‹©
    col1, col2 = st.columns(2)
    with col1:
        use_latest = st.checkbox("ä½¿ç”¨æœ€æ–°æ•°æ®", value=True, help="ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥æ•°æ®")
    
    with col2:
        if not use_latest:
            selected_date = st.date_input(
                "æŒ‡å®šæ—¥æœŸ",
                value=datetime.now().date(),
                help="é€‰æ‹©è¦åˆ†æçš„å…·ä½“æ—¥æœŸ"
            )
        else:
            selected_date = None
    
    # é¾™è™æ¦œè¯„åˆ†è¦æ±‚
    min_longhubang_score = st.slider(
        "é¾™è™æ¦œæœ€ä½è¯„åˆ†",
        min_value=0,
        max_value=100,
        value=60,
        step=5,
        help="é¾™è™æ¦œç»¼åˆè¯„åˆ†é˜ˆå€¼ï¼ŒåŒ…å«å¸­ä½è´¨é‡ã€èµ„é‡‘æµå‘ã€è·Ÿéšæ½œåŠ›ç­‰ç»´åº¦"
    )
    
    # AIå¢å¼ºé€‰é¡¹
    st.markdown("##### ğŸ¤– AIå¢å¼ºé€‰é¡¹")
    enable_ai_analysis = st.checkbox(
        "å¯ç”¨AIæ·±åº¦åˆ†æ", 
        value=True, 
        help="å¯¹é¾™è™æ¦œè‚¡ç¥¨è¿›è¡ŒAIå¢å¼ºåˆ†æï¼Œæä¾›æ›´æ™ºèƒ½çš„è¯„åˆ†å’Œå»ºè®®"
    )
    
    if enable_ai_analysis:
        ai_mode_map = {
            "AIå¢å¼º": "AI_ENHANCED",
            "ä¸“å®¶å§”å‘˜ä¼š": "EXPERT_COMMITTEE", 
            "è‡ªé€‚åº”ç­–ç•¥": "ADAPTIVE",
            "æ¨¡å¼è¯†åˆ«": "PATTERN_BASED",
            "å®Œæ•´AI": "FULL_AI"
        }
        
        ai_mode_display = st.selectbox(
            "AIåˆ†ææ¨¡å¼",
            options=list(ai_mode_map.keys()),
            index=0,
            help="é€‰æ‹©AIåˆ†æçš„æ·±åº¦å’Œç­–ç•¥"
        )
        
        # AIè¯„åˆ†æƒé‡é…ç½®
        with st.expander("âš–ï¸ è¯„åˆ†æƒé‡é…ç½®", expanded=False):
            longhubang_weight = st.slider(
                "é¾™è™æ¦œè¯„åˆ†æƒé‡",
                min_value=0.3,
                max_value=0.8,
                value=0.6,
                step=0.1,
                help="é¾™è™æ¦œåˆ†æåœ¨æœ€ç»ˆè¯„åˆ†ä¸­çš„æƒé‡"
            )
            
            ai_weight = 1.0 - longhubang_weight
            st.write(f"AIè¯„åˆ†æƒé‡: {ai_weight:.1f}")
            st.write(f"ç»¼åˆè¯„åˆ† = é¾™è™æ¦œè¯„åˆ† Ã— {longhubang_weight:.1f} + AIè¯„åˆ† Ã— {ai_weight:.1f}")
    else:
        ai_mode_display = None
        longhubang_weight = 1.0
        ai_weight = 0.0
    
    # å¸­ä½åˆ†æé…ç½®
    st.markdown("##### ğŸ›ï¸ å¸­ä½åˆ†æé…ç½®")
    
    col1, col2 = st.columns(2)
    with col1:
        focus_famous_investors = st.checkbox(
            "é‡ç‚¹å…³æ³¨çŸ¥åæŠ•èµ„è€…", 
            value=True, 
            help="ä¼˜å…ˆæ˜¾ç¤ºç« å»ºå¹³ã€èµµå»ºå¹³ã€æ—å›­ç­‰çŸ¥åç‰›æ•£çš„æ“ä½œ"
        )
        
        focus_institutions = st.checkbox(
            "é‡ç‚¹å…³æ³¨æœºæ„å¸­ä½", 
            value=True, 
            help="ä¼˜å…ˆæ˜¾ç¤ºå…¬å‹ŸåŸºé‡‘ã€ç§å‹ŸåŸºé‡‘ç­‰æœºæ„çš„æ“ä½œ"
        )
    
    with col2:
        detect_coordination = st.checkbox(
            "æ£€æµ‹ååŒäº¤æ˜“", 
            value=True, 
            help="è¯†åˆ«å¯èƒ½çš„ååŒæ“ä½œå’Œå¼‚å¸¸äº¤æ˜“æ¨¡å¼"
        )
        
        show_risk_warnings = st.checkbox(
            "æ˜¾ç¤ºé£é™©é¢„è­¦", 
            value=True, 
            help="æ˜¾ç¤ºæ¸¸èµ„ç‚’ä½œã€ååŒäº¤æ˜“ç­‰é£é™©æç¤º"
        )
    
    # ç»“æœç­›é€‰
    st.markdown("##### ğŸ“Š ç»“æœç­›é€‰")
    
    col1, col2 = st.columns(2)
    with col1:
        min_seat_influence = st.selectbox(
            "æœ€ä½å¸­ä½å½±å“åŠ›",
            options=["ä¸é™åˆ¶", "ä¸­ç­‰å½±å“åŠ›(â‰¥70åˆ†)", "é«˜å½±å“åŠ›(â‰¥80åˆ†)", "é¡¶çº§å½±å“åŠ›(â‰¥90åˆ†)"],
            index=1,
            help="æ ¹æ®å¸­ä½å½±å“åŠ›è¯„åˆ†ç­›é€‰"
        )
        
        battle_winner_filter = st.selectbox(
            "ä¹°å–æ–¹å®åŠ›",
            options=["ä¸é™åˆ¶", "ä¹°æ–¹å ä¼˜", "å–æ–¹å ä¼˜", "åŠ¿å‡åŠ›æ•Œ"],
            index=0,
            help="æ ¹æ®ä¹°å–åŒæ–¹å®åŠ›å¯¹æ¯”ç­›é€‰"
        )
    
    with col2:
        market_sentiment_filter = st.multiselect(
            "å¸‚åœºæƒ…ç»ª",
            options=["æåº¦çœ‹å¤š", "çœ‹å¤š", "ä¸­æ€§", "çœ‹ç©º", "æåº¦çœ‹ç©º"],
            default=[],
            help="æ ¹æ®å¸‚åœºæƒ…ç»ªç­›é€‰"
        )
        
        operation_pattern_filter = st.multiselect(
            "æ“ä½œæ¨¡å¼",
            options=["æœºæ„ä¹°å…¥", "æœºæ„å–å‡º", "æ¸¸èµ„ç‚’ä½œ", "æ•£æˆ·è·Ÿé£", "ååŒæ“ä½œ", "æ··åˆæ¨¡å¼"],
            default=[],
            help="æ ¹æ®æ“ä½œæ¨¡å¼ç­›é€‰"
        )
    
    # è¿”å›æ•°é‡
    limit = st.selectbox(
        "è¿”å›è‚¡ç¥¨æ•°é‡",
        options=[10, 20, 30, 50, 100],
        index=2,
        help="é¾™è™æ¦œå¢å¼ºé€‰è‚¡çš„ç»“æœæ•°é‡"
    )
    
    # ä¿å­˜å‚æ•°åˆ°session state
    st.session_state.longhubang_enhanced_params = {
        'ranking_type': ranking_type_map[ranking_type_display],
        'date': selected_date.strftime('%Y-%m-%d') if selected_date else None,
        'min_longhubang_score': min_longhubang_score,
        'enable_ai_analysis': enable_ai_analysis,
        'ai_mode': ai_mode_map.get(ai_mode_display) if ai_mode_display else None,
        'longhubang_weight': longhubang_weight,
        'ai_weight': ai_weight,
        'focus_famous_investors': focus_famous_investors,
        'focus_institutions': focus_institutions,
        'detect_coordination': detect_coordination,
        'show_risk_warnings': show_risk_warnings,
        'min_seat_influence': min_seat_influence,
        'battle_winner_filter': battle_winner_filter,
        'market_sentiment_filter': market_sentiment_filter,
        'operation_pattern_filter': operation_pattern_filter,
        'limit': limit
    }
    
    # æ˜¾ç¤ºæ€§èƒ½å¯¹æ¯”
    with st.expander("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ä¼ ç»Ÿå…¨å¸‚åœºæ‰«æ:**")
            st.write("â€¢ å€™é€‰è‚¡ç¥¨: 5000+ åª")
            st.write("â€¢ æ•°æ®è·å–: 10-30åˆ†é’Ÿ")
            st.write("â€¢ AIåˆ†æ: 30-60åˆ†é’Ÿ")
            st.write("â€¢ æ€»è€—æ—¶: 40-90åˆ†é’Ÿ")
            st.error("âŒ æ•ˆç‡ä½ï¼Œèµ„æºæ¶ˆè€—å¤§")
        
        with col2:
            st.markdown("**ğŸ‰ é¾™è™æ¦œå¢å¼ºé€‰è‚¡:**")
            st.write("â€¢ å€™é€‰è‚¡ç¥¨: 50-200 åª")
            st.write("â€¢ æ•°æ®è·å–: 10-30ç§’")
            st.write("â€¢ AIåˆ†æ: 2-5åˆ†é’Ÿ")
            st.write("â€¢ æ€»è€—æ—¶: 2-6åˆ†é’Ÿ")
            st.success("âœ… æ•ˆç‡æå‡10-25å€ï¼")
    
    # æ˜¾ç¤ºåŠŸèƒ½ç‰¹è‰²
    with st.expander("ğŸ’ åŠŸèƒ½ç‰¹è‰²", expanded=False):
        st.markdown("""
        **ğŸ¯ ç²¾å‡†å®šä½**
        - èšç„¦èµ„é‡‘æ´»è·ƒçš„çƒ­é—¨è‚¡ç¥¨
        - è‡ªåŠ¨è¯†åˆ«é‡è¦å¸­ä½æ“ä½œä¿¡å·
        - å¤šç»´åº¦é¾™è™æ¦œè¯„åˆ†ç³»ç»Ÿ
        
        **ğŸ§  æ™ºèƒ½åˆ†æ** 
        - å¸­ä½ç±»å‹æ™ºèƒ½è¯†åˆ«(ç‰›æ•£/æœºæ„/æ¸¸èµ„)
        - ä¹°å–åŒæ–¹å®åŠ›å¯¹æ¯”åˆ†æ
        - ååŒäº¤æ˜“æ¨¡å¼æ£€æµ‹
        
        **âš¡ æ€§èƒ½çªç ´**
        - å€™é€‰è‚¡ç¥¨æ•°é‡å‡å°‘95%+
        - åˆ†ææ—¶é—´ç¼©çŸ­90%+
        - ä¿æŒåˆ†æè´¨é‡å’Œå‡†ç¡®æ€§
        
        **ğŸ“Š ä¸°å¯Œä¿¡æ¯**
        - å¸­ä½å½±å“åŠ›è¯„åˆ†
        - èµ„é‡‘æµå‘åˆ†æ
        - å¸‚åœºæƒ…ç»ªåˆ¤æ–­
        - æ“ä½œæ¨¡å¼è¯†åˆ«
        - è·Ÿéšå»ºè®®ç”Ÿæˆ
        """)
    
    st.markdown("---")
    st.info("ğŸ’¡ **æç¤º**: é¾™è™æ¦œå¢å¼ºé€‰è‚¡æ˜¯è§£å†³å¤§è§„æ¨¡è‚¡ç¥¨ç­›é€‰æ€§èƒ½é—®é¢˜çš„åˆ›æ–°æ–¹æ¡ˆï¼Œé€šè¿‡é¢„ç­›é€‰é«˜è´¨é‡è‚¡ç¥¨æ± å®ç°æ•ˆç‡çªç ´ï¼")

def render_custom_selection_form():
    """æ¸²æŸ“è‡ªå®šä¹‰ç­›é€‰è¡¨å•"""
    st.markdown("#### ğŸ”§ è‡ªå®šä¹‰ç­›é€‰å‚æ•°")
    
    # è·å–å¯ç”¨å­—æ®µ
    try:
        from tradingagents.selectors.stock_selector import get_stock_selector
        selector = get_stock_selector()
        fields = selector.get_available_fields()
        
        # æ•°å€¼ç±»å‹å­—æ®µ
        numeric_fields = {k: v for k, v in fields.items() if v.get('type') == 'numeric'}
        
        st.markdown("##### ğŸ“Š æ•°å€¼æ¡ä»¶")
        conditions = []
        
        # åŠ¨æ€æ·»åŠ ç­›é€‰æ¡ä»¶
        num_conditions = st.number_input("ç­›é€‰æ¡ä»¶æ•°é‡", 1, 5, 2)
        
        for i in range(int(num_conditions)):
            with st.expander(f"æ¡ä»¶ {i+1}", expanded=True):
                col_a, col_b, col_c = st.columns([2, 1, 1])
                
                with col_a:
                    field = st.selectbox(
                        "å­—æ®µ",
                        options=list(numeric_fields.keys()),
                        format_func=lambda x: numeric_fields.get(x, {}).get('name', x),
                        key=f"field_{i}"
                    )
                
                with col_b:
                    operator = st.selectbox(
                        "æ¡ä»¶",
                        options=['>=', '<=', '=', '!='],
                        key=f"op_{i}"
                    )
                
                with col_c:
                    value = st.number_input(
                        "æ•°å€¼",
                        value=0.0,
                        key=f"val_{i}"
                    )
                
                conditions.append({
                    'field': field,
                    'operator': operator,
                    'value': value
                })
        
        # æ’åºè®¾ç½®
        st.markdown("##### ğŸ“ˆ æ’åºè®¾ç½®")
        sort_field = st.selectbox(
            "æ’åºå­—æ®µ",
            options=['overall_score'] + list(numeric_fields.keys())[:10],
            format_func=lambda x: fields.get(x, {}).get('name', x) if x in fields else x
        )
        
        sort_desc = st.checkbox("é™åºæ’åˆ—", value=True)
        
        # ç»“æœæ•°é‡
        limit = st.number_input("ç»“æœæ•°é‡", 1, 200, 50)
        
        # ä¿å­˜åˆ°session state
        st.session_state.custom_params = {
            'conditions': conditions,
            'sort_field': sort_field,
            'sort_desc': sort_desc,
            'limit': limit
        }
        
    except Exception as e:
        st.error(f"è·å–å­—æ®µä¿¡æ¯å¤±è´¥: {e}")

def render_ai_enhanced_form():
    """æ¸²æŸ“AIå¢å¼ºé€‰è‚¡è¡¨å•"""
    st.markdown("#### ğŸ¤– AIå¢å¼ºé€‰è‚¡")
    st.info("ğŸ† ä½¿ç”¨AIä¸“å®¶å§”å‘˜ä¼šã€è‡ªé€‚åº”ç­–ç•¥ã€æ¨¡å¼è¯†åˆ«ç­‰å¤šç§AIæŠ€æœ¯")
    
    # AIè¯„åˆ†è¦æ±‚
    min_ai_score = st.slider(
        "AIæœ€å°ç»¼åˆè¯„åˆ†",
        min_value=0,
        max_value=100,
        value=75,
        step=5,
        help="AIç»¼åˆåˆ†æåçš„æœ€ä½è¯„åˆ†è¦æ±‚"
    )
    
    # ç½®ä¿¡åº¦è¦æ±‚
    min_confidence = st.slider(
        "æœ€å°ç½®ä¿¡åº¦",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.05,
        help="AIåˆ†æç»“æœçš„æœ€ä½ç½®ä¿¡åº¦è¦æ±‚"
    )
    
    # é£é™©æ‰¿å—åº¦
    risk_tolerance = st.selectbox(
        "é£é™©æ‰¿å—åº¦",
        options=["ä½é£é™©", "ä¸­ç­‰é£é™©", "ä¸­é«˜é£é™©", "é«˜é£é™©"],
        index=1,
        help="é€‰æ‹©å¯æ¥å—çš„é£é™©æ°´å¹³"
    )
    
    # ç»“æœæ•°é‡
    limit = st.selectbox(
        "è¿”å›æ•°é‡",
        options=[10, 20, 30, 50],
        index=2,
        help="AIæ¨èè‚¡ç¥¨æ•°é‡"
    )
    
    # ä¿å­˜å‚æ•°
    st.session_state.ai_enhanced_params = {
        'min_ai_score': min_ai_score,
        'min_confidence': min_confidence,
        'risk_tolerance': risk_tolerance,
        'limit': limit
    }

def render_expert_committee_form():
    """æ¸²æŸ“ä¸“å®¶å§”å‘˜ä¼šè¡¨å•"""
    st.markdown("#### ğŸ’¼ ä¸“å®¶å§”å‘˜ä¼šå†³ç­–")
    st.info("ğŸ‘¥ 5åä¸“å®¶åˆ†æå¸ˆï¼šå¸‚åœºã€åŸºæœ¬é¢ã€æ–°é—»ã€ç¤¾äº¤åª’ä½“ã€çƒ­åº¦åˆ†æ")
    
    # ä¸“å®¶è¯„åˆ†è¦æ±‚
    min_expert_score = st.slider(
        "ä¸“å®¶å§”å‘˜ä¼šæœ€ä½è¯„åˆ†",
        min_value=0,
        max_value=100,
        value=80,
        step=5,
        help="ä¸“å®¶å§”å‘˜ä¼šç»¼åˆè¯„åˆ†è¦æ±‚"
    )
    
    # ä¸€è‡´æ€§è¦æ±‚
    consensus_level = st.selectbox(
        "ä¸€è‡´æ€§è¦æ±‚",
        options=["æ„è§åˆ†åŒ–", "å­˜åœ¨åˆ†æ­§", "åŸºæœ¬ä¸€è‡´", "é«˜åº¦ä¸€è‡´"],
        index=2,
        help="ä¸“å®¶æ„è§çš„ä¸€è‡´æ€§è¦æ±‚"
    )
    
    # ç»“æœæ•°é‡
    limit = st.selectbox(
        "è¿”å›æ•°é‡",
        options=[10, 15, 25, 30],
        index=2,
        help="ä¸“å®¶å§”å‘˜ä¼šæ¨èè‚¡ç¥¨æ•°é‡"
    )
    
    st.session_state.expert_committee_params = {
        'min_expert_score': min_expert_score,
        'consensus_level': consensus_level,
        'limit': limit
    }

def render_adaptive_strategy_form():
    """æ¸²æŸ“è‡ªé€‚åº”ç­–ç•¥è¡¨å•"""
    st.markdown("#### ğŸ”„ è‡ªé€‚åº”ç­–ç•¥")
    st.info("ğŸŒ¡ï¸ æ ¹æ®å¸‚åœºç¯å¢ƒè‡ªåŠ¨è°ƒæ•´ï¼šç‰›å¸‚/ç†Šå¸‚/éœ‡è¡/é«˜æ³¢åŠ¨/å¤è‹")
    
    # ç­–ç•¥åå¥½
    strategy_preference = st.selectbox(
        "ç­–ç•¥åå¥½",
        options=["è‡ªåŠ¨é€‚åº”", "æˆé•¿å‹", "ä»·å€¼å‹", "åŠ¨é‡å‹", "è´¨é‡å‹", "é˜²å¾¡å‹", "è¿›æ”»å‹"],
        index=0,
        help="ç­–ç•¥ç±»å‹åå¥½ï¼Œé€‰æ‹©è‡ªåŠ¨é€‚åº”å°†æ ¹æ®å¸‚åœºç¯å¢ƒé€‰æ‹©æœ€ä¼˜ç­–ç•¥"
    )
    
    # é£é™©åå¥½
    risk_preference = st.slider(
        "é£é™©åå¥½",
        min_value=0.1,
        max_value=1.0,
        value=0.6,
        step=0.1,
        help="0.1=ä¿å®ˆï¼Œ1.0=æ¿€è¿›"
    )
    
    # ç»“æœæ•°é‡
    limit = st.selectbox(
        "è¿”å›æ•°é‡",
        options=[15, 25, 40, 50],
        index=2,
        help="è‡ªé€‚åº”ç­–ç•¥æ¨èè‚¡ç¥¨æ•°é‡"
    )
    
    st.session_state.adaptive_strategy_params = {
        'strategy_preference': strategy_preference,
        'risk_preference': risk_preference,
        'limit': limit
    }

def render_pattern_based_form():
    """æ¸²æŸ“æ¨¡å¼è¯†åˆ«è¡¨å•"""
    st.markdown("#### ğŸ“ˆ æ¨¡å¼è¯†åˆ«é€‰è‚¡")
    st.info("ğŸ¤“ è¯†åˆ«12ç§æŠ€æœ¯æ¨¡å¼ï¼šè¶‹åŠ¿ã€çªç ´ã€åè½¬ã€åŠ¨é‡ã€æˆäº¤é‡ç­‰")
    
    # æ¨¡å¼ç±»å‹é€‰æ‹©
    pattern_types = st.multiselect(
        "æœŸæœ›æ¨¡å¼ç±»å‹",
        options=["çœ‹æ¶¨è¶‹åŠ¿", "å‘ä¸Šçªç ´", "çœ‹æ¶¨åè½¬", "å¼ºåŠ¿åŠ¨é‡", "æˆäº¤é‡å¼‚å¸¸", "ä½æ³¢åŠ¨ç‡"],
        default=["çœ‹æ¶¨è¶‹åŠ¿", "å‘ä¸Šçªç ´"],
        help="é€‰æ‹©å¸Œæœ›æ‰¾åˆ°çš„æŠ€æœ¯æ¨¡å¼"
    )
    
    # æ¨¡å¼è¯„åˆ†è¦æ±‚
    min_pattern_score = st.slider(
        "æœ€å°æ¨¡å¼è¯„åˆ†",
        min_value=50,
        max_value=100,
        value=75,
        step=5,
        help="æ¨¡å¼è¯†åˆ«çš„æœ€ä½è¯„åˆ†è¦æ±‚"
    )
    
    # ç½®ä¿¡åº¦è¦æ±‚
    min_pattern_confidence = st.slider(
        "æ¨¡å¼ç½®ä¿¡åº¦",
        min_value=0.5,
        max_value=1.0,
        value=0.75,
        step=0.05,
        help="æ¨¡å¼è¯†åˆ«çš„æœ€ä½ç½®ä¿¡åº¦"
    )
    
    # ç»“æœæ•°é‡
    limit = st.selectbox(
        "è¿”å›æ•°é‡",
        options=[15, 25, 35, 50],
        index=2,
        help="æ¨¡å¼é©±åŠ¨é€‰è‚¡ç»“æœæ•°é‡"
    )
    
    st.session_state.pattern_based_params = {
        'pattern_types': pattern_types,
        'min_pattern_score': min_pattern_score,
        'min_pattern_confidence': min_pattern_confidence,
        'limit': limit
    }

def render_full_ai_form():
    """æ¸²æŸ“å®Œæ•´AIè¡¨å•"""
    st.markdown("#### ğŸ† å®Œæ•´AIåˆ†æ")
    st.warning("âš ï¸ å®Œæ•´AIåˆ†æéœ€è¦æ›´é•¿æ—¶é—´ï¼Œä½†æä¾›æœ€å…¨é¢çš„æ™ºèƒ½åˆ†æ")
    
    # ç»¼åˆè¯„åˆ†è¦æ±‚
    min_overall_score = st.slider(
        "AIç»¼åˆè¯„åˆ†",
        min_value=60,
        max_value=100,
        value=85,
        step=5,
        help="å®Œæ•´AIåˆ†æçš„æœ€é«˜è¯„åˆ†è¦æ±‚"
    )
    
    # ç½®ä¿¡åº¦è¦æ±‚
    min_confidence = st.slider(
        "æœ€é«˜ç½®ä¿¡åº¦",
        min_value=0.6,
        max_value=1.0,
        value=0.8,
        step=0.05,
        help="AIåˆ†æçš„æœ€é«˜ç½®ä¿¡åº¦è¦æ±‚"
    )
    
    # é£é™©æ‰¿å—åº¦
    risk_tolerance = st.selectbox(
        "é£é™©æ‰¿å—åº¦",
        options=["ä½é£é™©", "ä¸­ç­‰é£é™©", "ä¸­é«˜é£é™©"],
        index=1,
        help="å®Œæ•´AIåˆ†æçš„é£é™©æ‰¿å—åº¦"
    )
    
    # ç»“æœæ•°é‡
    limit = st.selectbox(
        "ç²¾é€‰æ•°é‡",
        options=[5, 10, 15, 20],
        index=3,
        help="å®Œæ•´AIåˆ†æçš„ç²¾é€‰è‚¡ç¥¨æ•°é‡"
    )
    
    st.session_state.full_ai_params = {
        'min_overall_score': min_overall_score,
        'min_confidence': min_confidence,
        'risk_tolerance': risk_tolerance,
        'limit': limit
    }

def execute_stock_selection(selector, mode):
    """æ‰§è¡Œé€‰è‚¡æ“ä½œ"""
    try:
        # è·å–å¸‚åœºç±»å‹
        market_type = st.session_state.get('market_type', 'Aè‚¡')
        
        # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºå®¹å™¨
        progress_container = st.container()
        with progress_container:
            # æ£€æŸ¥æ˜¯å¦æ˜¯AIæ¨¡å¼
            is_ai_mode = mode in ["é¾™è™æ¦œå¢å¼ºé€‰è‚¡", "AIå¢å¼ºé€‰è‚¡", "ä¸“å®¶å§”å‘˜ä¼š", "è‡ªé€‚åº”ç­–ç•¥", "æ¨¡å¼è¯†åˆ«", "å®Œæ•´AIåˆ†æ"]
            
            if is_ai_mode:
                st.info(f"ğŸ¤– æ­£åœ¨å¯åŠ¨{market_type}AIä¸“å®¶ç³»ç»Ÿ...")
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # æ˜¾ç¤ºAIåˆ†ææ­¥éª¤
                ai_steps = [
                    f"ğŸ” è·å–{market_type}è‚¡ç¥¨åŸºç¡€æ•°æ®",
                    "ğŸ¤– å¯åŠ¨AIä¸“å®¶å§”å‘˜ä¼š",
                    "ğŸ“Š æ‰§è¡Œå¤šç»´åº¦åˆ†æ",
                    "âš–ï¸ èåˆä¸“å®¶æ„è§",
                    "ğŸ¯ ç”Ÿæˆæ™ºèƒ½æ¨è"
                ]
                
                for i, step in enumerate(ai_steps):
                    status_text.text(step)
                    progress_bar.progress((i + 1) * 20)
                    import time
                    time.sleep(0.5)  # æ¨¡æ‹Ÿåˆ†æè¿‡ç¨‹
        
        if mode == "é¾™è™æ¦œå¢å¼ºé€‰è‚¡":
            params = st.session_state.get('longhubang_enhanced_params', {})
            
            # å¯¼å…¥é¾™è™æ¦œç›¸å…³æšä¸¾
            try:
                from tradingagents.dataflows.longhubang_utils import RankingType
                from tradingagents.selectors.ai_strategies.ai_strategy_manager import AIMode
                
                # è½¬æ¢æ’è¡Œæ¦œç±»å‹
                ranking_type_map = {
                    "daily": RankingType.DAILY,
                    "limit_up": RankingType.LIMIT_UP,
                    "limit_down": RankingType.LIMIT_DOWN,
                    "turnover": RankingType.TURNOVER,
                    "amplitude": RankingType.AMPLITUDE,
                    "volume": RankingType.VOLUME,
                    "turnover_rate": RankingType.TURNOVER_RATE
                }
                
                ranking_type = ranking_type_map.get(params.get('ranking_type', 'daily'), RankingType.DAILY)
                
                # è½¬æ¢AIæ¨¡å¼
                ai_mode_map = {
                    "AI_ENHANCED": AIMode.AI_ENHANCED,
                    "EXPERT_COMMITTEE": AIMode.EXPERT_COMMITTEE,
                    "ADAPTIVE": AIMode.ADAPTIVE,
                    "PATTERN_BASED": AIMode.PATTERN_BASED,
                    "FULL_AI": AIMode.FULL_AI
                }
                
                ai_mode = ai_mode_map.get(params.get('ai_mode'), AIMode.AI_ENHANCED)
                
                result = selector.longhubang_enhanced_select(
                    date=params.get('date'),
                    ranking_type=ranking_type,
                    min_longhubang_score=params.get('min_longhubang_score', 60),
                    enable_ai_analysis=params.get('enable_ai_analysis', True),
                    ai_mode=ai_mode,
                    limit=params.get('limit', 30)
                )
                
            except ImportError as e:
                st.error(f"âŒ é¾™è™æ¦œåŠŸèƒ½ä¸å¯ç”¨: {e}")
                st.info("ğŸ’¡ è¯·ç¡®ä¿é¾™è™æ¦œåˆ†ææ¨¡å—å·²æ­£ç¡®å®‰è£…")
                return
                
        elif mode == "å¿«é€Ÿé€‰è‚¡":
            params = st.session_state.get('quick_params', {})
            result = selector.quick_select(
                min_score=params.get('min_score', 70),
                min_market_cap=params.get('min_market_cap', 50),
                max_pe_ratio=params.get('max_pe_ratio', 30),
                grades=params.get('grades', ['A+', 'A']),
                limit=params.get('limit', 20)
            )
        elif mode == "AIå¢å¼ºé€‰è‚¡":
            params = st.session_state.get('ai_enhanced_params', {})
            result = selector.ai_enhanced_select(
                min_ai_score=params.get('min_ai_score', 75),
                min_confidence=params.get('min_confidence', 0.7),
                max_risk_level=params.get('risk_tolerance', 'ä¸­ç­‰é£é™©'),
                limit=params.get('limit', 30)
            )
        elif mode == "ä¸“å®¶å§”å‘˜ä¼š":
            params = st.session_state.get('expert_committee_params', {})
            result = selector.expert_committee_select(
                min_expert_score=params.get('min_expert_score', 80),
                min_consensus=params.get('consensus_level', 'åŸºæœ¬ä¸€è‡´'),
                limit=params.get('limit', 25)
            )
        elif mode == "è‡ªé€‚åº”ç­–ç•¥":
            params = st.session_state.get('adaptive_strategy_params', {})
            result = selector.adaptive_strategy_select(
                limit=params.get('limit', 40)
            )
        elif mode == "æ¨¡å¼è¯†åˆ«":
            params = st.session_state.get('pattern_based_params', {})
            result = selector.pattern_based_select(
                pattern_types=params.get('pattern_types', []),
                min_pattern_score=params.get('min_pattern_score', 75),
                limit=params.get('limit', 35)
            )
        elif mode == "å®Œæ•´AIåˆ†æ":
            params = st.session_state.get('full_ai_params', {})
            result = selector.full_ai_select(
                min_overall_score=params.get('min_overall_score', 85),
                min_confidence=params.get('min_confidence', 0.8),
                risk_tolerance=params.get('risk_tolerance', 'ä¸­ç­‰é£é™©'),
                limit=params.get('limit', 20)
            )
        else:
            # è‡ªå®šä¹‰ç­›é€‰é€»è¾‘
            from tradingagents.selectors.stock_selector import SelectionCriteria
            from tradingagents.selectors.filter_conditions import FilterOperator
            
            params = st.session_state.get('custom_params', {})
            conditions = params.get('conditions', [])
            
            # æ„å»ºç­›é€‰å™¨
            filters = []
            for cond in conditions:
                if cond['operator'] == '>=':
                    op = FilterOperator.GREATER_EQUAL
                elif cond['operator'] == '<=':
                    op = FilterOperator.LESS_EQUAL
                elif cond['operator'] == '=':
                    op = FilterOperator.EQUAL
                else:  # !=
                    op = FilterOperator.NOT_EQUAL
                
                filter_obj = selector.create_numeric_filter(
                    cond['field'], op, cond['value']
                )
                filters.append(filter_obj)
            
            criteria = SelectionCriteria(
                filters=filters,
                sort_by=params.get('sort_field', 'overall_score'),
                sort_ascending=not params.get('sort_desc', True),
                limit=params.get('limit', 50),
                include_scores=True,
                include_basic_info=True
            )
            
            result = selector.select_stocks(criteria)
        
        # æ¸…ç†è¿›åº¦æ˜¾ç¤º
        if is_ai_mode:
            progress_container.empty()
        
        # ä¿å­˜ç»“æœåˆ°session state
        st.session_state.selection_result = result
        st.session_state.selection_mode = mode  # ä¿å­˜é€‰è‚¡æ¨¡å¼
        
        # è·å–å¸‚åœºç±»å‹
        market_type = st.session_state.get('market_type', 'Aè‚¡')
        
        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯å’ŒAIåˆ†ææ‘˜è¦
        success_col1, success_col2 = st.columns([2, 1])
        with success_col1:
            st.success(f"âœ… {market_type}é€‰è‚¡å®Œæˆ! æ‰¾åˆ° {len(result.symbols)} åªè‚¡ç¥¨")
            
        with success_col2:
            if is_ai_mode and hasattr(result, 'data') and not result.data.empty:
                # æ˜¾ç¤ºAIåˆ†ææ‘˜è¦
                if 'ai_overall_score' in result.data.columns:
                    avg_ai_score = result.data['ai_overall_score'].mean()
                    st.metric("AIå¹³å‡è¯„åˆ†", f"{avg_ai_score:.1f}")
                
        # æ˜¾ç¤ºAIå†³ç­–è¿‡ç¨‹æ‘˜è¦
        if is_ai_mode and hasattr(result, 'data') and not result.data.empty:
            with st.expander("ğŸ¤– AIå†³ç­–è¿‡ç¨‹è¯¦æƒ…", expanded=True):
                st.markdown(f"**ğŸ“‹ é€‰è‚¡æ¨¡å¼**: {mode}")
                st.markdown(f"**ğŸŒ å¸‚åœºç±»å‹**: {market_type}")
                st.markdown(f"**ğŸ¯ AIå‚ä¸ç¨‹åº¦**: æ·±åº¦æ™ºèƒ½åˆ†æ")
                
                # æ˜¾ç¤ºAIå¼•æ“çŠ¶æ€
                if 'ai_overall_score' in result.data.columns:
                    ai_scores = result.data['ai_overall_score'].dropna()
                    if len(ai_scores) > 0:
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("AIå¹³å‡è¯„åˆ†", f"{ai_scores.mean():.1f}")
                        with col2:
                            st.metric("AIæœ€é«˜è¯„åˆ†", f"{ai_scores.max():.1f}")
                        with col3:
                            st.metric("AIæœ€ä½è¯„åˆ†", f"{ai_scores.min():.1f}")
                        with col4:
                            high_score_count = len(ai_scores[ai_scores >= 80])
                            st.metric("ä¼˜è´¨è‚¡ç¥¨", f"{high_score_count}åª")
                
                # æ˜¾ç¤ºAIå¼•æ“è´¡çŒ®
                engine_contributions = []
                if 'expert_committee_score' in result.data.columns:
                    expert_scores = result.data['expert_committee_score'].dropna()
                    if len(expert_scores) > 0:
                        engine_contributions.append(f"ä¸“å®¶å§”å‘˜ä¼š: {expert_scores.mean():.1f}")
                
                if 'adaptive_strategy_score' in result.data.columns:
                    adaptive_scores = result.data['adaptive_strategy_score'].dropna()
                    if len(adaptive_scores) > 0:
                        engine_contributions.append(f"è‡ªé€‚åº”ç­–ç•¥: {adaptive_scores.mean():.1f}")
                
                if 'pattern_recognition_score' in result.data.columns:
                    pattern_scores = result.data['pattern_recognition_score'].dropna()
                    if len(pattern_scores) > 0:
                        engine_contributions.append(f"æ¨¡å¼è¯†åˆ«: {pattern_scores.mean():.1f}")
                
                if engine_contributions:
                    st.markdown("**ğŸ¤– AIå¼•æ“è´¡çŒ®**:")
                    for contribution in engine_contributions:
                        st.write(f"   â€¢ {contribution}")
                
                # æ˜¾ç¤ºç½®ä¿¡åº¦åˆ†æ
                if 'ai_confidence' in result.data.columns:
                    confidence_data = result.data['ai_confidence'].dropna()
                    if len(confidence_data) > 0:
                        st.markdown("**ğŸ“Š AIç½®ä¿¡åº¦åˆ†æ**:")
                        high_conf = len(confidence_data[confidence_data >= 0.8])
                        med_conf = len(confidence_data[(confidence_data >= 0.6) & (confidence_data < 0.8)])
                        low_conf = len(confidence_data[confidence_data < 0.6])
                        avg_conf = confidence_data.mean()
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("é«˜ç½®ä¿¡åº¦", f"{high_conf}åª")
                        with col2:
                            st.metric("ä¸­ç½®ä¿¡åº¦", f"{med_conf}åª")
                        with col3:
                            st.metric("ä½ç½®ä¿¡åº¦", f"{low_conf}åª")
                        with col4:
                            st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_conf:.2f}")
                
                # æ˜¾ç¤ºæ¨èåˆ†å¸ƒ
                if 'ai_recommendation' in result.data.columns:
                    recommendations = result.data['ai_recommendation'].dropna().value_counts()
                    if len(recommendations) > 0:
                        st.markdown("**ğŸ’¡ AIæ¨èåˆ†å¸ƒ**:")
                        for rec, count in recommendations.head(5).items():
                            st.write(f"   â€¢ {rec}: {count}åª")
                
                # æ˜¾ç¤ºé£é™©è¯„ä¼°
                if 'ai_risk_assessment' in result.data.columns:
                    risk_data = result.data['ai_risk_assessment'].dropna().value_counts()
                    if len(risk_data) > 0:
                        st.markdown("**âš ï¸ é£é™©è¯„ä¼°åˆ†å¸ƒ**:")
                        for risk, count in risk_data.head(5).items():
                            st.write(f"   â€¢ {risk}: {count}åª")
                
                # æ˜¾ç¤ºå¸‚åœºç¯å¢ƒåˆ†æ
                if 'market_regime' in result.data.columns:
                    regime_data = result.data['market_regime'].dropna().value_counts()
                    if len(regime_data) > 0:
                        st.markdown("**ğŸŒ¡ï¸ å¸‚åœºç¯å¢ƒåˆ†æ**:")
                        for regime, count in regime_data.items():
                            if regime and regime != 'æœªçŸ¥':
                                st.write(f"   â€¢ {regime}: {count}åª")
                
                # æ˜¾ç¤ºæ¨¡å¼è¯†åˆ«ç»“æœ
                if 'detected_patterns' in result.data.columns:
                    patterns_data = result.data['detected_patterns'].dropna()
                    if len(patterns_data) > 0:
                        st.markdown("**ğŸ“ˆ æ¨¡å¼è¯†åˆ«ç»“æœ**:")
                        all_patterns = []
                        for patterns_str in patterns_data:
                            try:
                                if isinstance(patterns_str, str) and patterns_str != '[]':
                                    patterns = patterns_str.replace('[', '').replace(']', '').replace("'", '').split(', ')
                                    all_patterns.extend([p.strip() for p in patterns if p.strip()])
                            except:
                                continue
                        
                        if all_patterns:
                            from collections import Counter
                            pattern_counts = Counter(all_patterns).most_common(5)
                            for pattern, count in pattern_counts:
                                st.write(f"   â€¢ {pattern}: {count}æ¬¡")
        
        logger.info(f"ğŸ“Š [é€‰è‚¡æˆåŠŸ] {mode}æ¨¡å¼æ‰¾åˆ° {len(result.symbols)} åªè‚¡ç¥¨")
        
    except Exception as e:
        st.error(f"âŒ é€‰è‚¡å¤±è´¥: {e}")
        logger.error(f"âŒ [é€‰è‚¡å¤±è´¥] {e}")

def display_selection_results():
    """æ˜¾ç¤ºé€‰è‚¡ç»“æœ"""
    if 'selection_result' not in st.session_state:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è®¾ç½®æ¡ä»¶å¹¶æ‰§è¡Œé€‰è‚¡")
        return
    
    result = st.session_state.selection_result
    
    if not result.symbols:
        st.warning("ğŸ˜” æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
        return
    
    # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("å€™é€‰æ€»æ•°", result.total_candidates)
    with col2:
        st.metric("ç­›é€‰ç»“æœ", result.filtered_count)
    with col3:
        st.metric("æˆåŠŸç‡", f"{result.summary.get('success_rate', 0):.1f}%")
    with col4:
        st.metric("æ‰§è¡Œæ—¶é—´", f"{result.execution_time:.2f}s")
    
    st.markdown("---")
    
    # æ˜¾ç¤ºè‚¡ç¥¨åˆ—è¡¨
    st.markdown("### ğŸ“‹ é€‰è‚¡ç»“æœ")
    
    if not result.data.empty:
        # å‡†å¤‡æ˜¾ç¤ºæ•°æ®
        display_data = result.data.copy()
        
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        display_columns = []
        if 'ts_code' in display_data.columns:
            display_columns.append('ts_code')
        if 'name' in display_data.columns:
            display_columns.append('name')
        
        # é¾™è™æ¦œç‰¹æœ‰åˆ—ä¼˜å…ˆæ˜¾ç¤º
        selection_mode = st.session_state.get('selection_mode', '')
        if selection_mode == "é¾™è™æ¦œå¢å¼ºé€‰è‚¡":
            if 'longhubang_overall_score' in display_data.columns:
                display_columns.append('longhubang_overall_score')
            if 'longhubang_ai_combined_score' in display_data.columns:
                display_columns.append('longhubang_ai_combined_score')
            if 'market_sentiment' in display_data.columns:
                display_columns.append('market_sentiment')
            if 'operation_pattern' in display_data.columns:
                display_columns.append('operation_pattern')
            if 'battle_result' in display_data.columns:
                display_columns.append('battle_result')
            if 'investment_suggestion' in display_data.columns:
                display_columns.append('investment_suggestion')
            if 'net_inflow' in display_data.columns:
                display_columns.append('net_inflow')
            if 'current_price' in display_data.columns:
                display_columns.append('current_price')
            if 'change_pct' in display_data.columns:
                display_columns.append('change_pct')
        
        # AIå¢å¼ºåˆ—ä¼˜å…ˆæ˜¾ç¤º
        if 'ai_overall_score' in display_data.columns:
            display_columns.append('ai_overall_score')
        if 'ai_recommendation' in display_data.columns:
            display_columns.append('ai_recommendation')
        if 'ai_confidence' in display_data.columns:
            display_columns.append('ai_confidence')
        if 'ai_risk_assessment' in display_data.columns:
            display_columns.append('ai_risk_assessment')
            
        # ä¼ ç»Ÿåˆ—
        if 'overall_score' in display_data.columns:
            display_columns.append('overall_score')
        if 'grade' in display_data.columns:
            display_columns.append('grade')
        if 'market_cap' in display_data.columns:
            display_columns.append('market_cap')
        if 'pe_ratio' in display_data.columns:
            display_columns.append('pe_ratio')
            
        # ä¸“ä¸šåˆ—
        if 'expert_committee_score' in display_data.columns:
            display_columns.append('expert_committee_score')
        if 'adaptive_strategy_score' in display_data.columns:
            display_columns.append('adaptive_strategy_score')
        if 'pattern_recognition_score' in display_data.columns:
            display_columns.append('pattern_recognition_score')
        if 'market_regime' in display_data.columns:
            display_columns.append('market_regime')
        
        # æ˜¾ç¤ºè¡¨æ ¼
        if display_columns:
            st.dataframe(
                display_data[display_columns].head(50),
                use_container_width=True,
                hide_index=True
            )
        else:
            # å¦‚æœæ²¡æœ‰é¢„æœŸçš„åˆ—ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®
            st.dataframe(display_data.head(50), use_container_width=True)
    else:
        # åªæ˜¾ç¤ºè‚¡ç¥¨ä»£ç åˆ—è¡¨
        symbols_df = pd.DataFrame({
            'åºå·': range(1, len(result.symbols) + 1),
            'è‚¡ç¥¨ä»£ç ': result.symbols
        })
        st.dataframe(symbols_df, use_container_width=True, hide_index=True)
    
    # æ˜¾ç¤ºAIæ´å¯Ÿé¢æ¿
    if not result.data.empty:
        display_ai_insights(result.data)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if 'statistics' in result.summary:
        with st.expander("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯", expanded=False):
            stats = result.summary['statistics']
            
            for field, stat_data in list(stats.items())[:5]:  # æ˜¾ç¤ºå‰5ä¸ªç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(f"{field} å¹³å‡", f"{stat_data.get('mean', 0):.2f}")
                with col2:
                    st.metric(f"{field} æœ€å¤§", f"{stat_data.get('max', 0):.2f}")
                with col3:
                    st.metric(f"{field} æœ€å°", f"{stat_data.get('min', 0):.2f}")
    
    # å¯¼å‡ºåŠŸèƒ½
    if st.button("ğŸ“„ å¯¼å‡ºç»“æœ", help="å¯¼å‡ºé€‰è‚¡ç»“æœåˆ°CSVæ–‡ä»¶"):
        try:
            csv_data = result.data.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ’¾ ä¸‹è½½CSVæ–‡ä»¶",
                data=csv_data,
                file_name=f"é€‰è‚¡ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        except Exception as e:
            st.error(f"å¯¼å‡ºå¤±è´¥: {e}")

def display_ai_insights(data: pd.DataFrame):
    """æ˜¾ç¤ºAIæ´å¯Ÿé¢æ¿"""
    if data.empty:
        return
        
    # æ£€æŸ¥æ˜¯å¦æœ‰AIç›¸å…³åˆ—å’Œé¾™è™æ¦œç›¸å…³åˆ—
    ai_columns = ['ai_overall_score', 'ai_confidence', 'ai_recommendation', 'ai_risk_assessment',
                 'expert_committee_score', 'adaptive_strategy_score', 'pattern_recognition_score',
                 'market_regime', 'detected_patterns', 'key_factors']
    
    longhubang_columns = ['longhubang_overall_score', 'longhubang_ai_combined_score', 
                         'market_sentiment', 'operation_pattern', 'battle_result',
                         'investment_suggestion', 'risk_warning', 'follow_recommendation',
                         'net_inflow', 'buy_seat_count', 'sell_seat_count']
    
    has_ai_data = any(col in data.columns for col in ai_columns)
    has_longhubang_data = any(col in data.columns for col in longhubang_columns)
    
    if not has_ai_data and not has_longhubang_data:
        return
    
    with st.expander("ğŸ¤– AIåˆ†ææ´å¯Ÿ", expanded=True):
        
        # æ˜¾ç¤ºé€‰è‚¡æ¨¡å¼å’ŒAIå‚ä¸ç¨‹åº¦
        selection_mode = st.session_state.get('selection_mode', 'æœªçŸ¥')
        if selection_mode == "é¾™è™æ¦œå¢å¼ºé€‰è‚¡":
            st.success(f"ğŸ‰ é€‰è‚¡æ¨¡å¼: {selection_mode} | ğŸš€ æ€§èƒ½çªç ´ + é¾™è™æ¦œæ™ºèƒ½åˆ†æ")
            
            # é¾™è™æ¦œç‰¹æœ‰åˆ†æ
            if has_longhubang_data:
                display_longhubang_insights(data)
        elif selection_mode in ["AIå¢å¼ºé€‰è‚¡", "ä¸“å®¶å§”å‘˜ä¼š", "è‡ªé€‚åº”ç­–ç•¥", "æ¨¡å¼è¯†åˆ«", "å®Œæ•´AIåˆ†æ"]:
            st.info(f"ğŸ“‹ é€‰è‚¡æ¨¡å¼: {selection_mode} | ğŸ¤– AIä¸“å®¶ç³»ç»Ÿæ·±åº¦å‚ä¸")
        else:
            st.info(f"ğŸ“‹ é€‰è‚¡æ¨¡å¼: {selection_mode} | ğŸ“Š ä¼ ç»Ÿç­›é€‰ + AIæ™ºèƒ½æ’åº")
        
        # AIè¯„åˆ†åˆ†å¸ƒ
        if 'ai_overall_score' in data.columns:
            st.markdown("##### ğŸ¯ AIç»¼åˆè¯„åˆ†åˆ†æ")
            
            col1, col2, col3, col4 = st.columns(4)
            ai_scores = data['ai_overall_score'].dropna()
            
            if not ai_scores.empty:
                with col1:
                    st.metric("AIå¹³å‡è¯„åˆ†", f"{ai_scores.mean():.1f}")
                with col2:
                    st.metric("AIæœ€é«˜è¯„åˆ†", f"{ai_scores.max():.1f}")
                with col3:
                    high_score_count = len(ai_scores[ai_scores >= 80])
                    st.metric("ä¼˜è´¨è‚¡ç¥¨ (â‰¥80)", high_score_count)
                with col4:
                    # è®¡ç®—æ™ºèƒ½è¯„åˆ†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if 'intelligent_score' in data.columns:
                        intelligent_scores = data['intelligent_score'].dropna()
                        if not intelligent_scores.empty:
                            st.metric("æ™ºèƒ½è¯„åˆ†", f"{intelligent_scores.mean():.1f}")
                    else:
                        st.metric("åˆ†æå®Œæˆ", f"{len(ai_scores)}åª")
                
                # è¯„åˆ†åˆ†å¸ƒå›¾
                score_ranges = {
                    '90-100åˆ† (å“è¶Š)': len(ai_scores[ai_scores >= 90]),
                    '80-89åˆ† (ä¼˜ç§€)': len(ai_scores[(ai_scores >= 80) & (ai_scores < 90)]),
                    '70-79åˆ† (è‰¯å¥½)': len(ai_scores[(ai_scores >= 70) & (ai_scores < 80)]),
                    '60-69åˆ† (ä¸€èˆ¬)': len(ai_scores[(ai_scores >= 60) & (ai_scores < 70)]),
                    'ä½äº60åˆ†': len(ai_scores[ai_scores < 60])
                }
                
                # åªæ˜¾ç¤ºæœ‰æ•°æ®çš„èŒƒå›´
                filtered_ranges = {k: v for k, v in score_ranges.items() if v > 0}
                if filtered_ranges:
                    st.markdown("**ğŸ“Š AIè¯„åˆ†åˆ†å¸ƒ**")
                    import pandas as pd
                    score_df = pd.DataFrame(list(filtered_ranges.items()), columns=['è¯„åˆ†èŒƒå›´', 'è‚¡ç¥¨æ•°é‡'])
                    score_df = score_df.set_index('è¯„åˆ†èŒƒå›´')
                    st.bar_chart(score_df)
        
        # ç½®ä¿¡åº¦åˆ†æ
        if 'ai_confidence' in data.columns:
            st.markdown("##### ğŸ¯ AIç½®ä¿¡åº¦åˆ†å¸ƒ")
            confidence_data = data['ai_confidence'].dropna()
            if not confidence_data.empty:
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    high_conf = len(confidence_data[confidence_data >= 0.8])
                    st.metric("é«˜ç½®ä¿¡åº¦ (â‰¥0.8)", high_conf)
                with col2:
                    med_conf = len(confidence_data[(confidence_data >= 0.6) & (confidence_data < 0.8)])
                    st.metric("ä¸­ç½®ä¿¡åº¦ (0.6-0.8)", med_conf)
                with col3:
                    low_conf = len(confidence_data[confidence_data < 0.6])
                    st.metric("ä½ç½®ä¿¡åº¦ (<0.6)", low_conf)
                with col4:
                    avg_conf = confidence_data.mean()
                    st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_conf:.2f}")
        
        # AIæ¨èåˆ†å¸ƒ
        if 'ai_recommendation' in data.columns:
            st.markdown("##### ğŸ“Š AIæ¨èåˆ†å¸ƒ")
            recommendations = data['ai_recommendation'].dropna().value_counts()
            if not recommendations.empty:
                col1, col2 = st.columns(2)
                
                with col1:
                    for rec, count in recommendations.head(3).items():
                        st.metric(f"ğŸ”¸ {rec}", count)
                
                with col2:
                    # ç®€å•çš„æŸ±çŠ¶å›¾
                    st.bar_chart(recommendations.head(5))
        
        # é£é™©è¯„ä¼°åˆ†å¸ƒ
        if 'ai_risk_assessment' in data.columns:
            st.markdown("##### âš ï¸ é£é™©è¯„ä¼°åˆ†å¸ƒ")
            risk_data = data['ai_risk_assessment'].dropna().value_counts()
            if not risk_data.empty:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    low_risk = risk_data.get('ä½é£é™©', 0)
                    st.metric("ï¿½ï¸¢ ä½é£é™©", low_risk)
                with col2:
                    med_risk = risk_data.get('ä¸­ç­‰é£é™©', 0) + risk_data.get('ä¸­é«˜é£é™©', 0)
                    st.metric("ğŸ˜ ä¸­ç­‰é£é™©", med_risk)
                with col3:
                    high_risk = risk_data.get('é«˜é£é™©', 0)
                    st.metric("ğŸ˜± é«˜é£é™©", high_risk)
        
        # å¸‚åœºç¯å¢ƒåˆ†æ
        if 'market_regime' in data.columns:
            st.markdown("##### ğŸŒ¡ï¸ å¸‚åœºç¯å¢ƒåˆ†æ")
            regime_data = data['market_regime'].dropna().value_counts()
            if not regime_data.empty:
                st.write("å½“å‰è¯†åˆ«åˆ°çš„å¸‚åœºç¯å¢ƒ:")
                for regime, count in regime_data.items():
                    if regime and regime != 'æœªçŸ¥':
                        st.info(f"ğŸ“ˆ {regime}: {count} åªè‚¡ç¥¨")
        
        # æ¨¡å¼è¯†åˆ«ç»“æœ
        if 'detected_patterns' in data.columns:
            st.markdown("##### ğŸ“ˆ æ¨¡å¼è¯†åˆ«ç»“æœ")
            patterns_data = data['detected_patterns'].dropna()
            if not patterns_data.empty:
                all_patterns = []
                for patterns_str in patterns_data:
                    try:
                        if isinstance(patterns_str, str) and patterns_str != '[]':
                            # ç®€å•è§£æåˆ—è¡¨å­—ç¬¦ä¸²
                            patterns = patterns_str.replace('[', '').replace(']', '').replace('\'', '').split(', ')
                            all_patterns.extend([p.strip() for p in patterns if p.strip()])
                    except:
                        continue
                
                if all_patterns:
                    pattern_counts = pd.Series(all_patterns).value_counts().head(5)
                    for pattern, count in pattern_counts.items():
                        st.write(f"â€¢ {pattern}: {count} æ¬¡")
        
        # AIå¼•æ“æ€§èƒ½å¯¹æ¯”
        if any(col in data.columns for col in ['expert_committee_score', 'adaptive_strategy_score', 'pattern_recognition_score']):
            st.markdown("##### ğŸš€ AIå¼•æ“æ€§èƒ½å¯¹æ¯”")
            
            performance_data = {}
            if 'expert_committee_score' in data.columns:
                expert_scores = data['expert_committee_score'].dropna()
                if not expert_scores.empty:
                    performance_data['ä¸“å®¶å§”å‘˜ä¼š'] = expert_scores.mean()
            
            if 'adaptive_strategy_score' in data.columns:
                adaptive_scores = data['adaptive_strategy_score'].dropna()
                if not adaptive_scores.empty:
                    performance_data['è‡ªé€‚åº”ç­–ç•¥'] = adaptive_scores.mean()
            
            if 'pattern_recognition_score' in data.columns:
                pattern_scores = data['pattern_recognition_score'].dropna()
                if not pattern_scores.empty:
                    performance_data['æ¨¡å¼è¯†åˆ«'] = pattern_scores.mean()
            
            if performance_data:
                # æ˜¾ç¤ºæ€§èƒ½å¯¹æ¯”
                performance_df = pd.DataFrame(list(performance_data.items()), 
                                            columns=['å¼•æ“', 'å¹³å‡è¯„åˆ†'])
                performance_df = performance_df.set_index('å¼•æ“')
                st.bar_chart(performance_df)
        
        # å…³é”®å› å­åˆ†æ
        if 'key_factors' in data.columns:
            st.markdown("##### ğŸ”‘ å…³é”®å› å­åˆ†æ")
            factors_data = data['key_factors'].dropna()
            if not factors_data.empty:
                all_factors = []
                for factors_str in factors_data:
                    try:
                        if isinstance(factors_str, str) and factors_str != '[]':
                            # ç®€å•è§£æåˆ—è¡¨å­—ç¬¦ä¸²
                            factors = factors_str.replace('[', '').replace(']', '').replace('\'', '').split(', ')
                            all_factors.extend([f.strip() for f in factors if f.strip()])
                    except:
                        continue
                
                if all_factors:
                    factor_counts = pd.Series(all_factors).value_counts().head(8)
                    cols = st.columns(2)
                    for i, (factor, count) in enumerate(factor_counts.items()):
                        with cols[i % 2]:
                            st.write(f"â€¢ {factor}: {count} æ¬¡")

def run_ai_system_check():
    """è¿è¡ŒAIç³»ç»Ÿæ£€æŸ¥"""
    try:
        with st.spinner("ğŸ” æ­£åœ¨æ£€æŸ¥AIç³»ç»ŸçŠ¶æ€..."):
            from tradingagents.selectors.ai_debug_tools import get_ai_debug_tools
            debug_tools = get_ai_debug_tools()
            check_result = debug_tools.run_full_system_check()
        
        overall_status = check_result.get('overall_status', 'unknown')
        
        # æ˜¾ç¤ºæ£€æŸ¥ç»“æœ
        if overall_status == 'fully_operational':
            st.success("âœ… AIç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼šå®Œå…¨æ­£å¸¸")
        elif overall_status == 'partially_operational':
            st.warning("âš¡ AIç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼šéƒ¨åˆ†å¯ç”¨")
        elif overall_status == 'limited_functionality':
            st.warning("ğŸ”§ AIç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼šåŠŸèƒ½å—é™")
        elif overall_status == 'basic_mode':
            st.info("ğŸ“Š AIç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼šåŸºç¡€æ¨¡å¼")
        else:
            st.error("âŒ AIç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼šå­˜åœ¨é—®é¢˜")
        
        # æ˜¾ç¤ºè¯¦ç»†æŠ¥å‘Š
        with st.expander("ğŸ“‹ è¯¦ç»†æ£€æŸ¥æŠ¥å‘Š", expanded=False):
            report = debug_tools.get_debug_report()
            st.text(report)
        
        # æ˜¾ç¤ºå»ºè®®
        recommendations = check_result.get('recommendations', [])
        if recommendations:
            st.markdown("**ğŸ’¡ ç³»ç»Ÿå»ºè®®:**")
            for rec in recommendations:
                st.write(f"â€¢ {rec}")
                
    except Exception as e:
        st.error(f"âŒ ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")

def clear_ai_caches():
    """æ¸…ç†AIç¼“å­˜"""
    try:
        with st.spinner("ğŸ§¹ æ­£åœ¨æ¸…ç†AIç¼“å­˜..."):
            from tradingagents.selectors.ai_debug_tools import get_ai_debug_tools
            debug_tools = get_ai_debug_tools()
            result = debug_tools.clear_ai_caches()
        
        cleared_caches = result.get('cleared_caches', [])
        if cleared_caches:
            st.success(f"âœ… ç¼“å­˜æ¸…ç†å®Œæˆ: {', '.join(cleared_caches)}")
        else:
            st.warning("âš ï¸ æ²¡æœ‰å‘ç°å¯æ¸…ç†çš„ç¼“å­˜")
            
    except Exception as e:
        st.error(f"âŒ ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")

def render_ai_model_selector(selector):
    """æ¸²æŸ“AIæ¨¡å‹é€‰æ‹©å™¨ - å¤ç”¨è‚¡ç¥¨åˆ†æçš„ä¾§è¾¹æ é…ç½®"""
    try:
        st.markdown("**ğŸ§  AIæ¨¡å‹é…ç½®**")
        st.info("ğŸ’¡ **æç¤º**: æ™ºèƒ½é€‰è‚¡ä½¿ç”¨ä¸è‚¡ç¥¨åˆ†æç›¸åŒçš„AIæ¨¡å‹é…ç½®ï¼Œè¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸­é€‰æ‹©AIæ¨¡å‹")
        
        # ä»session stateè·å–å½“å‰é…ç½®
        llm_provider = st.session_state.get('llm_provider')
        llm_model = st.session_state.get('llm_model')
        
        if llm_provider and llm_model:
            st.markdown("**ğŸ¯ å½“å‰AIæ¨¡å‹:**")
            col1, col2 = st.columns(2)
            with col1:
                # æ˜¾ç¤ºä¾§è¾¹æ é…ç½®çš„æ¨¡å‹ä¿¡æ¯
                provider_display = {
                    'dashscope': 'ğŸ‡¨ğŸ‡³ é˜¿é‡Œäº‘DashScope',
                    'deepseek': 'ğŸš€ DeepSeek V3',
                    'kimi': 'ğŸŒ™ æœˆä¹‹æš—é¢Kimi',
                    'google': 'ğŸŒŸ Google AI',
                    'openrouter': 'ğŸŒ OpenRouter',
                    'glm': 'ğŸ§  æ™ºè°±GLM'
                }.get(llm_provider, llm_provider.upper())
                
                st.success(f"**{llm_model}**")
                st.caption(f"ä¾›åº”å•†: {provider_display}")
            with col2:
                # æ˜¾ç¤ºé…ç½®çŠ¶æ€
                try:
                    # éªŒè¯æ¨¡å‹æ˜¯å¦æ­£ç¡®é…ç½®
                    current_model_info = selector.get_current_ai_model_info()
                    if current_model_info:
                        st.metric("çŠ¶æ€", "âœ… å·²é…ç½®")
                        if 'temperature' in current_model_info:
                            st.metric("æ¸©åº¦å‚æ•°", f"{current_model_info.get('temperature', 0.7):.1f}")
                    else:
                        st.metric("çŠ¶æ€", "âš ï¸ å¾…åŒæ­¥")
                except:
                    st.metric("çŠ¶æ€", "ğŸ”„ åŠ è½½ä¸­")
        else:
            st.warning("âš ï¸ æœªæ£€æµ‹åˆ°å½“å‰AIæ¨¡å‹ï¼Œè¯·åœ¨å·¦ä¾§ä¾§è¾¹æ é…ç½®")
            st.markdown("**è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®AIæ¨¡å‹ï¼š**")
            st.markdown("1. åœ¨å·¦ä¾§ä¾§è¾¹æ æ‰¾åˆ° **ğŸ§  AIæ¨¡å‹é…ç½®**")
            st.markdown("2. é€‰æ‹© **LLMæä¾›å•†** (å¦‚ï¼šğŸ‡¨ğŸ‡³ é˜¿é‡Œç™¾ç‚¼)")
            st.markdown("3. é€‰æ‹© **æ¨¡å‹ç‰ˆæœ¬** (å¦‚ï¼šPlus - å¹³è¡¡)")
            st.markdown("4. é…ç½®å®Œæˆåï¼Œæ™ºèƒ½é€‰è‚¡å°†è‡ªåŠ¨ä½¿ç”¨è¯¥æ¨¡å‹")
        
        # è·å–å¯ç”¨æ¨¡å‹ç»Ÿè®¡
        available_models = selector.get_available_ai_models()
        if available_models:
            # æŒ‰ä¾›åº”å•†åˆ†ç»„ç»Ÿè®¡
            providers = {}
            for model_key, model_info in available_models.items():
                provider = model_info.get('provider', 'unknown')
                if provider not in providers:
                    providers[provider] = []
                providers[provider].append((model_key, model_info))
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            with st.expander("ğŸ“Š å¯ç”¨æ¨¡å‹æ¦‚è§ˆ", expanded=False):
                st.write(f"**æ€»è®¡**: {len(available_models)} ä¸ªæ¨¡å‹ï¼Œæ¥è‡ª {len(providers)} ä¸ªä¾›åº”å•†")
                
                provider_names = {
                    'openai': 'ğŸŒ OpenAI',
                    'dashscope': 'ğŸ‡¨ğŸ‡³ é˜¿é‡Œäº‘DashScope', 
                    'deepseek': 'ğŸš€ DeepSeek',
                    'google': 'ğŸ” Google AI',
                    'anthropic': 'ğŸ§  Anthropic',
                    'openrouter': 'ğŸŒ OpenRouter',
                    'kimi': 'ğŸŒ™ æœˆä¹‹æš—é¢Kimi'
                }
                
                for provider, models in providers.items():
                    provider_display = provider_names.get(provider, provider.title())
                    enabled_count = sum(1 for _, info in models if info.get('enabled') and info.get('has_api_key'))
                    total_count = len(models)
                    
                    if enabled_count > 0:
                        st.success(f"âœ… **{provider_display}**: {enabled_count}/{total_count} ä¸ªæ¨¡å‹å¯ç”¨")
                    else:
                        st.error(f"âŒ **{provider_display}**: éœ€è¦é…ç½®APIå¯†é’¥")
        
        st.markdown("---")
        st.markdown("**ğŸ“ è¯´æ˜**:")
        st.markdown("- æ™ºèƒ½é€‰è‚¡çš„æ‰€æœ‰AIæ¨¡å¼å°†ä½¿ç”¨æ‚¨åœ¨ä¾§è¾¹æ ä¸­é€‰æ‹©çš„AIæ¨¡å‹")
        st.markdown("- åŒ…æ‹¬ï¼šAIå¢å¼ºé€‰è‚¡ã€ä¸“å®¶å§”å‘˜ä¼šé€‰è‚¡ã€è‡ªé€‚åº”ç­–ç•¥é€‰è‚¡ç­‰")
        st.markdown("- å¦‚éœ€æ›´æ¢æ¨¡å‹ï¼Œè¯·åœ¨å·¦ä¾§ä¾§è¾¹æ çš„ **ğŸ§  AIæ¨¡å‹é…ç½®** ä¸­é€‰æ‹©")
    
    except Exception as e:
        st.error(f"âŒ AIæ¨¡å‹é€‰æ‹©å™¨åŠ è½½å¤±è´¥: {e}")
        st.markdown("è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–è”ç³»ç®¡ç†å‘˜")

def get_api_key_name(provider: str) -> str:
    """è·å–APIå¯†é’¥ç¯å¢ƒå˜é‡å"""
    key_map = {
        'openai': 'OPENAI_API_KEY',
        'dashscope': 'DASHSCOPE_API_KEY', 
        'deepseek': 'DEEPSEEK_API_KEY',
        'google': 'GOOGLE_API_KEY',
        'anthropic': 'ANTHROPIC_API_KEY',
        'openrouter': 'OPENROUTER_API_KEY',
        'kimi': 'KIMI_API_KEY'
    }
    return key_map.get(provider.lower(), f'{provider.upper()}_API_KEY')

def switch_ai_model(selector, model_key: str, model_info: Dict[str, Any]):
    """åˆ‡æ¢AIæ¨¡å‹"""
    try:
        with st.spinner(f"ğŸ”„ æ­£åœ¨åˆ‡æ¢åˆ° {model_info.get('display_name', model_key)}..."):
            success = selector.switch_ai_model(model_key)
        
        if success:
            st.success(f"âœ… æˆåŠŸåˆ‡æ¢åˆ°: {model_info.get('display_name', model_key)}")
            st.info("ğŸ’¡ AIæ¨¡å‹å·²æ›´æ–°ï¼Œæ–°çš„é€‰è‚¡åˆ†æå°†ä½¿ç”¨æ­¤æ¨¡å‹")
            
            # è®°å½•åˆ°session stateä»¥ä¾¿åç»­ä½¿ç”¨
            st.session_state.current_ai_model = model_key
            
            # å»ºè®®ç”¨æˆ·æ¸…ç†ç¼“å­˜
            if st.button("ğŸ§¹ æ¸…ç†AIç¼“å­˜", help="æ¸…ç†æ—§æ¨¡å‹çš„åˆ†æç¼“å­˜"):
                clear_ai_caches()
            
        else:
            st.error(f"âŒ æ¨¡å‹åˆ‡æ¢å¤±è´¥: {model_key}")
            
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åˆ‡æ¢å¼‚å¸¸: {e}")
        logger.error(f"æ¨¡å‹åˆ‡æ¢å¤±è´¥: {e}")

def test_ai_model(selector, model_key: str):
    """æµ‹è¯•AIæ¨¡å‹è¿æ¥"""
    try:
        with st.spinner("ğŸ§ª æ­£åœ¨æµ‹è¯•æ¨¡å‹è¿æ¥..."):
            # å°è¯•é€šè¿‡é€‰è‚¡å™¨æµ‹è¯•æ¨¡å‹
            available_models = selector.get_available_ai_models()
            model_info = available_models.get(model_key, {})
            
            if not model_info.get('has_api_key'):
                st.error("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: APIå¯†é’¥æœªé…ç½®")
                return
            
            # ç®€å•çš„è¿æ¥æµ‹è¯•
            try:
                from tradingagents.llm_adapters.dynamic_llm_manager import get_llm_manager
                llm_manager = get_llm_manager()
                test_result = llm_manager.test_model(model_key)
                
                if test_result.get('success'):
                    st.success("âœ… æ¨¡å‹è¿æ¥æµ‹è¯•æˆåŠŸ")
                    
                    # æ˜¾ç¤ºæµ‹è¯•è¯¦æƒ…
                    with st.expander("ğŸ“‹ æµ‹è¯•è¯¦æƒ…", expanded=False):
                        st.write(f"**æ¨¡å‹**: {test_result.get('model', 'N/A')}")
                        st.write(f"**æä¾›å•†**: {test_result.get('provider', 'N/A')}")
                        
                        response = test_result.get('response', '')
                        if response:
                            st.write(f"**æµ‹è¯•å“åº”**: {response[:200]}...")
                else:
                    st.error(f"âŒ æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥: {test_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
            except Exception as e:
                st.error(f"âŒ æ¨¡å‹æµ‹è¯•å¼‚å¸¸: {e}")
                
    except Exception as e:
        st.error(f"âŒ æµ‹è¯•è¿‡ç¨‹å¤±è´¥: {e}")
        logger.error(f"æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")

def display_longhubang_insights(data: pd.DataFrame):
    """æ˜¾ç¤ºé¾™è™æ¦œæ´å¯Ÿåˆ†æ"""
    if data.empty:
        return
    
    st.markdown("##### ğŸ‰ é¾™è™æ¦œåˆ†ææ´å¯Ÿ")
    
    # æ€§èƒ½å¯¹æ¯”å±•ç¤º
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("åˆ†æè‚¡ç¥¨æ•°", len(data))
    with col2:
        if 'longhubang_overall_score' in data.columns:
            avg_score = data['longhubang_overall_score'].mean()
            st.metric("å¹³å‡é¾™è™æ¦œè¯„åˆ†", f"{avg_score:.1f}")
        else:
            st.metric("æ•°æ®ç±»å‹", "é¾™è™æ¦œ")
    with col3:
        if 'net_inflow' in data.columns:
            net_inflow_positive = len(data[data['net_inflow'] > 0])
            st.metric("å‡€æµå…¥è‚¡ç¥¨", f"{net_inflow_positive}åª")
        else:
            st.metric("åˆ†æç»´åº¦", "å¤šç»´åº¦")
    with col4:
        if 'longhubang_ai_combined_score' in data.columns:
            combined_scores = data['longhubang_ai_combined_score'].dropna()
            if not combined_scores.empty:
                st.metric("æ™ºèƒ½ç»¼åˆè¯„åˆ†", f"{combined_scores.mean():.1f}")
            else:
                st.metric("å¤„ç†æ¨¡å¼", "æ™ºèƒ½å¢å¼º")
        else:
            st.metric("å¤„ç†æ¨¡å¼", "åŸºç¡€åˆ†æ")
    
    # å¸‚åœºæƒ…ç»ªåˆ†å¸ƒ
    if 'market_sentiment' in data.columns:
        st.markdown("##### ğŸ“Š å¸‚åœºæƒ…ç»ªåˆ†å¸ƒ")
        sentiment_counts = data['market_sentiment'].value_counts()
        if not sentiment_counts.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                # æ˜¾ç¤ºæƒ…ç»ªç»Ÿè®¡
                sentiment_mapping = {
                    'extremely_bullish': 'ğŸš€ æåº¦çœ‹å¤š',
                    'bullish': 'ğŸ“ˆ çœ‹å¤š',
                    'neutral': 'ğŸ˜ ä¸­æ€§',
                    'bearish': 'ğŸ“‰ çœ‹ç©º',
                    'extremely_bearish': 'ğŸ’¥ æåº¦çœ‹ç©º'
                }
                
                for sentiment, count in sentiment_counts.items():
                    display_name = sentiment_mapping.get(sentiment, sentiment)
                    st.write(f"{display_name}: {count}åª")
            
            with col2:
                # ç®€å•æŸ±çŠ¶å›¾
                sentiment_display = {k: sentiment_mapping.get(k, k) for k in sentiment_counts.index}
                renamed_counts = sentiment_counts.rename(index=sentiment_display)
                st.bar_chart(renamed_counts)
    
    # æ“ä½œæ¨¡å¼åˆ†å¸ƒ
    if 'operation_pattern' in data.columns:
        st.markdown("##### ğŸ¯ æ“ä½œæ¨¡å¼åˆ†å¸ƒ")
        pattern_counts = data['operation_pattern'].value_counts()
        if not pattern_counts.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                pattern_mapping = {
                    'institutional_buying': 'ğŸ›ï¸ æœºæ„ä¹°å…¥',
                    'institutional_selling': 'ğŸ›ï¸ æœºæ„å–å‡º',
                    'hot_money_speculation': 'ğŸ”¥ æ¸¸èµ„ç‚’ä½œ',
                    'retail_following': 'ğŸ‘¥ æ•£æˆ·è·Ÿé£',
                    'coordinated_operation': 'âš ï¸ ååŒæ“ä½œ',
                    'mixed_pattern': 'ğŸ”€ æ··åˆæ¨¡å¼'
                }
                
                for pattern, count in pattern_counts.items():
                    display_name = pattern_mapping.get(pattern, pattern)
                    st.write(f"{display_name}: {count}åª")
            
            with col2:
                pattern_display = {k: pattern_mapping.get(k, k) for k in pattern_counts.index}
                renamed_counts = pattern_counts.rename(index=pattern_display)
                st.bar_chart(renamed_counts)
    
    # ä¹°å–å®åŠ›å¯¹æ¯”
    if 'battle_result' in data.columns:
        st.markdown("##### âš”ï¸ ä¹°å–å®åŠ›å¯¹æ¯”")
        battle_counts = data['battle_result'].value_counts()
        if not battle_counts.empty:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                buy_wins = battle_counts.get('ä¹°æ–¹å ä¼˜', 0)
                st.metric("ğŸŸ¢ ä¹°æ–¹å ä¼˜", f"{buy_wins}åª")
            
            with col2:
                balanced = battle_counts.get('åŠ¿å‡åŠ›æ•Œ', 0)
                st.metric("ğŸŸ¡ åŠ¿å‡åŠ›æ•Œ", f"{balanced}åª")
            
            with col3:
                sell_wins = battle_counts.get('å–æ–¹å ä¼˜', 0)
                st.metric("ğŸ”´ å–æ–¹å ä¼˜", f"{sell_wins}åª")
    
    # èµ„é‡‘æµå‘åˆ†æ
    if 'net_inflow' in data.columns:
        st.markdown("##### ğŸ’° èµ„é‡‘æµå‘åˆ†æ")
        net_inflow_data = data['net_inflow'].dropna()
        if not net_inflow_data.empty:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                avg_inflow = net_inflow_data.mean()
                st.metric("å¹³å‡å‡€æµå…¥", f"{avg_inflow:.0f}ä¸‡")
            
            with col2:
                max_inflow = net_inflow_data.max()
                st.metric("æœ€å¤§å‡€æµå…¥", f"{max_inflow:.0f}ä¸‡")
            
            with col3:
                positive_count = len(net_inflow_data[net_inflow_data > 0])
                st.metric("å‡€æµå…¥è‚¡ç¥¨", f"{positive_count}åª")
            
            with col4:
                inflow_ratio = positive_count / len(net_inflow_data) * 100
                st.metric("å‡€æµå…¥æ¯”ä¾‹", f"{inflow_ratio:.1f}%")
    
    # å¸­ä½ç»Ÿè®¡
    if 'buy_seat_count' in data.columns and 'sell_seat_count' in data.columns:
        st.markdown("##### ğŸ›ï¸ å¸­ä½ç»Ÿè®¡")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_buy_seats = data['buy_seat_count'].mean()
            st.metric("å¹³å‡ä¹°æ–¹å¸­ä½", f"{avg_buy_seats:.1f}ä¸ª")
        
        with col2:
            avg_sell_seats = data['sell_seat_count'].mean()
            st.metric("å¹³å‡å–æ–¹å¸­ä½", f"{avg_sell_seats:.1f}ä¸ª")
        
        with col3:
            total_buy_seats = data['buy_seat_count'].sum()
            st.metric("æ€»ä¹°æ–¹å¸­ä½", f"{total_buy_seats}ä¸ª")
        
        with col4:
            total_sell_seats = data['sell_seat_count'].sum()
            st.metric("æ€»å–æ–¹å¸­ä½", f"{total_sell_seats}ä¸ª")
    
    # æŠ•èµ„å»ºè®®åˆ†å¸ƒ
    if 'investment_suggestion' in data.columns:
        st.markdown("##### ğŸ’¡ æŠ•èµ„å»ºè®®åˆ†å¸ƒ")
        suggestions = data['investment_suggestion'].dropna()
        if not suggestions.empty:
            # ç»Ÿè®¡å»ºè®®ç±»å‹
            suggestion_keywords = {
                'å¼ºçƒˆæ¨è': ['å¼ºçƒˆæ¨è', 'å¼ºçƒˆå»ºè®®'],
                'å»ºè®®å…³æ³¨': ['å»ºè®®å…³æ³¨', 'å»ºè®®è·Ÿéš'],
                'è°¨æ…è§‚å¯Ÿ': ['è°¨æ…è§‚å¯Ÿ', 'è°¨æ…è·Ÿéš'],
                'å»ºè®®å›é¿': ['å»ºè®®å›é¿', 'å»ºè®®è§‚æœ›']
            }
            
            suggestion_stats = {key: 0 for key in suggestion_keywords.keys()}
            
            for suggestion in suggestions:
                for category, keywords in suggestion_keywords.items():
                    if any(keyword in str(suggestion) for keyword in keywords):
                        suggestion_stats[category] += 1
                        break
            
            # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
            cols = st.columns(len(suggestion_stats))
            for i, (category, count) in enumerate(suggestion_stats.items()):
                with cols[i]:
                    st.metric(category, f"{count}åª")
    
    # é£é™©é¢„è­¦
    if 'risk_warning' in data.columns:
        st.markdown("##### âš ï¸ é£é™©é¢„è­¦åˆ†æ")
        risk_warnings = data['risk_warning'].dropna()
        if not risk_warnings.empty:
            # ç»Ÿè®¡é£é™©ç±»å‹
            risk_keywords = {
                'é«˜é£é™©': ['é«˜é£é™©', 'æ¸¸èµ„ç‚’ä½œ'],
                'ä¸­ç­‰é£é™©': ['ä¸­ç­‰é£é™©'],
                'ååŒæ“ä½œé£é™©': ['ååŒæ“ä½œ', 'æ“çºµ'],
                'è¿½é«˜é£é™©': ['è¿½é«˜é£é™©', 'æ³¨æ„æ³¢åŠ¨']
            }
            
            risk_stats = {key: 0 for key in risk_keywords.keys()}
            safe_stocks = len(risk_warnings)
            
            for warning in risk_warnings:
                warning_str = str(warning)
                if 'é£é™©ç›¸å¯¹å¯æ§' in warning_str:
                    continue
                    
                for category, keywords in risk_keywords.items():
                    if any(keyword in warning_str for keyword in keywords):
                        risk_stats[category] += 1
                        safe_stocks -= 1
                        break
            
            # æ˜¾ç¤ºé£é™©ç»Ÿè®¡
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**é£é™©åˆ†å¸ƒ:**")
                for category, count in risk_stats.items():
                    if count > 0:
                        st.write(f"â€¢ {category}: {count}åª")
                if safe_stocks > 0:
                    st.write(f"â€¢ ğŸŸ¢ é£é™©å¯æ§: {safe_stocks}åª")
            
            with col2:
                # é£é™©é¥¼å›¾æ•°æ®
                risk_chart_data = {k: v for k, v in risk_stats.items() if v > 0}
                if safe_stocks > 0:
                    risk_chart_data['é£é™©å¯æ§'] = safe_stocks
                
                if risk_chart_data:
                    import pandas as pd
                    risk_df = pd.DataFrame(list(risk_chart_data.items()), 
                                         columns=['é£é™©ç±»å‹', 'è‚¡ç¥¨æ•°é‡'])
                    risk_df = risk_df.set_index('é£é™©ç±»å‹')
                    st.bar_chart(risk_df)
    
    # è·Ÿéšå»ºè®®
    if 'follow_recommendation' in data.columns:
        st.markdown("##### ğŸ¯ è·Ÿéšå»ºè®®ç»Ÿè®¡")
        follow_data = data['follow_recommendation'].value_counts()
        if not follow_data.empty:
            cols = st.columns(min(4, len(follow_data)))
            for i, (recommendation, count) in enumerate(follow_data.items()):
                if i < len(cols):
                    with cols[i]:
                        st.metric(recommendation, f"{count}åª")

if __name__ == "__main__":
    render_stock_selector_page()