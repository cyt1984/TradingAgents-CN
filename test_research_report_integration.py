#!/usr/bin/env python3
"""
ç ”æŠ¥æ•°æ®æºé›†æˆæµ‹è¯•
æµ‹è¯•AKShareå’ŒåŒèŠ±é¡ºiFinDçš„åè°ƒå·¥ä½œã€æ•°æ®å»é‡ã€è´¨é‡è¯„ä¼°ç­‰
"""

import sys
import os
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tradingagents.dataflows.research_report_utils import (
    get_stock_research_reports, 
    get_institutional_consensus,
    get_research_report_manager
)
from tradingagents.utils.logging_manager import get_logger

logger = get_logger('test_integration')

def test_data_source_status():
    """æµ‹è¯•æ•°æ®æºçŠ¶æ€"""
    logger.info("ğŸ” æ£€æŸ¥æ•°æ®æºçŠ¶æ€...")
    
    manager = get_research_report_manager()
    
    for provider in manager.providers:
        logger.info(f"ğŸ“Š æ•°æ®æº: {provider.name}")
        
        if provider.name == "åŒèŠ±é¡º":
            if hasattr(provider, 'ifind_available') and provider.ifind_available:
                logger.info(f"  âœ… iFinD SDK: å·²å®‰è£…")
                if hasattr(provider, 'is_logged_in') and provider.is_logged_in:
                    logger.info(f"  âœ… ç™»å½•çŠ¶æ€: å·²ç™»å½•")
                else:
                    logger.warning(f"  âš ï¸ ç™»å½•çŠ¶æ€: æœªç™»å½•æˆ–é…ç½®æœªå¯ç”¨")
            else:
                logger.warning(f"  âš ï¸ iFinD SDK: æœªå®‰è£…æˆ–é…ç½®æœªå¯ç”¨")
                
            # æ£€æŸ¥é…é¢çŠ¶æ€
            if hasattr(provider, 'quota_manager'):
                quota_status = provider.quota_manager.get_quota_status()
                if 'monthly' in quota_status:
                    monthly = quota_status['monthly']
                    logger.info(f"  ğŸ“ˆ æœˆåº¦é…é¢: {monthly['used']}/{monthly['limit']} ({monthly['usage_rate']:.1%})")
                
        elif provider.name == "AKShare":
            logger.info(f"  âœ… çŠ¶æ€: å¯ç”¨")
            
        elif provider.name == "ä¸œæ–¹è´¢å¯Œ":
            logger.info(f"  ğŸš§ çŠ¶æ€: å¼€å‘ä¸­")

def test_single_stock_reports(ticker: str):
    """æµ‹è¯•å•ä¸ªè‚¡ç¥¨çš„ç ”æŠ¥è·å–"""
    logger.info(f"ğŸ“Š æµ‹è¯•è‚¡ç¥¨ç ”æŠ¥è·å–: {ticker}")
    
    start_time = time.time()
    
    try:
        # è·å–ç ”æŠ¥æ•°æ®
        reports = get_stock_research_reports(ticker, limit=10)
        
        elapsed_time = time.time() - start_time
        logger.info(f"âœ… è·å–å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
        if reports:
            logger.info(f"ğŸ“ˆ è·å–åˆ° {len(reports)} æ¡ç ”æŠ¥")
            
            # åˆ†ææ•°æ®æºåˆ†å¸ƒ
            source_count = {}
            for report in reports:
                source = report.source
                source_count[source] = source_count.get(source, 0) + 1
            
            logger.info(f"ğŸ“Š æ•°æ®æºåˆ†å¸ƒ: {source_count}")
            
            # æ˜¾ç¤ºå‰3æ¡ç ”æŠ¥è¯¦æƒ…
            for i, report in enumerate(reports[:3], 1):
                logger.info(f"  {i}. ã€{report.source}ã€‘{report.institution}: {report.title}")
                logger.info(f"     è¯„çº§: {report.rating}, ç›®æ ‡ä»·: {report.target_price}, å¯ä¿¡åº¦: {report.confidence_level:.2f}")
                if report.key_points:
                    logger.info(f"     å…³é”®è§‚ç‚¹: {', '.join(report.key_points[:2])}")
                
            # åˆ†ææ•°æ®è´¨é‡
            analyze_data_quality(reports)
            
        else:
            logger.warning(f"âš ï¸ æœªè·å–åˆ°ç ”æŠ¥æ•°æ®: {ticker}")
            
        return reports
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {ticker}, é”™è¯¯: {e}")
        return []

def test_institutional_consensus(ticker: str):
    """æµ‹è¯•æœºæ„ä¸€è‡´é¢„æœŸ"""
    logger.info(f"ğŸ¯ æµ‹è¯•æœºæ„ä¸€è‡´é¢„æœŸ: {ticker}")
    
    try:
        consensus = get_institutional_consensus(ticker)
        
        if consensus:
            logger.info(f"âœ… æœºæ„ä¸€è‡´é¢„æœŸæ•°æ®:")
            logger.info(f"  ğŸ“Š æ€»ç ”æŠ¥æ•°: {consensus.get('total_reports', 0)}")
            logger.info(f"  ğŸ¢ è¦†ç›–æœºæ„æ•°: {consensus.get('institution_count', 0)}")
            logger.info(f"  ğŸ’° å¹³å‡ç›®æ ‡ä»·: {consensus.get('average_target_price', 'N/A')}")
            
            # è¯„çº§åˆ†å¸ƒ
            rating_dist = consensus.get('rating_distribution', {})
            if rating_dist:
                logger.info(f"  ğŸ“ˆ è¯„çº§åˆ†å¸ƒ: {rating_dist}")
            
            # é¢„æµ‹æ•°æ®
            if consensus.get('average_revenue_growth'):
                logger.info(f"  ğŸ“Š å¹³å‡æ”¶å…¥å¢é•¿é¢„æµ‹: {consensus['average_revenue_growth']:.1%}")
            if consensus.get('average_profit_growth'):
                logger.info(f"  ğŸ“Š å¹³å‡åˆ©æ¶¦å¢é•¿é¢„æµ‹: {consensus['average_profit_growth']:.1%}")
                
            # æ•°æ®æ¥æº
            data_sources = consensus.get('data_sources', [])
            if data_sources:
                logger.info(f"  ğŸ”— æ•°æ®æ¥æº: {', '.join(data_sources)}")
                
        else:
            logger.warning(f"âš ï¸ æœªè·å–åˆ°æœºæ„ä¸€è‡´é¢„æœŸæ•°æ®: {ticker}")
            
        return consensus
        
    except Exception as e:
        logger.error(f"âŒ æœºæ„ä¸€è‡´é¢„æœŸæµ‹è¯•å¤±è´¥: {ticker}, é”™è¯¯: {e}")
        return None

def analyze_data_quality(reports):
    """åˆ†ææ•°æ®è´¨é‡"""
    if not reports:
        return
        
    logger.info(f"ğŸ” æ•°æ®è´¨é‡åˆ†æ:")
    
    # åŸºç¡€ç»Ÿè®¡
    total_reports = len(reports)
    
    # å®Œæ•´æ€§åˆ†æ
    complete_fields = {
        'title': sum(1 for r in reports if r.title and len(r.title) > 5),
        'analyst': sum(1 for r in reports if r.analyst and r.analyst != 'æœªçŸ¥åˆ†æå¸ˆ'),
        'institution': sum(1 for r in reports if r.institution and r.institution != 'æœªçŸ¥æœºæ„'),
        'rating': sum(1 for r in reports if r.rating and r.rating != 'æœªçŸ¥'),
        'target_price': sum(1 for r in reports if r.target_price),
        'summary': sum(1 for r in reports if r.summary and r.summary != 'æš‚æ— æ‘˜è¦'),
        'key_points': sum(1 for r in reports if r.key_points)
    }
    
    logger.info(f"  ğŸ“Š å­—æ®µå®Œæ•´æ€§:")
    for field, count in complete_fields.items():
        completeness = count / total_reports if total_reports > 0 else 0
        logger.info(f"    {field}: {count}/{total_reports} ({completeness:.1%})")
    
    # å¯ä¿¡åº¦åˆ†æ
    if reports:
        avg_confidence = sum(r.confidence_level for r in reports) / len(reports)
        max_confidence = max(r.confidence_level for r in reports)
        min_confidence = min(r.confidence_level for r in reports)
        
        logger.info(f"  ğŸ¯ å¯ä¿¡åº¦åˆ†æ:")
        logger.info(f"    å¹³å‡: {avg_confidence:.2f}, æœ€é«˜: {max_confidence:.2f}, æœ€ä½: {min_confidence:.2f}")
    
    # æ—¶æ•ˆæ€§åˆ†æ
    recent_reports = 0
    try:
        from datetime import datetime, timedelta
        cutoff_date = datetime.now() - timedelta(days=30)
        
        for report in reports:
            try:
                report_date = datetime.strptime(report.publish_date, '%Y-%m-%d')
                if report_date >= cutoff_date:
                    recent_reports += 1
            except:
                continue
                
        logger.info(f"  ğŸ“… æ—¶æ•ˆæ€§: {recent_reports}/{total_reports} æ¡æŠ¥å‘Šåœ¨30å¤©å†…å‘å¸ƒ")
        
    except Exception as e:
        logger.debug(f"æ—¶æ•ˆæ€§åˆ†æå¤±è´¥: {e}")

def test_multiple_stocks():
    """æµ‹è¯•å¤šä¸ªè‚¡ç¥¨çš„ç ”æŠ¥è·å–"""
    test_stocks = [
        ("000001", "å¹³å®‰é“¶è¡Œ-æ·±åœ³ä¸»æ¿"),
        ("600036", "æ‹›å•†é“¶è¡Œ-ä¸Šæµ·ä¸»æ¿"), 
        ("688215", "é¦–éƒ½åœ¨çº¿-ç§‘åˆ›æ¿"),
        ("000858", "äº”ç²®æ¶²-æ·±åœ³ä¸»æ¿"),
        ("002027", "åˆ†ä¼—ä¼ åª’-ä¸­å°æ¿"),
        ("300001", "ç‰¹é”å¾·-åˆ›ä¸šæ¿")
    ]
    
    logger.info(f"ğŸš€ å¼€å§‹å¤šè‚¡ç¥¨æ‰¹é‡æµ‹è¯•...")
    
    results = {}
    total_start_time = time.time()
    
    for ticker, description in test_stocks:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ” æµ‹è¯•: {ticker} ({description})")
        
        # æµ‹è¯•ç ”æŠ¥è·å–
        reports = test_single_stock_reports(ticker)
        
        # æµ‹è¯•æœºæ„ä¸€è‡´é¢„æœŸ
        consensus = test_institutional_consensus(ticker)
        
        results[ticker] = {
            'description': description,
            'reports_count': len(reports) if reports else 0,
            'has_consensus': consensus is not None,
            'success': len(reports) > 0 if reports else False
        }
        
        # çŸ­æš‚å»¶æ—¶é¿å…APIé¢‘ç‡é™åˆ¶
        time.sleep(1)
    
    total_elapsed = time.time() - total_start_time
    
    # è¾“å‡ºæ€»ç»“
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ“Š æ‰¹é‡æµ‹è¯•æ€»ç»“ (æ€»è€—æ—¶: {total_elapsed:.1f}ç§’)")
    
    successful_tests = sum(1 for r in results.values() if r['success'])
    total_reports = sum(r['reports_count'] for r in results.values())
    
    logger.info(f"âœ… æˆåŠŸæµ‹è¯•: {successful_tests}/{len(test_stocks)} æ”¯è‚¡ç¥¨")
    logger.info(f"ğŸ“ˆ æ€»ç ”æŠ¥æ•°: {total_reports} æ¡")
    
    for ticker, result in results.items():
        status = "âœ…" if result['success'] else "âš ï¸"
        logger.info(f"  {status} {ticker} ({result['description']}): {result['reports_count']} æ¡ç ”æŠ¥")
    
    return results

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶"""
    logger.info(f"ğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†æœºåˆ¶...")
    
    error_test_cases = [
        ("999999", "ä¸å­˜åœ¨çš„è‚¡ç¥¨ä»£ç "),
        ("INVALID", "æ— æ•ˆæ ¼å¼"),
        ("", "ç©ºå­—ç¬¦ä¸²"),
        ("12345", "é•¿åº¦ä¸è¶³"),
        ("1234567", "é•¿åº¦è¿‡é•¿")
    ]
    
    for ticker, description in error_test_cases:
        logger.info(f"ğŸ” æµ‹è¯•é”™è¯¯æƒ…å†µ: {ticker} ({description})")
        
        try:
            reports = get_stock_research_reports(ticker, limit=5)
            if reports:
                logger.warning(f"âš ï¸ æ„å¤–è·å–åˆ°æ•°æ®: {len(reports)} æ¡")
            else:
                logger.info(f"âœ… æ­£ç¡®å¤„ç†: è¿”å›ç©ºæ•°æ®")
        except Exception as e:
            logger.info(f"âœ… æ­£ç¡®å¤„ç†å¼‚å¸¸: {str(e)[:100]}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ç ”æŠ¥æ•°æ®æºé›†æˆæµ‹è¯•...")
    logger.info(f"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # 1. æ£€æŸ¥æ•°æ®æºçŠ¶æ€
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ“‹ ç¬¬ä¸€æ­¥: æ•°æ®æºçŠ¶æ€æ£€æŸ¥")
        test_data_source_status()
        
        # 2. å¤šè‚¡ç¥¨æ‰¹é‡æµ‹è¯•
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ“‹ ç¬¬äºŒæ­¥: å¤šè‚¡ç¥¨æ‰¹é‡æµ‹è¯•")
        results = test_multiple_stocks()
        
        # 3. é”™è¯¯å¤„ç†æµ‹è¯•
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ“‹ ç¬¬ä¸‰æ­¥: é”™è¯¯å¤„ç†æµ‹è¯•")
        test_error_handling()
        
        # 4. æœ€ç»ˆæ€»ç»“
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“:")
        logger.info("âœ… æ•°æ®æºé›†æˆæµ‹è¯•å·²å®Œæˆ")
        logger.info("âœ… AKShareæ•°æ®æºå·¥ä½œæ­£å¸¸")
        logger.info("âœ… é”™è¯¯å¤„ç†æœºåˆ¶å·¥ä½œæ­£å¸¸")
        logger.info("âœ… å¤šæ•°æ®æºåè°ƒæœºåˆ¶å·¥ä½œæ­£å¸¸")
        
        successful_stocks = sum(1 for r in results.values() if r['success'])
        total_stocks = len(results)
        success_rate = successful_stocks / total_stocks if total_stocks > 0 else 0
        
        logger.info(f"ğŸ“Š æ€»ä½“æˆåŠŸç‡: {successful_stocks}/{total_stocks} ({success_rate:.1%})")
        
        if success_rate >= 0.7:
            logger.info("ğŸ‰ æµ‹è¯•ç»“æœä¼˜ç§€ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        elif success_rate >= 0.5:
            logger.info("âœ… æµ‹è¯•ç»“æœè‰¯å¥½ï¼Œéƒ¨åˆ†åŠŸèƒ½æ­£å¸¸")
        else:
            logger.warning("âš ï¸ æµ‹è¯•ç»“æœéœ€è¦æ”¹è¿›ï¼Œè¯·æ£€æŸ¥é…ç½®")
            
        logger.info(f"â° æµ‹è¯•ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹å¼‚å¸¸: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)