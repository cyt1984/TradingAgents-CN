#!/usr/bin/env python3
"""
æ•°æ®ç®¡ç†CLIå·¥å…·
ç”¨äºç®¡ç†æœ¬åœ°æŒä¹…åŒ–å­˜å‚¨çš„è‚¡ç¥¨æ•°æ®
"""

import argparse
import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tradingagents.utils.logging_manager import get_logger
from tradingagents.dataflows.persistent_storage import get_persistent_manager
from tradingagents.dataflows.historical_data_manager import get_historical_manager
from tradingagents.dataflows.stock_master_manager import get_stock_master_manager

logger = get_logger('data_management_cli')


class DataManagementCLI:
    """æ•°æ®ç®¡ç†CLIå·¥å…·ç±»"""
    
    def __init__(self):
        self.persistent_manager = get_persistent_manager()
        self.historical_manager = get_historical_manager()
        self.stock_master_manager = get_stock_master_manager()
    
    def show_status(self):
        """æ˜¾ç¤ºæ•°æ®çŠ¶æ€"""
        print("ğŸ“Š æ•°æ®å­˜å‚¨çŠ¶æ€")
        print("=" * 50)
        
        # è‚¡ç¥¨åŸºç¡€ä¿¡æ¯çŠ¶æ€
        stock_summary = self.stock_master_manager.get_market_summary()
        if stock_summary:
            print(f"ğŸ“ˆ è‚¡ç¥¨æ€»æ•°: {stock_summary.get('total_stocks', 0)}")
            print(f"ğŸ”„ æœ€åæ›´æ–°: {stock_summary.get('last_updated', 'æœªçŸ¥')}")
            
            markets = stock_summary.get('markets', {})
            if markets:
                print("\nğŸ›ï¸ æŒ‰å¸‚åœºåˆ†å¸ƒ:")
                for market, count in markets.items():
                    print(f"   {market}: {count} åªè‚¡ç¥¨")
        
        # å†å²æ•°æ®çŠ¶æ€
        for freq in ['daily', 'weekly', 'monthly']:
            summary = self.historical_manager.get_data_summary(freq)
            if summary['total_symbols'] > 0:
                print(f"\nğŸ“… {freq.upper()}å†å²æ•°æ®:")
                print(f"   è‚¡ç¥¨æ•°é‡: {summary['total_symbols']}")
                print(f"   æ€»è®°å½•æ•°: {summary['total_records']:,}")
                print(f"   æ•°æ®èŒƒå›´: {summary['earliest_date']} - {summary['latest_date']}")
        
        # å­˜å‚¨ç©ºé—´ç»Ÿè®¡
        data_dir = Path("./data/persistent")
        if data_dir.exists():
            total_size = 0
            file_count = 0
            
            for category_dir in data_dir.iterdir():
                if category_dir.is_dir():
                    for file in category_dir.rglob("*.parquet"):
                        total_size += file.stat().st_size
                        file_count += 1
            
            print(f"\nğŸ’¾ å­˜å‚¨ç»Ÿè®¡:")
            print(f"   æ–‡ä»¶æ€»æ•°: {file_count}")
            print(f"   æ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB")
    
    def list_stocks(self, market: Optional[str] = None, limit: int = 50):
        """åˆ—å‡ºè‚¡ç¥¨"""
        stock_list = self.stock_master_manager.load_stock_list(market)
        
        if stock_list is None or stock_list.empty:
            print("âŒ æ— è‚¡ç¥¨æ•°æ®")
            return
        
        print(f"ğŸ“‹ è‚¡ç¥¨åˆ—è¡¨ ({len(stock_list)} åªè‚¡ç¥¨)")
        print("=" * 80)
        
        display_df = stock_list[['symbol', 'name', 'industry', 'market']].head(limit)
        print(display_df.to_string(index=False))
        
        if len(stock_list) > limit:
            print(f"\n... æ˜¾ç¤ºå‰ {limit} æ¡ï¼Œå…± {len(stock_list)} åªè‚¡ç¥¨")
    
    def search_stocks(self, keyword: str, field: str = "name"):
        """æœç´¢è‚¡ç¥¨"""
        results = self.stock_master_manager.search_stocks(keyword, field)
        
        if results.empty:
            print(f"âŒ æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„è‚¡ç¥¨")
            return
        
        print(f"ğŸ” æœç´¢ç»“æœ: '{keyword}' (å­—æ®µ: {field})")
        print("=" * 80)
        print(results[['symbol', 'name', 'industry', 'market']].to_string(index=False))
        print(f"\næ‰¾åˆ° {len(results)} åªè‚¡ç¥¨")
    
    def show_stock_info(self, symbol: str):
        """æ˜¾ç¤ºè‚¡ç¥¨è¯¦ç»†ä¿¡æ¯"""
        info = self.stock_master_manager.get_stock_info(symbol)
        
        if not info:
            print(f"âŒ æœªæ‰¾åˆ°è‚¡ç¥¨ä»£ç : {symbol}")
            return
        
        print(f"ğŸ“ˆ è‚¡ç¥¨è¯¦æƒ…: {symbol}")
        print("=" * 50)
        
        for key, value in info.items():
            if pd.notna(value) and value not in ['', None]:
                print(f"{key}: {value}")
    
    def check_data_integrity(self, symbol: str):
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        print(f"ğŸ” æ£€æŸ¥æ•°æ®å®Œæ•´æ€§: {symbol}")
        print("=" * 50)
        
        # æ£€æŸ¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        stock_info = self.stock_master_manager.get_stock_info(symbol)
        if not stock_info:
            print(f"âŒ è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ç¼ºå¤±: {symbol}")
            return
        
        print("âœ… è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å­˜åœ¨")
        
        # æ£€æŸ¥å†å²æ•°æ®
        for freq in ['daily', 'weekly', 'monthly']:
            availability = self.historical_manager.get_data_availability(symbol, freq)
            if availability['available']:
                print(f"âœ… {freq.upper()}å†å²æ•°æ®: {availability['record_count']} æ¡è®°å½•")
                
                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                integrity = self.historical_manager.verify_data_integrity(symbol, freq)
                if integrity['integrity_check'] == 'passed':
                    print(f"   âœ… {freq.upper()}æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                else:
                    print(f"   âŒ {freq.upper()}æ•°æ®å®Œæ•´æ€§é—®é¢˜:")
                    for issue in integrity['issues']:
                        print(f"      - {issue}")
            else:
                print(f"âš ï¸ {freq.upper()}å†å²æ•°æ®ä¸å­˜åœ¨")
    
    def cleanup_expired_data(self, days: int = 30):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        print(f"ğŸ§¹ æ¸…ç† {days} å¤©å‰çš„è¿‡æœŸæ•°æ®...")
        
        cutoff_date = datetime.now() - timedelta(days=days)
        cleaned_count = 0
        
        # æ¸…ç†æ—§çš„å…ƒæ•°æ®æ–‡ä»¶
        data_dir = Path("./data/persistent")
        if data_dir.exists():
            for metadata_file in data_dir.rglob("*_metadata.json"):
                try:
                    file_time = datetime.fromtimestamp(metadata_file.stat().st_mtime)
                    if file_time < cutoff_date:
                        # æ£€æŸ¥å¯¹åº”çš„æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        data_file = metadata_file.with_suffix('.parquet')
                        if not data_file.exists():
                            metadata_file.unlink()
                            cleaned_count += 1
                            print(f"âœ… æ¸…ç†å­¤ç«‹å…ƒæ•°æ®: {metadata_file}")
                except Exception as e:
                    print(f"âŒ æ¸…ç†å¤±è´¥: {metadata_file} - {e}")
        
        print(f"ğŸ‰ æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleaned_count} ä¸ªæ–‡ä»¶")
    
    def export_data(self, symbol: str, output_path: str, format: str = "csv"):
        """å¯¼å‡ºæ•°æ®"""
        print(f"ğŸ“¤ å¯¼å‡ºæ•°æ®: {symbol}")
        
        # å¯¼å‡ºè‚¡ç¥¨ä¿¡æ¯
        stock_info = self.stock_master_manager.get_stock_info(symbol)
        if stock_info:
            info_df = pd.DataFrame([stock_info])
            info_file = Path(output_path) / f"{symbol}_info.{format}"
            
            if format == "csv":
                info_df.to_csv(info_file, index=False, encoding='utf-8')
            elif format == "json":
                info_df.to_json(info_file, orient='records', force_ascii=False, indent=2)
            
            print(f"âœ… è‚¡ç¥¨ä¿¡æ¯å·²å¯¼å‡º: {info_file}")
        
        # å¯¼å‡ºå†å²æ•°æ®
        for freq in ['daily', 'weekly', 'monthly']:
            data = self.historical_manager.load_historical_data(symbol, freq)
            if data is not None and not data.empty:
                data_file = Path(output_path) / f"{symbol}_{freq}.{format}"
                
                if format == "csv":
                    data.to_csv(data_file, index=False, encoding='utf-8')
                elif format == "json":
                    data.to_json(data_file, orient='records', force_ascii=False, indent=2)
                
                print(f"âœ… {freq.upper()}å†å²æ•°æ®å·²å¯¼å‡º: {data_file}")
    
    def migrate_from_cache(self, source_dir: str = "./cache"):
        """ä»ç¼“å­˜è¿ç§»æ•°æ®åˆ°æŒä¹…åŒ–å­˜å‚¨"""
        print("ğŸ”„ ä»ç¼“å­˜è¿ç§»æ•°æ®åˆ°æŒä¹…åŒ–å­˜å‚¨...")
        
        cache_dir = Path(source_dir)
        if not cache_dir.exists():
            print(f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {source_dir}")
            return
        
        migrated_count = 0
        
        # è¿ç§»è‚¡ç¥¨åˆ—è¡¨æ•°æ®
        stock_files = list(cache_dir.glob("*stocks*.csv")) + list(cache_dir.glob("*stocks*.json"))
        for stock_file in stock_files:
            try:
                if stock_file.suffix == '.csv':
                    df = pd.read_csv(stock_file)
                elif stock_file.suffix == '.json':
                    df = pd.read_json(stock_file)
                
                if 'symbol' in df.columns and 'name' in df.columns:
                    self.stock_master_manager.save_stock_list(df.to_dict('records'))
                    migrated_count += 1
                    print(f"âœ… è¿ç§»è‚¡ç¥¨åˆ—è¡¨: {stock_file}")
            except Exception as e:
                print(f"âŒ è¿ç§»å¤±è´¥: {stock_file} - {e}")
        
        print(f"ğŸ‰ è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ä¸ªæ–‡ä»¶")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="TradingAgents æ•°æ®ç®¡ç†å·¥å…·")
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # çŠ¶æ€å‘½ä»¤
    status_parser = subparsers.add_parser('status', help='æ˜¾ç¤ºæ•°æ®çŠ¶æ€')
    
    # åˆ—è¡¨å‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºè‚¡ç¥¨')
    list_parser.add_argument('--market', help='æŒ‡å®šå¸‚åœº')
    list_parser.add_argument('--limit', type=int, default=50, help='æ˜¾ç¤ºæ•°é‡é™åˆ¶')
    
    # æœç´¢å‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æœç´¢è‚¡ç¥¨')
    search_parser.add_argument('keyword', help='æœç´¢å…³é”®è¯')
    search_parser.add_argument('--field', default='name', choices=['name', 'symbol', 'industry'], help='æœç´¢å­—æ®µ')
    
    # è¯¦æƒ…å‘½ä»¤
    info_parser = subparsers.add_parser('info', help='æ˜¾ç¤ºè‚¡ç¥¨è¯¦æƒ…')
    info_parser.add_argument('symbol', help='è‚¡ç¥¨ä»£ç ')
    
    # æ£€æŸ¥å‘½ä»¤
    check_parser = subparsers.add_parser('check', help='æ£€æŸ¥æ•°æ®å®Œæ•´æ€§')
    check_parser.add_argument('symbol', help='è‚¡ç¥¨ä»£ç ')
    
    # æ¸…ç†å‘½ä»¤
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†è¿‡æœŸæ•°æ®')
    cleanup_parser.add_argument('--days', type=int, default=30, help='æ¸…ç†å¤©æ•°')
    
    # å¯¼å‡ºå‘½ä»¤
    export_parser = subparsers.add_parser('export', help='å¯¼å‡ºæ•°æ®')
    export_parser.add_argument('symbol', help='è‚¡ç¥¨ä»£ç ')
    export_parser.add_argument('--output', default='./exports', help='è¾“å‡ºç›®å½•')
    export_parser.add_argument('--format', choices=['csv', 'json'], default='csv', help='å¯¼å‡ºæ ¼å¼')
    
    # è¿ç§»å‘½ä»¤
    migrate_parser = subparsers.add_parser('migrate', help='ä»ç¼“å­˜è¿ç§»æ•°æ®')
    migrate_parser.add_argument('--source', default='./cache', help='æºç›®å½•')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        cli = DataManagementCLI()
        
        if args.command == 'status':
            cli.show_status()
        elif args.command == 'list':
            cli.list_stocks(args.market, args.limit)
        elif args.command == 'search':
            cli.search_stocks(args.keyword, args.field)
        elif args.command == 'info':
            cli.show_stock_info(args.symbol)
        elif args.command == 'check':
            cli.check_data_integrity(args.symbol)
        elif args.command == 'cleanup':
            cli.cleanup_expired_data(args.days)
        elif args.command == 'export':
            cli.export_data(args.symbol, args.output, args.format)
        elif args.command == 'migrate':
            cli.migrate_from_cache(args.source)
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    main()